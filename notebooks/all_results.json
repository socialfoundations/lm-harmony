{
    "train_before_test": {
        "mnli": {
            "google/gemma-2-2b": 0.8758023433520122,
            "Qwen/Qwen1.5-4B-Chat": 0.8757004584819155,
            "Qwen/Qwen1.5-14B-Chat": 0.9016811003565971,
            "Qwen/Qwen2-7B-Instruct": 0.8920020376974019,
            "01-ai/Yi-9B": 0.899745287824758,
            "Qwen/Qwen2-1.5B": 0.8634742740703005,
            "EleutherAI/pythia-1b-deduped": 0.7812531839021906,
            "Qwen/Qwen2.5-7B-Instruct": 0.8988283239938869,
            "meta-llama/Llama-3.2-1B": 0.8482934284258787,
            "meta-llama/Meta-Llama-3-8B": 0.8879266428935303,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.8217014773306164,
            "01-ai/Yi-1.5-9B": 0.9025980641874681,
            "EleutherAI/pythia-1.4b-deduped": 0.8118186449312277,
            "Qwen/Qwen1.5-4B": 0.8792664289353032,
            "meta-llama/Llama-3.2-3B": 0.8748853795211411,
            "Qwen/Qwen1.5-0.5B-Chat": 0.8051961283749364,
            "EleutherAI/pythia-2.8b-deduped": 0.8360672440142639,
            "Qwen/Qwen2-0.5B": 0.8075394803871625,
            "01-ai/Yi-6B": 0.8802852776362711,
            "Qwen/Qwen1.5-7B-Chat": 0.8888436067244014,
            "Qwen/Qwen2.5-3B": 0.887111563932756,
            "Qwen/Qwen2-0.5B-Instruct": 0.807743250127356,
            "01-ai/Yi-6B-Chat": 0.8806928171166581,
            "google/gemma-7b-it": 0.891492613346918,
            "Qwen/Qwen1.5-14B": 0.9053489556800816,
            "meta-llama/Llama-3.1-8B": 0.8937340804890473,
            "01-ai/Yi-1.5-6B-Chat": 0.890983188996434,
            "EleutherAI/pythia-410m-deduped": 0.7589403973509934,
            "01-ai/Yi-1.5-9B-Chat": 0.8998471726948548,
            "Qwen/Qwen1.5-1.8B": 0.8388181355068772,
            "openai-community/gpt2-xl": 0.8060112073357106,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.8966887417218543,
            "google/gemma-2b-it": 0.8462557310239429,
            "google/gemma-7b": 0.903616912888436,
            "meta-llama/Llama-3.1-8B-Instruct": 0.9023942944472746,
            "Qwen/Qwen2.5-14B-Instruct": 0.910443199184921,
            "EleutherAI/pythia-160m-deduped": 0.6116148751910341,
            "meta-llama/Llama-3.2-1B-Instruct": 0.841874681609781,
            "meta-llama/Llama-3.2-3B-Instruct": 0.8833418237391747,
            "openai-community/gpt2": 0.5843097300050942,
            "Qwen/Qwen1.5-7B": 0.889047376464595,
            "Qwen/Qwen2.5-0.5B": 0.8214977075904228,
            "Qwen/Qwen2.5-14B": 0.9074885379521141,
            "google/gemma-2-9b": 0.9085073866530821,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.86571574121243,
            "Qwen/Qwen2.5-1.5B": 0.8647987773815589,
            "Qwen/Qwen2-1.5B-Instruct": 0.8614365766683647,
            "01-ai/Yi-1.5-6B": 0.8905756495160468,
            "Qwen/Qwen1.5-0.5B": 0.810188487009679,
            "openai-community/gpt2-large": 0.7754457463066735,
            "EleutherAI/pythia-6.9b-deduped": 0.8419765664798777,
            "openai-community/gpt2-medium": 0.6944472745797249,
            "Qwen/Qwen2.5-3B-Instruct": 0.8887417218543047,
            "google/gemma-2-9b-it": 0.9075904228222109,
            "google/gemma-2-2b-it": 0.8735608762098829,
            "Qwen/Qwen1.5-1.8B-Chat": 0.8455425369332654,
            "Qwen/Qwen2-7B": 0.894854814060112,
            "google/gemma-2b": 0.8544065206316862,
            "EleutherAI/pythia-12b": 0.8473764645950076,
            "Qwen/Qwen2.5-7B": 0.8952623535404992,
            "EleutherAI/pythia-70m-deduped": 0.5413143148242486
        },
        "qqp": {
            "google/gemma-2-2b": 0.8764,
            "Qwen/Qwen1.5-4B-Chat": 0.8767,
            "Qwen/Qwen1.5-14B-Chat": 0.8882,
            "Qwen/Qwen2-7B-Instruct": 0.8847,
            "01-ai/Yi-9B": 0.89,
            "Qwen/Qwen2-1.5B": 0.868,
            "EleutherAI/pythia-1b-deduped": 0.838,
            "Qwen/Qwen2.5-7B-Instruct": 0.8816,
            "meta-llama/Llama-3.2-1B": 0.8459,
            "meta-llama/Meta-Llama-3-8B": 0.8851,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.8588,
            "01-ai/Yi-1.5-9B": 0.8883,
            "EleutherAI/pythia-1.4b-deduped": 0.8538,
            "Qwen/Qwen1.5-4B": 0.8755,
            "meta-llama/Llama-3.2-3B": 0.8813,
            "Qwen/Qwen1.5-0.5B-Chat": 0.8529,
            "EleutherAI/pythia-2.8b-deduped": 0.8636,
            "Qwen/Qwen2-0.5B": 0.8572,
            "01-ai/Yi-6B": 0.8813,
            "Qwen/Qwen1.5-7B-Chat": 0.8822,
            "Qwen/Qwen2.5-3B": 0.8786,
            "Qwen/Qwen2-0.5B-Instruct": 0.8501,
            "01-ai/Yi-6B-Chat": 0.8828,
            "google/gemma-7b-it": 0.8822,
            "Qwen/Qwen1.5-14B": 0.8888,
            "meta-llama/Llama-3.1-8B": 0.8807,
            "01-ai/Yi-1.5-6B-Chat": 0.8799,
            "EleutherAI/pythia-410m-deduped": 0.8409,
            "01-ai/Yi-1.5-9B-Chat": 0.8855,
            "Qwen/Qwen1.5-1.8B": 0.87,
            "openai-community/gpt2-xl": 0.8373,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.8869,
            "google/gemma-2b-it": 0.8623,
            "google/gemma-7b": 0.8922,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8906,
            "Qwen/Qwen2.5-14B-Instruct": 0.8896,
            "EleutherAI/pythia-160m-deduped": 0.786,
            "meta-llama/Llama-3.2-1B-Instruct": 0.8431,
            "meta-llama/Llama-3.2-3B-Instruct": 0.8797,
            "openai-community/gpt2": 0.7115,
            "Qwen/Qwen1.5-7B": 0.8871,
            "Qwen/Qwen2.5-0.5B": 0.858,
            "Qwen/Qwen2.5-14B": 0.8884,
            "google/gemma-2-9b": 0.8926,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.8699,
            "Qwen/Qwen2.5-1.5B": 0.8726,
            "Qwen/Qwen2-1.5B-Instruct": 0.8691,
            "01-ai/Yi-1.5-6B": 0.8808,
            "Qwen/Qwen1.5-0.5B": 0.8555,
            "openai-community/gpt2-large": 0.816,
            "EleutherAI/pythia-6.9b-deduped": 0.8669,
            "openai-community/gpt2-medium": 0.7992,
            "Qwen/Qwen2.5-3B-Instruct": 0.8733,
            "google/gemma-2-9b-it": 0.8923,
            "google/gemma-2-2b-it": 0.8799,
            "Qwen/Qwen1.5-1.8B-Chat": 0.861,
            "Qwen/Qwen2-7B": 0.8823,
            "google/gemma-2b": 0.8683,
            "EleutherAI/pythia-12b": 0.8747,
            "Qwen/Qwen2.5-7B": 0.8816,
            "EleutherAI/pythia-70m-deduped": 0.7079
        },
        "medmcqa": {
            "google/gemma-2-2b": 0.47860387281855127,
            "Qwen/Qwen1.5-4B-Chat": 0.46593354052115704,
            "Qwen/Qwen1.5-14B-Chat": 0.5412383456849151,
            "Qwen/Qwen2-7B-Instruct": 0.5713602677504184,
            "01-ai/Yi-9B": 0.542194597179058,
            "Qwen/Qwen2-1.5B": 0.4561319627061917,
            "EleutherAI/pythia-1b-deduped": 0.33540521157064307,
            "Qwen/Qwen2.5-7B-Instruct": 0.6091322017690652,
            "meta-llama/Llama-3.2-1B": 0.40186469041357875,
            "meta-llama/Meta-Llama-3-8B": 0.5883337317714559,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.40712407363136505,
            "01-ai/Yi-1.5-9B": 0.5467367917762371,
            "EleutherAI/pythia-1.4b-deduped": 0.3413817834090366,
            "Qwen/Qwen1.5-4B": 0.4731054267272293,
            "meta-llama/Llama-3.2-3B": 0.5120726751135549,
            "Qwen/Qwen1.5-0.5B-Chat": 0.3695912024862539,
            "EleutherAI/pythia-2.8b-deduped": 0.3523786755916806,
            "Qwen/Qwen2-0.5B": 0.38034903179536217,
            "01-ai/Yi-6B": 0.5034664116662683,
            "Qwen/Qwen1.5-7B-Chat": 0.5008367200573751,
            "Qwen/Qwen2.5-3B": 0.5433899115467368,
            "Qwen/Qwen2-0.5B-Instruct": 0.3798709060482907,
            "01-ai/Yi-6B-Chat": 0.5080086062634472,
            "google/gemma-7b-it": 0.5058570404016256,
            "Qwen/Qwen1.5-14B": 0.545063351661487,
            "meta-llama/Llama-3.1-8B": 0.5840306000478126,
            "01-ai/Yi-1.5-6B-Chat": 0.5058570404016256,
            "EleutherAI/pythia-410m-deduped": 0.3275161367439637,
            "01-ai/Yi-1.5-9B-Chat": 0.5228305044226632,
            "Qwen/Qwen1.5-1.8B": 0.41788190294047334,
            "openai-community/gpt2-xl": 0.33468802295003586,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.614869710733923,
            "google/gemma-2b-it": 0.37843652880707623,
            "google/gemma-7b": 0.544107100167344,
            "meta-llama/Llama-3.1-8B-Instruct": 0.603872818551279,
            "Qwen/Qwen2.5-14B-Instruct": 0.6552713363614631,
            "EleutherAI/pythia-160m-deduped": 0.31436767869949794,
            "meta-llama/Llama-3.2-1B-Instruct": 0.4637819746593354,
            "meta-llama/Llama-3.2-3B-Instruct": 0.5606024384413101,
            "openai-community/gpt2": 0.318909873296677,
            "Qwen/Qwen1.5-7B": 0.5041836002868755,
            "Qwen/Qwen2.5-0.5B": 0.40545063351661487,
            "Qwen/Qwen2.5-14B": 0.6567057136026775,
            "google/gemma-2-9b": 0.6251494142959598,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.5003585943103036,
            "Qwen/Qwen2.5-1.5B": 0.5046617260339469,
            "Qwen/Qwen2-1.5B-Instruct": 0.4434616304087975,
            "01-ai/Yi-1.5-6B": 0.5089648577575903,
            "Qwen/Qwen1.5-0.5B": 0.3683958881185752,
            "openai-community/gpt2-large": 0.31986612479082,
            "EleutherAI/pythia-6.9b-deduped": 0.3648099450155391,
            "openai-community/gpt2-medium": 0.3158020559407124,
            "Qwen/Qwen2.5-3B-Instruct": 0.5467367917762371,
            "google/gemma-2-9b-it": 0.5998087497011714,
            "google/gemma-2-2b-it": 0.4793210614391585,
            "Qwen/Qwen1.5-1.8B-Chat": 0.40951470236672244,
            "Qwen/Qwen2-7B": 0.5756633994740616,
            "google/gemma-2b": 0.3901506096103275,
            "EleutherAI/pythia-12b": 0.3944537413339708,
            "Qwen/Qwen2.5-7B": 0.6163040879751375,
            "EleutherAI/pythia-70m-deduped": 0.32034425053789145
        },
        "qnli": {
            "google/gemma-2-2b": 0.9015193117334798,
            "Qwen/Qwen1.5-4B-Chat": 0.9119531393007505,
            "Qwen/Qwen1.5-14B-Chat": 0.9317224967966319,
            "Qwen/Qwen2-7B-Instruct": 0.9278784550613216,
            "01-ai/Yi-9B": 0.9214717188358045,
            "Qwen/Qwen2-1.5B": 0.8943803770821893,
            "EleutherAI/pythia-1b-deduped": 0.8491671242906828,
            "Qwen/Qwen2.5-7B-Instruct": 0.9123192385136372,
            "meta-llama/Llama-3.2-1B": 0.8740618707669778,
            "meta-llama/Meta-Llama-3-8B": 0.9236683141131247,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.862529745561047,
            "01-ai/Yi-1.5-9B": 0.9231191652937946,
            "EleutherAI/pythia-1.4b-deduped": 0.8769906644700713,
            "Qwen/Qwen1.5-4B": 0.9071938495332235,
            "meta-llama/Llama-3.2-3B": 0.9156141314296175,
            "Qwen/Qwen1.5-0.5B-Chat": 0.8649093904448105,
            "EleutherAI/pythia-2.8b-deduped": 0.8855939959729087,
            "Qwen/Qwen2-0.5B": 0.861980596741717,
            "01-ai/Yi-6B": 0.9022515101592532,
            "Qwen/Qwen1.5-7B-Chat": 0.8929159802306426,
            "Qwen/Qwen2.5-3B": 0.8940142778693025,
            "Qwen/Qwen2-0.5B-Instruct": 0.85667215815486,
            "01-ai/Yi-6B-Chat": 0.9033498077979132,
            "google/gemma-7b-it": 0.9209225700164745,
            "Qwen/Qwen1.5-14B": 0.9132344865458539,
            "meta-llama/Llama-3.1-8B": 0.9304411495515285,
            "01-ai/Yi-1.5-6B-Chat": 0.9022515101592532,
            "EleutherAI/pythia-410m-deduped": 0.8420281896393923,
            "01-ai/Yi-1.5-9B-Chat": 0.9229361156873512,
            "Qwen/Qwen1.5-1.8B": 0.876258466044298,
            "openai-community/gpt2-xl": 0.8912685337726524,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.9267801574226615,
            "google/gemma-2b-it": 0.8733296723412045,
            "google/gemma-7b": 0.9278784550613216,
            "meta-llama/Llama-3.1-8B-Instruct": 0.9265971078162182,
            "Qwen/Qwen2.5-14B-Instruct": 0.928610653487095,
            "EleutherAI/pythia-160m-deduped": 0.7303679297089511,
            "meta-llama/Llama-3.2-1B-Instruct": 0.8802855573860516,
            "meta-llama/Llama-3.2-3B-Instruct": 0.9200073219842577,
            "openai-community/gpt2": 0.6426871682225883,
            "Qwen/Qwen1.5-7B": 0.8859600951857953,
            "Qwen/Qwen2.5-0.5B": 0.8693025809994509,
            "Qwen/Qwen2.5-14B": 0.9311733479773019,
            "google/gemma-2-9b": 0.9344682408932821,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.8888888888888888,
            "Qwen/Qwen2.5-1.5B": 0.8907193849533224,
            "Qwen/Qwen2-1.5B-Instruct": 0.890536335346879,
            "01-ai/Yi-1.5-6B": 0.9055464030752334,
            "Qwen/Qwen1.5-0.5B": 0.8702178290316676,
            "openai-community/gpt2-large": 0.8544755628775398,
            "EleutherAI/pythia-6.9b-deduped": 0.8951125755079626,
            "openai-community/gpt2-medium": 0.8206113856855207,
            "Qwen/Qwen2.5-3B-Instruct": 0.8929159802306426,
            "google/gemma-2-9b-it": 0.9330038440417353,
            "google/gemma-2-2b-it": 0.9082921471718836,
            "Qwen/Qwen1.5-1.8B-Chat": 0.8797364085667215,
            "Qwen/Qwen2-7B": 0.9082921471718836,
            "google/gemma-2b": 0.8861431447922387,
            "EleutherAI/pythia-12b": 0.8855939959729087,
            "Qwen/Qwen2.5-7B": 0.9024345597656965,
            "EleutherAI/pythia-70m-deduped": 0.6075416437854658
        },
        "nq_open": {
            "google/gemma-2-2b": 0.22659279778393351,
            "Qwen/Qwen1.5-4B-Chat": 0.17340720221606648,
            "Qwen/Qwen1.5-14B-Chat": 0.24598337950138505,
            "Qwen/Qwen2-7B-Instruct": 0.2631578947368421,
            "01-ai/Yi-9B": 0.22326869806094182,
            "Qwen/Qwen2-1.5B": 0.14792243767313018,
            "EleutherAI/pythia-1b-deduped": 0.06703601108033241,
            "Qwen/Qwen2.5-7B-Instruct": 0.23213296398891967,
            "meta-llama/Llama-3.2-1B": 0.15373961218836565,
            "meta-llama/Meta-Llama-3-8B": 0.3146814404432133,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.06869806094182826,
            "01-ai/Yi-1.5-9B": 0.2409972299168975,
            "EleutherAI/pythia-1.4b-deduped": 0.07534626038781163,
            "Qwen/Qwen1.5-4B": 0.18254847645429362,
            "meta-llama/Llama-3.2-3B": 0.2562326869806094,
            "Qwen/Qwen1.5-0.5B-Chat": 0.04958448753462604,
            "EleutherAI/pythia-2.8b-deduped": 0.11689750692520776,
            "Qwen/Qwen2-0.5B": 0.06814404432132964,
            "01-ai/Yi-6B": 0.2565096952908587,
            "Qwen/Qwen1.5-7B-Chat": 0.21911357340720222,
            "Qwen/Qwen2.5-3B": 0.18864265927977839,
            "Qwen/Qwen2-0.5B-Instruct": 0.06454293628808865,
            "01-ai/Yi-6B-Chat": 0.25373961218836566,
            "google/gemma-7b-it": 0.22853185595567868,
            "Qwen/Qwen1.5-14B": 0.2484764542936288,
            "meta-llama/Llama-3.1-8B": 0.30886426592797783,
            "01-ai/Yi-1.5-6B-Chat": 0.20083102493074792,
            "EleutherAI/pythia-410m-deduped": 0.03628808864265928,
            "01-ai/Yi-1.5-9B-Chat": 0.21717451523545706,
            "Qwen/Qwen1.5-1.8B": 0.12936288088642658,
            "openai-community/gpt2-xl": 0.0850415512465374,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.29556786703601107,
            "google/gemma-2b-it": 0.1182825484764543,
            "google/gemma-7b": 0.29833795013850417,
            "meta-llama/Llama-3.1-8B-Instruct": 0.30969529085872577,
            "Qwen/Qwen2.5-14B-Instruct": 0.3033240997229917,
            "EleutherAI/pythia-160m-deduped": 0.0019390581717451524,
            "meta-llama/Llama-3.2-1B-Instruct": 0.18614958448753463,
            "meta-llama/Llama-3.2-3B-Instruct": 0.2822714681440443,
            "openai-community/gpt2": 0.025761772853185594,
            "Qwen/Qwen1.5-7B": 0.24542936288088643,
            "Qwen/Qwen2.5-0.5B": 0.07617728531855955,
            "Qwen/Qwen2.5-14B": 0.29889196675900276,
            "google/gemma-2-9b": 0.3221606648199446,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.1146814404432133,
            "Qwen/Qwen2.5-1.5B": 0.13656509695290858,
            "Qwen/Qwen2-1.5B-Instruct": 0.13601108033240997,
            "01-ai/Yi-1.5-6B": 0.2412742382271468,
            "Qwen/Qwen1.5-0.5B": 0.0628808864265928,
            "openai-community/gpt2-large": 0.07063711911357341,
            "EleutherAI/pythia-6.9b-deduped": 0.1481994459833795,
            "openai-community/gpt2-medium": 0.049307479224376734,
            "Qwen/Qwen2.5-3B-Instruct": 0.16565096952908587,
            "google/gemma-2-9b-it": 0.3238227146814404,
            "google/gemma-2-2b-it": 0.2116343490304709,
            "Qwen/Qwen1.5-1.8B-Chat": 0.12022160664819945,
            "Qwen/Qwen2-7B": 0.2775623268698061,
            "google/gemma-2b": 0.15983379501385042,
            "EleutherAI/pythia-12b": 0.17534626038781165,
            "Qwen/Qwen2.5-7B": 0.24986149584487535,
            "EleutherAI/pythia-70m-deduped": 0.0002770083102493075
        },
        "sst2": {
            "google/gemma-2-2b": 0.9552752293577982,
            "Qwen/Qwen1.5-4B-Chat": 0.9541284403669725,
            "Qwen/Qwen1.5-14B-Chat": 0.9678899082568807,
            "Qwen/Qwen2-7B-Instruct": 0.963302752293578,
            "01-ai/Yi-9B": 0.9575688073394495,
            "Qwen/Qwen2-1.5B": 0.9575688073394495,
            "EleutherAI/pythia-1b-deduped": 0.9254587155963303,
            "Qwen/Qwen2.5-7B-Instruct": 0.9621559633027523,
            "meta-llama/Llama-3.2-1B": 0.9506880733944955,
            "meta-llama/Meta-Llama-3-8B": 0.9587155963302753,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.9288990825688074,
            "01-ai/Yi-1.5-9B": 0.9587155963302753,
            "EleutherAI/pythia-1.4b-deduped": 0.9426605504587156,
            "Qwen/Qwen1.5-4B": 0.9575688073394495,
            "meta-llama/Llama-3.2-3B": 0.9644495412844036,
            "Qwen/Qwen1.5-0.5B-Chat": 0.930045871559633,
            "EleutherAI/pythia-2.8b-deduped": 0.9415137614678899,
            "Qwen/Qwen2-0.5B": 0.9220183486238532,
            "01-ai/Yi-6B": 0.9621559633027523,
            "Qwen/Qwen1.5-7B-Chat": 0.9587155963302753,
            "Qwen/Qwen2.5-3B": 0.9587155963302753,
            "Qwen/Qwen2-0.5B-Instruct": 0.9357798165137615,
            "01-ai/Yi-6B-Chat": 0.963302752293578,
            "google/gemma-7b-it": 0.9552752293577982,
            "Qwen/Qwen1.5-14B": 0.9644495412844036,
            "meta-llama/Llama-3.1-8B": 0.9575688073394495,
            "01-ai/Yi-1.5-6B-Chat": 0.9621559633027523,
            "EleutherAI/pythia-410m-deduped": 0.9174311926605505,
            "01-ai/Yi-1.5-9B-Chat": 0.9552752293577982,
            "Qwen/Qwen1.5-1.8B": 0.9461009174311926,
            "openai-community/gpt2-xl": 0.9403669724770642,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.9610091743119266,
            "google/gemma-2b-it": 0.948394495412844,
            "google/gemma-7b": 0.9598623853211009,
            "meta-llama/Llama-3.1-8B-Instruct": 0.9529816513761468,
            "Qwen/Qwen2.5-14B-Instruct": 0.963302752293578,
            "EleutherAI/pythia-160m-deduped": 0.8841743119266054,
            "meta-llama/Llama-3.2-1B-Instruct": 0.944954128440367,
            "meta-llama/Llama-3.2-3B-Instruct": 0.9621559633027523,
            "openai-community/gpt2": 0.893348623853211,
            "Qwen/Qwen1.5-7B": 0.9621559633027523,
            "Qwen/Qwen2.5-0.5B": 0.9231651376146789,
            "Qwen/Qwen2.5-14B": 0.9644495412844036,
            "google/gemma-2-9b": 0.9655963302752294,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.9529816513761468,
            "Qwen/Qwen2.5-1.5B": 0.9518348623853211,
            "Qwen/Qwen2-1.5B-Instruct": 0.9575688073394495,
            "01-ai/Yi-1.5-6B": 0.9598623853211009,
            "Qwen/Qwen1.5-0.5B": 0.9311926605504587,
            "openai-community/gpt2-large": 0.930045871559633,
            "EleutherAI/pythia-6.9b-deduped": 0.9529816513761468,
            "openai-community/gpt2-medium": 0.9288990825688074,
            "Qwen/Qwen2.5-3B-Instruct": 0.9587155963302753,
            "google/gemma-2-9b-it": 0.9610091743119266,
            "google/gemma-2-2b-it": 0.9575688073394495,
            "Qwen/Qwen1.5-1.8B-Chat": 0.9575688073394495,
            "Qwen/Qwen2-7B": 0.9598623853211009,
            "google/gemma-2b": 0.9598623853211009,
            "EleutherAI/pythia-12b": 0.9472477064220184,
            "Qwen/Qwen2.5-7B": 0.9564220183486238,
            "EleutherAI/pythia-70m-deduped": 0.7672018348623854
        },
        "winogrande": {
            "google/gemma-2-2b": 0.7861089187056038,
            "Qwen/Qwen1.5-4B-Chat": 0.7529597474348856,
            "Qwen/Qwen1.5-14B-Chat": 0.8161010260457774,
            "Qwen/Qwen2-7B-Instruct": 0.8271507498026835,
            "01-ai/Yi-9B": 0.813733228097869,
            "Qwen/Qwen2-1.5B": 0.7095501183898973,
            "EleutherAI/pythia-1b-deduped": 0.6029992107340174,
            "Qwen/Qwen2.5-7B-Instruct": 0.8224151539068666,
            "meta-llama/Llama-3.2-1B": 0.7008681925808997,
            "meta-llama/Meta-Llama-3-8B": 0.8602999210734017,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.6037884767166535,
            "01-ai/Yi-1.5-9B": 0.819258089976322,
            "EleutherAI/pythia-1.4b-deduped": 0.632991318074191,
            "Qwen/Qwen1.5-4B": 0.7482241515390686,
            "meta-llama/Llama-3.2-3B": 0.7845303867403315,
            "Qwen/Qwen1.5-0.5B-Chat": 0.5887924230465666,
            "EleutherAI/pythia-2.8b-deduped": 0.67008681925809,
            "Qwen/Qwen2-0.5B": 0.6172059984214681,
            "01-ai/Yi-6B": 0.7876874506708761,
            "Qwen/Qwen1.5-7B-Chat": 0.7821625887924231,
            "Qwen/Qwen2.5-3B": 0.7600631412786109,
            "Qwen/Qwen2-0.5B-Instruct": 0.6250986582478295,
            "01-ai/Yi-6B-Chat": 0.7908445146014207,
            "google/gemma-7b-it": 0.8176795580110497,
            "Qwen/Qwen1.5-14B": 0.824782951854775,
            "meta-llama/Llama-3.1-8B": 0.8500394632991318,
            "01-ai/Yi-1.5-6B-Chat": 0.7861089187056038,
            "EleutherAI/pythia-410m-deduped": 0.5611681136543015,
            "01-ai/Yi-1.5-9B-Chat": 0.8050513022888713,
            "Qwen/Qwen1.5-1.8B": 0.6724546172059984,
            "openai-community/gpt2-xl": 0.6479873717442778,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.8492501973164956,
            "google/gemma-2b-it": 0.6764009471191792,
            "google/gemma-7b": 0.8752959747434885,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8571428571428571,
            "Qwen/Qwen2.5-14B-Instruct": 0.8658247829518547,
            "EleutherAI/pythia-160m-deduped": 0.5256511444356748,
            "meta-llama/Llama-3.2-1B-Instruct": 0.681136543014996,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7861089187056038,
            "openai-community/gpt2": 0.516179952644041,
            "Qwen/Qwen1.5-7B": 0.7908445146014207,
            "Qwen/Qwen2.5-0.5B": 0.6179952644041041,
            "Qwen/Qwen2.5-14B": 0.8634569850039463,
            "google/gemma-2-9b": 0.8745067087608525,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7292817679558011,
            "Qwen/Qwen2.5-1.5B": 0.7174427782162589,
            "Qwen/Qwen2-1.5B-Instruct": 0.7213891081294396,
            "01-ai/Yi-1.5-6B": 0.7829518547750592,
            "Qwen/Qwen1.5-0.5B": 0.6077348066298343,
            "openai-community/gpt2-large": 0.5880031570639306,
            "EleutherAI/pythia-6.9b-deduped": 0.7158642462509865,
            "openai-community/gpt2-medium": 0.5730071033938438,
            "Qwen/Qwen2.5-3B-Instruct": 0.7600631412786109,
            "google/gemma-2-9b-it": 0.8634569850039463,
            "google/gemma-2-2b-it": 0.7947908445146015,
            "Qwen/Qwen1.5-1.8B-Chat": 0.6606156274664562,
            "Qwen/Qwen2-7B": 0.8326756116811366,
            "google/gemma-2b": 0.7363851617995264,
            "EleutherAI/pythia-12b": 0.7071823204419889,
            "Qwen/Qwen2.5-7B": 0.824782951854775,
            "EleutherAI/pythia-70m-deduped": 0.4861878453038674
        },
        "hellaswag": {
            "google/gemma-2-2b": 0.7853,
            "Qwen/Qwen1.5-4B-Chat": 0.7418,
            "Qwen/Qwen1.5-14B-Chat": 0.8272,
            "Qwen/Qwen2-7B-Instruct": 0.821,
            "01-ai/Yi-9B": 0.8085,
            "Qwen/Qwen2-1.5B": 0.6904,
            "EleutherAI/pythia-1b-deduped": 0.517,
            "Qwen/Qwen2.5-7B-Instruct": 0.8187,
            "meta-llama/Llama-3.2-1B": 0.6882,
            "meta-llama/Meta-Llama-3-8B": 0.8528,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.5386,
            "01-ai/Yi-1.5-9B": 0.8243,
            "EleutherAI/pythia-1.4b-deduped": 0.5763,
            "Qwen/Qwen1.5-4B": 0.7528,
            "meta-llama/Llama-3.2-3B": 0.7921,
            "Qwen/Qwen1.5-0.5B-Chat": 0.4848,
            "EleutherAI/pythia-2.8b-deduped": 0.6405,
            "Qwen/Qwen2-0.5B": 0.5145,
            "01-ai/Yi-6B": 0.7897,
            "Qwen/Qwen1.5-7B-Chat": 0.7936,
            "Qwen/Qwen2.5-3B": 0.7664,
            "Qwen/Qwen2-0.5B-Instruct": 0.5155,
            "01-ai/Yi-6B-Chat": 0.7889,
            "google/gemma-7b-it": 0.8124,
            "Qwen/Qwen1.5-14B": 0.8288,
            "meta-llama/Llama-3.1-8B": 0.8519,
            "01-ai/Yi-1.5-6B-Chat": 0.7919,
            "EleutherAI/pythia-410m-deduped": 0.4362,
            "01-ai/Yi-1.5-9B-Chat": 0.818,
            "Qwen/Qwen1.5-1.8B": 0.6433,
            "openai-community/gpt2-xl": 0.5418,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.8317,
            "google/gemma-2b-it": 0.675,
            "google/gemma-7b": 0.8613,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8335,
            "Qwen/Qwen2.5-14B-Instruct": 0.8618,
            "EleutherAI/pythia-160m-deduped": 0.3149,
            "meta-llama/Llama-3.2-1B-Instruct": 0.6591,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7654,
            "openai-community/gpt2": 0.3148,
            "Qwen/Qwen1.5-7B": 0.8012,
            "Qwen/Qwen2.5-0.5B": 0.5459,
            "Qwen/Qwen2.5-14B": 0.8607,
            "google/gemma-2-9b": 0.8579,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7052,
            "Qwen/Qwen2.5-1.5B": 0.7068,
            "Qwen/Qwen2-1.5B-Instruct": 0.6869,
            "01-ai/Yi-1.5-6B": 0.8042,
            "Qwen/Qwen1.5-0.5B": 0.5232,
            "openai-community/gpt2-large": 0.4733,
            "EleutherAI/pythia-6.9b-deduped": 0.709,
            "openai-community/gpt2-medium": 0.4127,
            "Qwen/Qwen2.5-3B-Instruct": 0.7631,
            "google/gemma-2-9b-it": 0.8555,
            "google/gemma-2-2b-it": 0.7767,
            "Qwen/Qwen1.5-1.8B-Chat": 0.6343,
            "Qwen/Qwen2-7B": 0.8277,
            "google/gemma-2b": 0.747,
            "EleutherAI/pythia-12b": 0.7277,
            "Qwen/Qwen2.5-7B": 0.8221,
            "EleutherAI/pythia-70m-deduped": 0.2757
        },
        "social_iqa": {
            "google/gemma-2-2b": 0.5762538382804504,
            "Qwen/Qwen1.5-4B-Chat": 0.5598771750255885,
            "Qwen/Qwen1.5-14B-Chat": 0.5665301944728761,
            "Qwen/Qwen2-7B-Instruct": 0.5808597748208802,
            "01-ai/Yi-9B": 0.579324462640737,
            "Qwen/Qwen2-1.5B": 0.5496417604912999,
            "EleutherAI/pythia-1b-deduped": 0.4953940634595701,
            "Qwen/Qwen2.5-7B-Instruct": 0.5619242579324463,
            "meta-llama/Llama-3.2-1B": 0.5363357215967247,
            "meta-llama/Meta-Llama-3-8B": 0.5967246673490276,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.4872057318321392,
            "01-ai/Yi-1.5-9B": 0.5885363357215967,
            "EleutherAI/pythia-1.4b-deduped": 0.5092118730808598,
            "Qwen/Qwen1.5-4B": 0.5557830092118731,
            "meta-llama/Llama-3.2-3B": 0.5685772773797338,
            "Qwen/Qwen1.5-0.5B-Chat": 0.481064483111566,
            "EleutherAI/pythia-2.8b-deduped": 0.5235414534288638,
            "Qwen/Qwen2-0.5B": 0.49744114636642783,
            "01-ai/Yi-6B": 0.5644831115660184,
            "Qwen/Qwen1.5-7B-Chat": 0.5429887410440123,
            "Qwen/Qwen2.5-3B": 0.5481064483111566,
            "Qwen/Qwen2-0.5B-Instruct": 0.4984646878198567,
            "01-ai/Yi-6B-Chat": 0.5624360286591606,
            "google/gemma-7b-it": 0.5680655066530195,
            "Qwen/Qwen1.5-14B": 0.5655066530194472,
            "meta-llama/Llama-3.1-8B": 0.601842374616172,
            "01-ai/Yi-1.5-6B-Chat": 0.5849539406345957,
            "EleutherAI/pythia-410m-deduped": 0.4677584442169908,
            "01-ai/Yi-1.5-9B-Chat": 0.6069600818833163,
            "Qwen/Qwen1.5-1.8B": 0.5286591606960082,
            "openai-community/gpt2-xl": 0.5056294779938587,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.612589559877175,
            "google/gemma-2b-it": 0.5414534288638689,
            "google/gemma-7b": 0.6095189355168884,
            "meta-llama/Llama-3.1-8B-Instruct": 0.5823950870010235,
            "Qwen/Qwen2.5-14B-Instruct": 0.5987717502558854,
            "EleutherAI/pythia-160m-deduped": 0.3961105424769703,
            "meta-llama/Llama-3.2-1B-Instruct": 0.5337768679631525,
            "meta-llama/Llama-3.2-3B-Instruct": 0.5598771750255885,
            "openai-community/gpt2": 0.42374616171954965,
            "Qwen/Qwen1.5-7B": 0.5475946775844421,
            "Qwen/Qwen2.5-0.5B": 0.49027635619242577,
            "Qwen/Qwen2.5-14B": 0.5910951893551689,
            "google/gemma-2-9b": 0.6095189355168884,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.5240532241555783,
            "Qwen/Qwen2.5-1.5B": 0.5184237461617196,
            "Qwen/Qwen2-1.5B-Instruct": 0.5419651995905834,
            "01-ai/Yi-1.5-6B": 0.5680655066530195,
            "Qwen/Qwen1.5-0.5B": 0.4907881269191402,
            "openai-community/gpt2-large": 0.49027635619242577,
            "EleutherAI/pythia-6.9b-deduped": 0.5501535312180144,
            "openai-community/gpt2-medium": 0.4872057318321392,
            "Qwen/Qwen2.5-3B-Instruct": 0.5465711361310133,
            "google/gemma-2-9b-it": 0.6136131013306039,
            "google/gemma-2-2b-it": 0.5696008188331627,
            "Qwen/Qwen1.5-1.8B-Chat": 0.5286591606960082,
            "Qwen/Qwen2-7B": 0.5788126919140225,
            "google/gemma-2b": 0.553224155578301,
            "EleutherAI/pythia-12b": 0.5475946775844421,
            "Qwen/Qwen2.5-7B": 0.5701125895598772,
            "EleutherAI/pythia-70m-deduped": 0.3602865916069601
        },
        "mathqa": {
            "google/gemma-2-2b": 0.421105527638191,
            "Qwen/Qwen1.5-4B-Chat": 0.4629815745393635,
            "Qwen/Qwen1.5-14B-Chat": 0.5745393634840871,
            "Qwen/Qwen2-7B-Instruct": 0.5634840871021776,
            "01-ai/Yi-9B": 0.4914572864321608,
            "Qwen/Qwen2-1.5B": 0.39798994974874374,
            "EleutherAI/pythia-1b-deduped": 0.25025125628140704,
            "Qwen/Qwen2.5-7B-Instruct": 0.590284757118928,
            "meta-llama/Llama-3.2-1B": 0.32998324958123953,
            "meta-llama/Meta-Llama-3-8B": 0.5051926298157454,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.33768844221105526,
            "01-ai/Yi-1.5-9B": 0.5031825795644891,
            "EleutherAI/pythia-1.4b-deduped": 0.2646566164154104,
            "Qwen/Qwen1.5-4B": 0.48743718592964824,
            "meta-llama/Llama-3.2-3B": 0.4438860971524288,
            "Qwen/Qwen1.5-0.5B-Chat": 0.27035175879396983,
            "EleutherAI/pythia-2.8b-deduped": 0.2723618090452261,
            "Qwen/Qwen2-0.5B": 0.31088777219430486,
            "01-ai/Yi-6B": 0.4130653266331658,
            "Qwen/Qwen1.5-7B-Chat": 0.4964824120603015,
            "Qwen/Qwen2.5-3B": 0.5135678391959799,
            "Qwen/Qwen2-0.5B-Instruct": 0.2994974874371859,
            "01-ai/Yi-6B-Chat": 0.39966499162479063,
            "google/gemma-7b-it": 0.48542713567839196,
            "Qwen/Qwen1.5-14B": 0.5819095477386935,
            "meta-llama/Llama-3.1-8B": 0.5005025125628141,
            "01-ai/Yi-1.5-6B-Chat": 0.5041876046901173,
            "EleutherAI/pythia-410m-deduped": 0.22981574539363483,
            "01-ai/Yi-1.5-9B-Chat": 0.5912897822445561,
            "Qwen/Qwen1.5-1.8B": 0.35577889447236183,
            "openai-community/gpt2-xl": 0.23819095477386934,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.4991624790619765,
            "google/gemma-2b-it": 0.33467336683417087,
            "google/gemma-7b": 0.5675041876046901,
            "meta-llama/Llama-3.1-8B-Instruct": 0.5035175879396985,
            "Qwen/Qwen2.5-14B-Instruct": 0.6820770519262982,
            "EleutherAI/pythia-160m-deduped": 0.23115577889447236,
            "meta-llama/Llama-3.2-1B-Instruct": 0.3417085427135678,
            "meta-llama/Llama-3.2-3B-Instruct": 0.47571189279731996,
            "openai-community/gpt2": 0.21708542713567838,
            "Qwen/Qwen1.5-7B": 0.4988274706867672,
            "Qwen/Qwen2.5-0.5B": 0.3417085427135678,
            "Qwen/Qwen2.5-14B": 0.6834170854271356,
            "google/gemma-2-9b": 0.6170854271356784,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.4304857621440536,
            "Qwen/Qwen2.5-1.5B": 0.43618090452261304,
            "Qwen/Qwen2-1.5B-Instruct": 0.39765494137353435,
            "01-ai/Yi-1.5-6B": 0.46700167504187606,
            "Qwen/Qwen1.5-0.5B": 0.28710217755443884,
            "openai-community/gpt2-large": 0.2338358458961474,
            "EleutherAI/pythia-6.9b-deduped": 0.3152428810720268,
            "openai-community/gpt2-medium": 0.22948073701842547,
            "Qwen/Qwen2.5-3B-Instruct": 0.4991624790619765,
            "google/gemma-2-9b-it": 0.5715242881072027,
            "google/gemma-2-2b-it": 0.42579564489112226,
            "Qwen/Qwen1.5-1.8B-Chat": 0.3628140703517588,
            "Qwen/Qwen2-7B": 0.5500837520938023,
            "google/gemma-2b": 0.3574539363484087,
            "EleutherAI/pythia-12b": 0.32998324958123953,
            "Qwen/Qwen2.5-7B": 0.6134003350083752,
            "EleutherAI/pythia-70m-deduped": 0.2254606365159129
        },
        "anli_r1": {
            "google/gemma-2-2b": 0.583,
            "Qwen/Qwen1.5-4B-Chat": 0.603,
            "Qwen/Qwen1.5-14B-Chat": 0.721,
            "Qwen/Qwen2-7B-Instruct": 0.688,
            "01-ai/Yi-9B": 0.693,
            "Qwen/Qwen2-1.5B": 0.568,
            "EleutherAI/pythia-1b-deduped": 0.391,
            "Qwen/Qwen2.5-7B-Instruct": 0.709,
            "meta-llama/Llama-3.2-1B": 0.423,
            "meta-llama/Meta-Llama-3-8B": 0.689,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.447,
            "01-ai/Yi-1.5-9B": 0.714,
            "EleutherAI/pythia-1.4b-deduped": 0.396,
            "Qwen/Qwen1.5-4B": 0.619,
            "meta-llama/Llama-3.2-3B": 0.592,
            "Qwen/Qwen1.5-0.5B-Chat": 0.437,
            "EleutherAI/pythia-2.8b-deduped": 0.434,
            "Qwen/Qwen2-0.5B": 0.419,
            "01-ai/Yi-6B": 0.657,
            "Qwen/Qwen1.5-7B-Chat": 0.698,
            "Qwen/Qwen2.5-3B": 0.64,
            "Qwen/Qwen2-0.5B-Instruct": 0.425,
            "01-ai/Yi-6B-Chat": 0.647,
            "google/gemma-7b-it": 0.651,
            "Qwen/Qwen1.5-14B": 0.724,
            "meta-llama/Llama-3.1-8B": 0.685,
            "01-ai/Yi-1.5-6B-Chat": 0.689,
            "EleutherAI/pythia-410m-deduped": 0.386,
            "01-ai/Yi-1.5-9B-Chat": 0.675,
            "Qwen/Qwen1.5-1.8B": 0.451,
            "openai-community/gpt2-xl": 0.379,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.688,
            "google/gemma-2b-it": 0.441,
            "google/gemma-7b": 0.715,
            "meta-llama/Llama-3.1-8B-Instruct": 0.699,
            "Qwen/Qwen2.5-14B-Instruct": 0.764,
            "EleutherAI/pythia-160m-deduped": 0.347,
            "meta-llama/Llama-3.2-1B-Instruct": 0.452,
            "meta-llama/Llama-3.2-3B-Instruct": 0.607,
            "openai-community/gpt2": 0.354,
            "Qwen/Qwen1.5-7B": 0.694,
            "Qwen/Qwen2.5-0.5B": 0.437,
            "Qwen/Qwen2.5-14B": 0.762,
            "google/gemma-2-9b": 0.718,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.574,
            "Qwen/Qwen2.5-1.5B": 0.558,
            "Qwen/Qwen2-1.5B-Instruct": 0.563,
            "01-ai/Yi-1.5-6B": 0.673,
            "Qwen/Qwen1.5-0.5B": 0.433,
            "openai-community/gpt2-large": 0.358,
            "EleutherAI/pythia-6.9b-deduped": 0.457,
            "openai-community/gpt2-medium": 0.383,
            "Qwen/Qwen2.5-3B-Instruct": 0.642,
            "google/gemma-2-9b-it": 0.752,
            "google/gemma-2-2b-it": 0.592,
            "Qwen/Qwen1.5-1.8B-Chat": 0.469,
            "Qwen/Qwen2-7B": 0.678,
            "google/gemma-2b": 0.495,
            "EleutherAI/pythia-12b": 0.485,
            "Qwen/Qwen2.5-7B": 0.708,
            "EleutherAI/pythia-70m-deduped": 0.329
        },
        "piqa": {
            "google/gemma-2-2b": 0.8052230685527747,
            "Qwen/Qwen1.5-4B-Chat": 0.7840043525571273,
            "Qwen/Qwen1.5-14B-Chat": 0.8215451577801959,
            "Qwen/Qwen2-7B-Instruct": 0.823177366702938,
            "01-ai/Yi-9B": 0.8177366702937976,
            "Qwen/Qwen2-1.5B": 0.7687704026115343,
            "EleutherAI/pythia-1b-deduped": 0.7132752992383025,
            "Qwen/Qwen2.5-7B-Instruct": 0.8188248095756256,
            "meta-llama/Llama-3.2-1B": 0.780195865070729,
            "meta-llama/Meta-Llama-3-8B": 0.8438520130576714,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.704570184983678,
            "01-ai/Yi-1.5-9B": 0.8286180631120783,
            "EleutherAI/pythia-1.4b-deduped": 0.7334058759521219,
            "Qwen/Qwen1.5-4B": 0.7921653971708379,
            "meta-llama/Llama-3.2-3B": 0.8117519042437432,
            "Qwen/Qwen1.5-0.5B-Chat": 0.6898803046789989,
            "EleutherAI/pythia-2.8b-deduped": 0.7595212187159956,
            "Qwen/Qwen2-0.5B": 0.6953210010881393,
            "01-ai/Yi-6B": 0.8106637649619152,
            "Qwen/Qwen1.5-7B-Chat": 0.8030467899891186,
            "Qwen/Qwen2.5-3B": 0.795429815016322,
            "Qwen/Qwen2-0.5B-Instruct": 0.6996735582154516,
            "01-ai/Yi-6B-Chat": 0.8035908596300326,
            "google/gemma-7b-it": 0.8128400435255713,
            "Qwen/Qwen1.5-14B": 0.8193688792165397,
            "meta-llama/Llama-3.1-8B": 0.8460282916213275,
            "01-ai/Yi-1.5-6B-Chat": 0.8144722524483133,
            "EleutherAI/pythia-410m-deduped": 0.6806311207834603,
            "01-ai/Yi-1.5-9B-Chat": 0.8280739934711643,
            "Qwen/Qwen1.5-1.8B": 0.7453754080522307,
            "openai-community/gpt2-xl": 0.7159956474428727,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.8188248095756256,
            "google/gemma-2b-it": 0.764417845484222,
            "google/gemma-7b": 0.8389553862894451,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8335146898803046,
            "Qwen/Qwen2.5-14B-Instruct": 0.8405875952121872,
            "EleutherAI/pythia-160m-deduped": 0.6251360174102285,
            "meta-llama/Llama-3.2-1B-Instruct": 0.7480957562568009,
            "meta-llama/Llama-3.2-3B-Instruct": 0.79379760609358,
            "openai-community/gpt2": 0.6305767138193689,
            "Qwen/Qwen1.5-7B": 0.8041349292709467,
            "Qwen/Qwen2.5-0.5B": 0.70620239390642,
            "Qwen/Qwen2.5-14B": 0.8389553862894451,
            "google/gemma-2-9b": 0.8520130576713819,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7752992383025027,
            "Qwen/Qwen2.5-1.5B": 0.7763873775843307,
            "Qwen/Qwen2-1.5B-Instruct": 0.7633297062023939,
            "01-ai/Yi-1.5-6B": 0.8199129488574538,
            "Qwen/Qwen1.5-0.5B": 0.7105549510337323,
            "openai-community/gpt2-large": 0.7187159956474428,
            "EleutherAI/pythia-6.9b-deduped": 0.7889009793253536,
            "openai-community/gpt2-medium": 0.6637649619151251,
            "Qwen/Qwen2.5-3B-Instruct": 0.794341675734494,
            "google/gemma-2-9b-it": 0.8394994559303591,
            "google/gemma-2-2b-it": 0.8128400435255713,
            "Qwen/Qwen1.5-1.8B-Chat": 0.7573449401523396,
            "Qwen/Qwen2-7B": 0.8286180631120783,
            "google/gemma-2b": 0.795429815016322,
            "EleutherAI/pythia-12b": 0.79379760609358,
            "Qwen/Qwen2.5-7B": 0.8166485310119695,
            "EleutherAI/pythia-70m-deduped": 0.5837867247007617
        },
        "sciq": {
            "google/gemma-2-2b": 0.985,
            "Qwen/Qwen1.5-4B-Chat": 0.971,
            "Qwen/Qwen1.5-14B-Chat": 0.978,
            "Qwen/Qwen2-7B-Instruct": 0.964,
            "01-ai/Yi-9B": 0.984,
            "Qwen/Qwen2-1.5B": 0.966,
            "EleutherAI/pythia-1b-deduped": 0.95,
            "Qwen/Qwen2.5-7B-Instruct": 0.98,
            "meta-llama/Llama-3.2-1B": 0.966,
            "meta-llama/Meta-Llama-3-8B": 0.981,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.957,
            "01-ai/Yi-1.5-9B": 0.982,
            "EleutherAI/pythia-1.4b-deduped": 0.956,
            "Qwen/Qwen1.5-4B": 0.976,
            "meta-llama/Llama-3.2-3B": 0.977,
            "Qwen/Qwen1.5-0.5B-Chat": 0.943,
            "EleutherAI/pythia-2.8b-deduped": 0.97,
            "Qwen/Qwen2-0.5B": 0.945,
            "01-ai/Yi-6B": 0.979,
            "Qwen/Qwen1.5-7B-Chat": 0.971,
            "Qwen/Qwen2.5-3B": 0.975,
            "Qwen/Qwen2-0.5B-Instruct": 0.947,
            "01-ai/Yi-6B-Chat": 0.975,
            "google/gemma-7b-it": 0.974,
            "Qwen/Qwen1.5-14B": 0.978,
            "meta-llama/Llama-3.1-8B": 0.982,
            "01-ai/Yi-1.5-6B-Chat": 0.979,
            "EleutherAI/pythia-410m-deduped": 0.944,
            "01-ai/Yi-1.5-9B-Chat": 0.975,
            "Qwen/Qwen1.5-1.8B": 0.963,
            "openai-community/gpt2-xl": 0.953,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.979,
            "google/gemma-2b-it": 0.969,
            "google/gemma-7b": 0.982,
            "meta-llama/Llama-3.1-8B-Instruct": 0.977,
            "Qwen/Qwen2.5-14B-Instruct": 0.988,
            "EleutherAI/pythia-160m-deduped": 0.874,
            "meta-llama/Llama-3.2-1B-Instruct": 0.967,
            "meta-llama/Llama-3.2-3B-Instruct": 0.971,
            "openai-community/gpt2": 0.89,
            "Qwen/Qwen1.5-7B": 0.973,
            "Qwen/Qwen2.5-0.5B": 0.959,
            "Qwen/Qwen2.5-14B": 0.988,
            "google/gemma-2-9b": 0.985,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.962,
            "Qwen/Qwen2.5-1.5B": 0.969,
            "Qwen/Qwen2-1.5B-Instruct": 0.961,
            "01-ai/Yi-1.5-6B": 0.973,
            "Qwen/Qwen1.5-0.5B": 0.942,
            "openai-community/gpt2-large": 0.943,
            "EleutherAI/pythia-6.9b-deduped": 0.964,
            "openai-community/gpt2-medium": 0.916,
            "Qwen/Qwen2.5-3B-Instruct": 0.972,
            "google/gemma-2-9b-it": 0.986,
            "google/gemma-2-2b-it": 0.979,
            "Qwen/Qwen1.5-1.8B-Chat": 0.962,
            "Qwen/Qwen2-7B": 0.977,
            "google/gemma-2b": 0.969,
            "EleutherAI/pythia-12b": 0.975,
            "Qwen/Qwen2.5-7B": 0.977,
            "EleutherAI/pythia-70m-deduped": 0.718
        },
        "commonsense_qa": {
            "google/gemma-2-2b": 0.7616707616707616,
            "Qwen/Qwen1.5-4B-Chat": 0.814086814086814,
            "Qwen/Qwen1.5-14B-Chat": 0.8665028665028665,
            "Qwen/Qwen2-7B-Instruct": 0.8509418509418509,
            "01-ai/Yi-9B": 0.8402948402948403,
            "Qwen/Qwen2-1.5B": 0.7305487305487306,
            "EleutherAI/pythia-1b-deduped": 0.19328419328419327,
            "Qwen/Qwen2.5-7B-Instruct": 0.8501228501228502,
            "meta-llama/Llama-3.2-1B": 0.6519246519246519,
            "meta-llama/Meta-Llama-3-8B": 0.8124488124488124,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.6216216216216216,
            "01-ai/Yi-1.5-9B": 0.8452088452088452,
            "EleutherAI/pythia-1.4b-deduped": 0.21785421785421785,
            "Qwen/Qwen1.5-4B": 0.8091728091728092,
            "meta-llama/Llama-3.2-3B": 0.769041769041769,
            "Qwen/Qwen1.5-0.5B-Chat": 0.5733005733005733,
            "EleutherAI/pythia-2.8b-deduped": 0.20966420966420968,
            "Qwen/Qwen2-0.5B": 0.6027846027846028,
            "01-ai/Yi-6B": 0.814086814086814,
            "Qwen/Qwen1.5-7B-Chat": 0.8419328419328419,
            "Qwen/Qwen2.5-3B": 0.8222768222768223,
            "Qwen/Qwen2-0.5B-Instruct": 0.5872235872235873,
            "01-ai/Yi-6B-Chat": 0.8034398034398035,
            "google/gemma-7b-it": 0.7919737919737919,
            "Qwen/Qwen1.5-14B": 0.8714168714168714,
            "meta-llama/Llama-3.1-8B": 0.8075348075348076,
            "01-ai/Yi-1.5-6B-Chat": 0.8222768222768223,
            "EleutherAI/pythia-410m-deduped": 0.19082719082719082,
            "01-ai/Yi-1.5-9B-Chat": 0.8468468468468469,
            "Qwen/Qwen1.5-1.8B": 0.7305487305487306,
            "openai-community/gpt2-xl": 0.19574119574119575,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.8132678132678133,
            "google/gemma-2b-it": 0.6445536445536445,
            "google/gemma-7b": 0.8149058149058149,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8116298116298116,
            "Qwen/Qwen2.5-14B-Instruct": 0.8722358722358723,
            "EleutherAI/pythia-160m-deduped": 0.1941031941031941,
            "meta-llama/Llama-3.2-1B-Instruct": 0.6855036855036855,
            "meta-llama/Llama-3.2-3B-Instruct": 0.782964782964783,
            "openai-community/gpt2": 0.2153972153972154,
            "Qwen/Qwen1.5-7B": 0.8435708435708436,
            "Qwen/Qwen2.5-0.5B": 0.6322686322686323,
            "Qwen/Qwen2.5-14B": 0.877968877968878,
            "google/gemma-2-9b": 0.8435708435708436,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7747747747747747,
            "Qwen/Qwen2.5-1.5B": 0.778050778050778,
            "Qwen/Qwen2-1.5B-Instruct": 0.7395577395577395,
            "01-ai/Yi-1.5-6B": 0.7993447993447993,
            "Qwen/Qwen1.5-0.5B": 0.5855855855855856,
            "openai-community/gpt2-large": 0.19901719901719903,
            "EleutherAI/pythia-6.9b-deduped": 0.6437346437346437,
            "openai-community/gpt2-medium": 0.19737919737919737,
            "Qwen/Qwen2.5-3B-Instruct": 0.8173628173628174,
            "google/gemma-2-9b-it": 0.8386568386568387,
            "google/gemma-2-2b-it": 0.7665847665847666,
            "Qwen/Qwen1.5-1.8B-Chat": 0.7411957411957412,
            "Qwen/Qwen2-7B": 0.8574938574938575,
            "google/gemma-2b": 0.6773136773136773,
            "EleutherAI/pythia-12b": 0.6388206388206388,
            "Qwen/Qwen2.5-7B": 0.8648648648648649,
            "EleutherAI/pythia-70m-deduped": 0.19656019656019655
        },
        "boolq": {
            "google/gemma-2-2b": 0.8522935779816514,
            "Qwen/Qwen1.5-4B-Chat": 0.8440366972477065,
            "Qwen/Qwen1.5-14B-Chat": 0.881651376146789,
            "Qwen/Qwen2-7B-Instruct": 0.8648318042813455,
            "01-ai/Yi-9B": 0.8871559633027523,
            "Qwen/Qwen2-1.5B": 0.8131498470948012,
            "EleutherAI/pythia-1b-deduped": 0.6847094801223241,
            "Qwen/Qwen2.5-7B-Instruct": 0.8733944954128441,
            "meta-llama/Llama-3.2-1B": 0.7960244648318043,
            "meta-llama/Meta-Llama-3-8B": 0.8859327217125382,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.7379204892966361,
            "01-ai/Yi-1.5-9B": 0.8807339449541285,
            "EleutherAI/pythia-1.4b-deduped": 0.7495412844036697,
            "Qwen/Qwen1.5-4B": 0.8354740061162079,
            "meta-llama/Llama-3.2-3B": 0.8669724770642202,
            "Qwen/Qwen1.5-0.5B-Chat": 0.6938837920489297,
            "EleutherAI/pythia-2.8b-deduped": 0.7868501529051988,
            "Qwen/Qwen2-0.5B": 0.7403669724770642,
            "01-ai/Yi-6B": 0.8550458715596331,
            "Qwen/Qwen1.5-7B-Chat": 0.8672782874617737,
            "Qwen/Qwen2.5-3B": 0.8577981651376146,
            "Qwen/Qwen2-0.5B-Instruct": 0.7247706422018348,
            "01-ai/Yi-6B-Chat": 0.8529051987767584,
            "google/gemma-7b-it": 0.8752293577981651,
            "Qwen/Qwen1.5-14B": 0.8889908256880734,
            "meta-llama/Llama-3.1-8B": 0.8850152905198777,
            "01-ai/Yi-1.5-6B-Chat": 0.8602446483180428,
            "EleutherAI/pythia-410m-deduped": 0.6761467889908257,
            "01-ai/Yi-1.5-9B-Chat": 0.8840978593272171,
            "Qwen/Qwen1.5-1.8B": 0.7856269113149847,
            "openai-community/gpt2-xl": 0.7269113149847095,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.8844036697247707,
            "google/gemma-2b-it": 0.7951070336391437,
            "google/gemma-7b": 0.8987767584097859,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8743119266055046,
            "Qwen/Qwen2.5-14B-Instruct": 0.8990825688073395,
            "EleutherAI/pythia-160m-deduped": 0.5981651376146789,
            "meta-llama/Llama-3.2-1B-Instruct": 0.7948012232415902,
            "meta-llama/Llama-3.2-3B-Instruct": 0.8590214067278288,
            "openai-community/gpt2": 0.6174311926605505,
            "Qwen/Qwen1.5-7B": 0.8697247706422019,
            "Qwen/Qwen2.5-0.5B": 0.7440366972477064,
            "Qwen/Qwen2.5-14B": 0.8996941896024465,
            "google/gemma-2-9b": 0.8978593272171254,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.8204892966360856,
            "Qwen/Qwen2.5-1.5B": 0.8275229357798165,
            "Qwen/Qwen2-1.5B-Instruct": 0.8174311926605504,
            "01-ai/Yi-1.5-6B": 0.8605504587155963,
            "Qwen/Qwen1.5-0.5B": 0.7229357798165138,
            "openai-community/gpt2-large": 0.6730886850152905,
            "EleutherAI/pythia-6.9b-deduped": 0.7981651376146789,
            "openai-community/gpt2-medium": 0.6412844036697247,
            "Qwen/Qwen2.5-3B-Instruct": 0.8599388379204893,
            "google/gemma-2-9b-it": 0.8932721712538226,
            "google/gemma-2-2b-it": 0.8535168195718654,
            "Qwen/Qwen1.5-1.8B-Chat": 0.7798165137614679,
            "Qwen/Qwen2-7B": 0.8657492354740061,
            "google/gemma-2b": 0.8177370030581039,
            "EleutherAI/pythia-12b": 0.8085626911314985,
            "Qwen/Qwen2.5-7B": 0.8779816513761468,
            "EleutherAI/pythia-70m-deduped": 0.6201834862385321
        },
        "cola": {
            "google/gemma-2-2b": 0.6319360049440768,
            "Qwen/Qwen1.5-4B-Chat": 0.6290472328963514,
            "Qwen/Qwen1.5-14B-Chat": 0.659237695747808,
            "Qwen/Qwen2-7B-Instruct": 0.6552244872723852,
            "01-ai/Yi-9B": 0.6248005169199495,
            "Qwen/Qwen2-1.5B": 0.5438848339212031,
            "EleutherAI/pythia-1b-deduped": 0.36511995503147754,
            "Qwen/Qwen2.5-7B-Instruct": 0.6373753124945251,
            "meta-llama/Llama-3.2-1B": 0.3319931000006738,
            "meta-llama/Meta-Llama-3-8B": 0.6354631293719158,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.35225835421905216,
            "01-ai/Yi-1.5-9B": 0.6169486919573096,
            "EleutherAI/pythia-1.4b-deduped": 0.3780568600075974,
            "Qwen/Qwen1.5-4B": 0.5898155805306483,
            "meta-llama/Llama-3.2-3B": 0.6123636063534844,
            "Qwen/Qwen1.5-0.5B-Chat": 0.29616698146800524,
            "EleutherAI/pythia-2.8b-deduped": 0.509917442354426,
            "Qwen/Qwen2-0.5B": 0.38512055344294677,
            "01-ai/Yi-6B": 0.6300663607102815,
            "Qwen/Qwen1.5-7B-Chat": 0.6500130889192514,
            "Qwen/Qwen2.5-3B": 0.604369091078345,
            "Qwen/Qwen2-0.5B-Instruct": 0.4844731708451588,
            "01-ai/Yi-6B-Chat": 0.6283714653016793,
            "google/gemma-7b-it": 0.5931289339428089,
            "Qwen/Qwen1.5-14B": 0.681351539687662,
            "meta-llama/Llama-3.1-8B": 0.6431520906619793,
            "01-ai/Yi-1.5-6B-Chat": 0.5666714425184584,
            "EleutherAI/pythia-410m-deduped": 0.006970123547161724,
            "01-ai/Yi-1.5-9B-Chat": 0.6084916718373158,
            "Qwen/Qwen1.5-1.8B": 0.5168530090749146,
            "openai-community/gpt2-xl": 0.0592680243795702,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.6355401056109184,
            "google/gemma-2b-it": 0.46008202227481587,
            "google/gemma-7b": 0.6754481998405855,
            "meta-llama/Llama-3.1-8B-Instruct": 0.6401931314484078,
            "Qwen/Qwen2.5-14B-Instruct": 0.6984878487471121,
            "EleutherAI/pythia-160m-deduped": 0.03479330099568123,
            "meta-llama/Llama-3.2-1B-Instruct": 0.4038697051002986,
            "meta-llama/Llama-3.2-3B-Instruct": 0.5966643221556519,
            "openai-community/gpt2": 0.025690322354642595,
            "Qwen/Qwen1.5-7B": 0.6663576224965111,
            "Qwen/Qwen2.5-0.5B": 0.36691383052991144,
            "Qwen/Qwen2.5-14B": 0.6807862826744437,
            "google/gemma-2-9b": 0.6707417313993576,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.5930833673541395,
            "Qwen/Qwen2.5-1.5B": 0.5646641419963531,
            "Qwen/Qwen2-1.5B-Instruct": 0.5773965947429363,
            "01-ai/Yi-1.5-6B": 0.5938714713515044,
            "Qwen/Qwen1.5-0.5B": 0.4239707198545135,
            "openai-community/gpt2-large": 0.0,
            "EleutherAI/pythia-6.9b-deduped": 0.5152333373313759,
            "openai-community/gpt2-medium": 0.009023667523969658,
            "Qwen/Qwen2.5-3B-Instruct": 0.5823091363718065,
            "google/gemma-2-9b-it": 0.6731940561885269,
            "google/gemma-2-2b-it": 0.6253608167975634,
            "Qwen/Qwen1.5-1.8B-Chat": 0.4694776800953171,
            "Qwen/Qwen2-7B": 0.6331116476930755,
            "google/gemma-2b": 0.5549381063161408,
            "EleutherAI/pythia-12b": 0.5356928374519817,
            "Qwen/Qwen2.5-7B": 0.5729071075701487,
            "EleutherAI/pythia-70m-deduped": 0.0
        },
        "gsm8k": {
            "google/gemma-2-2b": 0.37680060652009095,
            "Qwen/Qwen1.5-4B-Chat": 0.4579226686884003,
            "Qwen/Qwen1.5-14B-Chat": 0.6633813495072024,
            "Qwen/Qwen2-7B-Instruct": 0.7498104624715694,
            "01-ai/Yi-9B": 0.5375284306292646,
            "Qwen/Qwen2-1.5B": 0.5382865807429871,
            "EleutherAI/pythia-1b-deduped": 0.04397270659590599,
            "Qwen/Qwen2.5-7B-Instruct": 0.7869598180439727,
            "meta-llama/Llama-3.2-1B": 0.12509476876421532,
            "meta-llama/Meta-Llama-3-8B": 0.5579984836997726,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.3062926459438969,
            "01-ai/Yi-1.5-9B": 0.6595905989385898,
            "EleutherAI/pythia-1.4b-deduped": 0.06292645943896892,
            "Qwen/Qwen1.5-4B": 0.5178165276724791,
            "meta-llama/Llama-3.2-3B": 0.379833206974981,
            "Qwen/Qwen1.5-0.5B-Chat": 0.155420773313116,
            "EleutherAI/pythia-2.8b-deduped": 0.10386656557998483,
            "Qwen/Qwen2-0.5B": 0.332827899924185,
            "01-ai/Yi-6B": 0.42380591357088704,
            "Qwen/Qwen1.5-7B-Chat": 0.5231235784685367,
            "Qwen/Qwen2.5-3B": 0.6747536012130402,
            "Qwen/Qwen2-0.5B-Instruct": 0.2896133434420015,
            "01-ai/Yi-6B-Chat": 0.40561031084154664,
            "google/gemma-7b-it": 0.5344958301743745,
            "Qwen/Qwen1.5-14B": 0.6732373009855952,
            "meta-llama/Llama-3.1-8B": 0.5572403335860501,
            "01-ai/Yi-1.5-6B-Chat": 0.6717210007581501,
            "EleutherAI/pythia-410m-deduped": 0.02577710386656558,
            "01-ai/Yi-1.5-9B-Chat": 0.7626990144048522,
            "Qwen/Qwen1.5-1.8B": 0.36997725549658833,
            "openai-community/gpt2-xl": 0.04245640636846096,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7520849128127369,
            "google/gemma-2b-it": 0.20318423047763456,
            "google/gemma-7b": 0.6307808946171342,
            "meta-llama/Llama-3.1-8B-Instruct": 0.7376800606520091,
            "Qwen/Qwen2.5-14B-Instruct": 0.8225928733889311,
            "EleutherAI/pythia-160m-deduped": 0.02047005307050796,
            "meta-llama/Llama-3.2-1B-Instruct": 0.35633055344958303,
            "meta-llama/Llama-3.2-3B-Instruct": 0.6360879454131918,
            "openai-community/gpt2": 0.02350265352539803,
            "Qwen/Qwen1.5-7B": 0.5815011372251706,
            "Qwen/Qwen2.5-0.5B": 0.33965125094768767,
            "Qwen/Qwen2.5-14B": 0.8188021228203184,
            "google/gemma-2-9b": 0.7119029567854435,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.5072024260803639,
            "Qwen/Qwen2.5-1.5B": 0.624715693707354,
            "Qwen/Qwen2-1.5B-Instruct": 0.4973464746019712,
            "01-ai/Yi-1.5-6B": 0.5701288855193328,
            "Qwen/Qwen1.5-0.5B": 0.22517058377558757,
            "openai-community/gpt2-large": 0.02350265352539803,
            "EleutherAI/pythia-6.9b-deduped": 0.1243366186504928,
            "openai-community/gpt2-medium": 0.022744503411675512,
            "Qwen/Qwen2.5-3B-Instruct": 0.6777862016679302,
            "google/gemma-2-9b-it": 0.7649734647460197,
            "google/gemma-2-2b-it": 0.5572403335860501,
            "Qwen/Qwen1.5-1.8B-Chat": 0.33131159969673996,
            "Qwen/Qwen2-7B": 0.7498104624715694,
            "google/gemma-2b": 0.20318423047763456,
            "EleutherAI/pythia-12b": 0.14329037149355572,
            "Qwen/Qwen2.5-7B": 0.7649734647460197,
            "EleutherAI/pythia-70m-deduped": 0.01592115238817286
        },
        "wic": {
            "google/gemma-2-2b": 0.6943573667711599,
            "Qwen/Qwen1.5-4B-Chat": 0.7147335423197492,
            "Qwen/Qwen1.5-14B-Chat": 0.7507836990595611,
            "Qwen/Qwen2-7B-Instruct": 0.7586206896551724,
            "01-ai/Yi-9B": 0.7476489028213166,
            "Qwen/Qwen2-1.5B": 0.6865203761755486,
            "EleutherAI/pythia-1b-deduped": 0.5893416927899686,
            "Qwen/Qwen2.5-7B-Instruct": 0.7272727272727273,
            "meta-llama/Llama-3.2-1B": 0.5783699059561128,
            "meta-llama/Meta-Llama-3-8B": 0.7460815047021944,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.6630094043887147,
            "01-ai/Yi-1.5-9B": 0.7476489028213166,
            "EleutherAI/pythia-1.4b-deduped": 0.6206896551724138,
            "Qwen/Qwen1.5-4B": 0.6974921630094044,
            "meta-llama/Llama-3.2-3B": 0.7084639498432602,
            "Qwen/Qwen1.5-0.5B-Chat": 0.6300940438871473,
            "EleutherAI/pythia-2.8b-deduped": 0.6316614420062696,
            "Qwen/Qwen2-0.5B": 0.6285266457680251,
            "01-ai/Yi-6B": 0.7288401253918495,
            "Qwen/Qwen1.5-7B-Chat": 0.7225705329153606,
            "Qwen/Qwen2.5-3B": 0.6974921630094044,
            "Qwen/Qwen2-0.5B-Instruct": 0.6347962382445141,
            "01-ai/Yi-6B-Chat": 0.7351097178683386,
            "google/gemma-7b-it": 0.7115987460815048,
            "Qwen/Qwen1.5-14B": 0.7507836990595611,
            "meta-llama/Llama-3.1-8B": 0.7304075235109718,
            "01-ai/Yi-1.5-6B-Chat": 0.7304075235109718,
            "EleutherAI/pythia-410m-deduped": 0.5736677115987461,
            "01-ai/Yi-1.5-9B-Chat": 0.7382445141065831,
            "Qwen/Qwen1.5-1.8B": 0.6473354231974922,
            "openai-community/gpt2-xl": 0.54858934169279,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7288401253918495,
            "google/gemma-2b-it": 0.6786833855799373,
            "google/gemma-7b": 0.731974921630094,
            "meta-llama/Llama-3.1-8B-Instruct": 0.725705329153605,
            "Qwen/Qwen2.5-14B-Instruct": 0.7492163009404389,
            "EleutherAI/pythia-160m-deduped": 0.554858934169279,
            "meta-llama/Llama-3.2-1B-Instruct": 0.6065830721003135,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7115987460815048,
            "openai-community/gpt2": 0.4952978056426332,
            "Qwen/Qwen1.5-7B": 0.719435736677116,
            "Qwen/Qwen2.5-0.5B": 0.6442006269592476,
            "Qwen/Qwen2.5-14B": 0.7664576802507836,
            "google/gemma-2-9b": 0.7601880877742947,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.670846394984326,
            "Qwen/Qwen2.5-1.5B": 0.6943573667711599,
            "Qwen/Qwen2-1.5B-Instruct": 0.7053291536050157,
            "01-ai/Yi-1.5-6B": 0.7225705329153606,
            "Qwen/Qwen1.5-0.5B": 0.6065830721003135,
            "openai-community/gpt2-large": 0.5579937304075235,
            "EleutherAI/pythia-6.9b-deduped": 0.6551724137931034,
            "openai-community/gpt2-medium": 0.5094043887147336,
            "Qwen/Qwen2.5-3B-Instruct": 0.7225705329153606,
            "google/gemma-2-9b-it": 0.7398119122257053,
            "google/gemma-2-2b-it": 0.7147335423197492,
            "Qwen/Qwen1.5-1.8B-Chat": 0.670846394984326,
            "Qwen/Qwen2-7B": 0.7429467084639498,
            "google/gemma-2b": 0.6598746081504702,
            "EleutherAI/pythia-12b": 0.6269592476489029,
            "Qwen/Qwen2.5-7B": 0.7429467084639498,
            "EleutherAI/pythia-70m-deduped": 0.5344827586206896
        },
        "openbookqa": {
            "google/gemma-2-2b": 0.524,
            "Qwen/Qwen1.5-4B-Chat": 0.478,
            "Qwen/Qwen1.5-14B-Chat": 0.562,
            "Qwen/Qwen2-7B-Instruct": 0.566,
            "01-ai/Yi-9B": 0.548,
            "Qwen/Qwen2-1.5B": 0.43,
            "EleutherAI/pythia-1b-deduped": 0.33,
            "Qwen/Qwen2.5-7B-Instruct": 0.542,
            "meta-llama/Llama-3.2-1B": 0.446,
            "meta-llama/Meta-Llama-3-8B": 0.572,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.378,
            "01-ai/Yi-1.5-9B": 0.546,
            "EleutherAI/pythia-1.4b-deduped": 0.37,
            "Qwen/Qwen1.5-4B": 0.492,
            "meta-llama/Llama-3.2-3B": 0.518,
            "Qwen/Qwen1.5-0.5B-Chat": 0.344,
            "EleutherAI/pythia-2.8b-deduped": 0.436,
            "Qwen/Qwen2-0.5B": 0.366,
            "01-ai/Yi-6B": 0.492,
            "Qwen/Qwen1.5-7B-Chat": 0.522,
            "Qwen/Qwen2.5-3B": 0.504,
            "Qwen/Qwen2-0.5B-Instruct": 0.364,
            "01-ai/Yi-6B-Chat": 0.494,
            "google/gemma-7b-it": 0.57,
            "Qwen/Qwen1.5-14B": 0.562,
            "meta-llama/Llama-3.1-8B": 0.602,
            "01-ai/Yi-1.5-6B-Chat": 0.548,
            "EleutherAI/pythia-410m-deduped": 0.3,
            "01-ai/Yi-1.5-9B-Chat": 0.552,
            "Qwen/Qwen1.5-1.8B": 0.438,
            "openai-community/gpt2-xl": 0.362,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.542,
            "google/gemma-2b-it": 0.408,
            "google/gemma-7b": 0.608,
            "meta-llama/Llama-3.1-8B-Instruct": 0.548,
            "Qwen/Qwen2.5-14B-Instruct": 0.61,
            "EleutherAI/pythia-160m-deduped": 0.268,
            "meta-llama/Llama-3.2-1B-Instruct": 0.434,
            "meta-llama/Llama-3.2-3B-Instruct": 0.484,
            "openai-community/gpt2": 0.272,
            "Qwen/Qwen1.5-7B": 0.56,
            "Qwen/Qwen2.5-0.5B": 0.376,
            "Qwen/Qwen2.5-14B": 0.634,
            "google/gemma-2-9b": 0.622,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.454,
            "Qwen/Qwen2.5-1.5B": 0.478,
            "Qwen/Qwen2-1.5B-Instruct": 0.416,
            "01-ai/Yi-1.5-6B": 0.508,
            "Qwen/Qwen1.5-0.5B": 0.338,
            "openai-community/gpt2-large": 0.35,
            "EleutherAI/pythia-6.9b-deduped": 0.448,
            "openai-community/gpt2-medium": 0.302,
            "Qwen/Qwen2.5-3B-Instruct": 0.518,
            "google/gemma-2-9b-it": 0.622,
            "google/gemma-2-2b-it": 0.542,
            "Qwen/Qwen1.5-1.8B-Chat": 0.418,
            "Qwen/Qwen2-7B": 0.558,
            "google/gemma-2b": 0.496,
            "EleutherAI/pythia-12b": 0.46,
            "Qwen/Qwen2.5-7B": 0.592,
            "EleutherAI/pythia-70m-deduped": 0.248
        },
        "mrpc": {
            "google/gemma-2-2b": 0.7745098039215687,
            "Qwen/Qwen1.5-4B-Chat": 0.8235294117647058,
            "Qwen/Qwen1.5-14B-Chat": 0.8602941176470589,
            "Qwen/Qwen2-7B-Instruct": 0.8553921568627451,
            "01-ai/Yi-9B": 0.8504901960784313,
            "Qwen/Qwen2-1.5B": 0.7794117647058824,
            "EleutherAI/pythia-1b-deduped": 0.7328431372549019,
            "Qwen/Qwen2.5-7B-Instruct": 0.8333333333333334,
            "meta-llama/Llama-3.2-1B": 0.7254901960784313,
            "meta-llama/Meta-Llama-3-8B": 0.8578431372549019,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.7892156862745098,
            "01-ai/Yi-1.5-9B": 0.821078431372549,
            "EleutherAI/pythia-1.4b-deduped": 0.7549019607843137,
            "Qwen/Qwen1.5-4B": 0.8357843137254902,
            "meta-llama/Llama-3.2-3B": 0.8235294117647058,
            "Qwen/Qwen1.5-0.5B-Chat": 0.7671568627450981,
            "EleutherAI/pythia-2.8b-deduped": 0.7475490196078431,
            "Qwen/Qwen2-0.5B": 0.7696078431372549,
            "01-ai/Yi-6B": 0.803921568627451,
            "Qwen/Qwen1.5-7B-Chat": 0.8504901960784313,
            "Qwen/Qwen2.5-3B": 0.821078431372549,
            "Qwen/Qwen2-0.5B-Instruct": 0.7696078431372549,
            "01-ai/Yi-6B-Chat": 0.8406862745098039,
            "google/gemma-7b-it": 0.8357843137254902,
            "Qwen/Qwen1.5-14B": 0.8700980392156863,
            "meta-llama/Llama-3.1-8B": 0.8284313725490197,
            "01-ai/Yi-1.5-6B-Chat": 0.8235294117647058,
            "EleutherAI/pythia-410m-deduped": 0.7058823529411765,
            "01-ai/Yi-1.5-9B-Chat": 0.8455882352941176,
            "Qwen/Qwen1.5-1.8B": 0.8063725490196079,
            "openai-community/gpt2-xl": 0.7083333333333334,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.8333333333333334,
            "google/gemma-2b-it": 0.7990196078431373,
            "google/gemma-7b": 0.8333333333333334,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8284313725490197,
            "Qwen/Qwen2.5-14B-Instruct": 0.875,
            "EleutherAI/pythia-160m-deduped": 0.696078431372549,
            "meta-llama/Llama-3.2-1B-Instruct": 0.7549019607843137,
            "meta-llama/Llama-3.2-3B-Instruct": 0.8259803921568627,
            "openai-community/gpt2": 0.6813725490196079,
            "Qwen/Qwen1.5-7B": 0.821078431372549,
            "Qwen/Qwen2.5-0.5B": 0.7941176470588235,
            "Qwen/Qwen2.5-14B": 0.8946078431372549,
            "google/gemma-2-9b": 0.8774509803921569,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.8137254901960784,
            "Qwen/Qwen2.5-1.5B": 0.8161764705882353,
            "Qwen/Qwen2-1.5B-Instruct": 0.8014705882352942,
            "01-ai/Yi-1.5-6B": 0.8431372549019608,
            "Qwen/Qwen1.5-0.5B": 0.7892156862745098,
            "openai-community/gpt2-large": 0.7058823529411765,
            "EleutherAI/pythia-6.9b-deduped": 0.7867647058823529,
            "openai-community/gpt2-medium": 0.7132352941176471,
            "Qwen/Qwen2.5-3B-Instruct": 0.7941176470588235,
            "google/gemma-2-9b-it": 0.8725490196078431,
            "google/gemma-2-2b-it": 0.8235294117647058,
            "Qwen/Qwen1.5-1.8B-Chat": 0.8112745098039216,
            "Qwen/Qwen2-7B": 0.8602941176470589,
            "google/gemma-2b": 0.7769607843137255,
            "EleutherAI/pythia-12b": 0.7647058823529411,
            "Qwen/Qwen2.5-7B": 0.8431372549019608,
            "EleutherAI/pythia-70m-deduped": 0.6838235294117647
        },
        "headqa_en": {
            "google/gemma-2-2b": 0.46061269146608314,
            "Qwen/Qwen1.5-4B-Chat": 0.38037928519328956,
            "Qwen/Qwen1.5-14B-Chat": 0.45550692924872355,
            "Qwen/Qwen2-7B-Instruct": 0.4697301239970824,
            "01-ai/Yi-9B": 0.4638949671772429,
            "Qwen/Qwen2-1.5B": 0.37819110138584977,
            "EleutherAI/pythia-1b-deduped": 0.3424507658643326,
            "Qwen/Qwen2.5-7B-Instruct": 0.47957695113056165,
            "meta-llama/Llama-3.2-1B": 0.39095550692924874,
            "meta-llama/Meta-Llama-3-8B": 0.5156819839533188,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.3388037928519329,
            "01-ai/Yi-1.5-9B": 0.474835886214442,
            "EleutherAI/pythia-1.4b-deduped": 0.34974471188913203,
            "Qwen/Qwen1.5-4B": 0.3924142961342086,
            "meta-llama/Llama-3.2-3B": 0.4682713347921225,
            "Qwen/Qwen1.5-0.5B-Chat": 0.29832239241429614,
            "EleutherAI/pythia-2.8b-deduped": 0.39460247994164843,
            "Qwen/Qwen2-0.5B": 0.31947483588621445,
            "01-ai/Yi-6B": 0.43836615609044494,
            "Qwen/Qwen1.5-7B-Chat": 0.42924872355944566,
            "Qwen/Qwen2.5-3B": 0.45587162654996355,
            "Qwen/Qwen2-0.5B-Instruct": 0.31546316557257476,
            "01-ai/Yi-6B-Chat": 0.4325309992706054,
            "google/gemma-7b-it": 0.44675419401896427,
            "Qwen/Qwen1.5-14B": 0.4657184536834427,
            "meta-llama/Llama-3.1-8B": 0.5171407731582787,
            "01-ai/Yi-1.5-6B-Chat": 0.43070751276440555,
            "EleutherAI/pythia-410m-deduped": 0.31582786287381476,
            "01-ai/Yi-1.5-9B-Chat": 0.4540481400437637,
            "Qwen/Qwen1.5-1.8B": 0.35120350109409193,
            "openai-community/gpt2-xl": 0.30342815463165573,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.5054704595185996,
            "google/gemma-2b-it": 0.3665207877461707,
            "google/gemma-7b": 0.5076586433260394,
            "meta-llama/Llama-3.1-8B-Instruct": 0.5109409190371991,
            "Qwen/Qwen2.5-14B-Instruct": 0.5441283734500365,
            "EleutherAI/pythia-160m-deduped": 0.2760758570386579,
            "meta-llama/Llama-3.2-1B-Instruct": 0.387308533916849,
            "meta-llama/Llama-3.2-3B-Instruct": 0.4431072210065646,
            "openai-community/gpt2": 0.26695842450765866,
            "Qwen/Qwen1.5-7B": 0.4401896425966448,
            "Qwen/Qwen2.5-0.5B": 0.3362509117432531,
            "Qwen/Qwen2.5-14B": 0.5590809628008753,
            "google/gemma-2-9b": 0.5769511305616338,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.39204959883296864,
            "Qwen/Qwen2.5-1.5B": 0.4048140043763676,
            "Qwen/Qwen2-1.5B-Instruct": 0.3588621444201313,
            "01-ai/Yi-1.5-6B": 0.4401896425966448,
            "Qwen/Qwen1.5-0.5B": 0.31327498176513496,
            "openai-community/gpt2-large": 0.29321663019693656,
            "EleutherAI/pythia-6.9b-deduped": 0.4022611232676878,
            "openai-community/gpt2-medium": 0.2924872355944566,
            "Qwen/Qwen2.5-3B-Instruct": 0.45331874544128375,
            "google/gemma-2-9b-it": 0.5477753464624362,
            "google/gemma-2-2b-it": 0.44566010211524437,
            "Qwen/Qwen1.5-1.8B-Chat": 0.3435448577680525,
            "Qwen/Qwen2-7B": 0.4711889132020423,
            "google/gemma-2b": 0.3986141502552881,
            "EleutherAI/pythia-12b": 0.4204959883296864,
            "Qwen/Qwen2.5-7B": 0.4974471188913202,
            "EleutherAI/pythia-70m-deduped": 0.2684172137126185
        },
        "rte": {
            "google/gemma-2-2b": 0.8303249097472925,
            "Qwen/Qwen1.5-4B-Chat": 0.851985559566787,
            "Qwen/Qwen1.5-14B-Chat": 0.9025270758122743,
            "Qwen/Qwen2-7B-Instruct": 0.8844765342960289,
            "01-ai/Yi-9B": 0.9025270758122743,
            "Qwen/Qwen2-1.5B": 0.8086642599277978,
            "EleutherAI/pythia-1b-deduped": 0.6642599277978339,
            "Qwen/Qwen2.5-7B-Instruct": 0.8700361010830325,
            "meta-llama/Llama-3.2-1B": 0.6895306859205776,
            "meta-llama/Meta-Llama-3-8B": 0.851985559566787,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.7436823104693141,
            "01-ai/Yi-1.5-9B": 0.9061371841155235,
            "EleutherAI/pythia-1.4b-deduped": 0.7148014440433214,
            "Qwen/Qwen1.5-4B": 0.851985559566787,
            "meta-llama/Llama-3.2-3B": 0.8231046931407943,
            "Qwen/Qwen1.5-0.5B-Chat": 0.7328519855595668,
            "EleutherAI/pythia-2.8b-deduped": 0.7292418772563177,
            "Qwen/Qwen2-0.5B": 0.7436823104693141,
            "01-ai/Yi-6B": 0.855595667870036,
            "Qwen/Qwen1.5-7B-Chat": 0.8664259927797834,
            "Qwen/Qwen2.5-3B": 0.8664259927797834,
            "Qwen/Qwen2-0.5B-Instruct": 0.7364620938628159,
            "01-ai/Yi-6B-Chat": 0.8411552346570397,
            "google/gemma-7b-it": 0.8303249097472925,
            "Qwen/Qwen1.5-14B": 0.9061371841155235,
            "meta-llama/Llama-3.1-8B": 0.8592057761732852,
            "01-ai/Yi-1.5-6B-Chat": 0.8375451263537906,
            "EleutherAI/pythia-410m-deduped": 0.5740072202166066,
            "01-ai/Yi-1.5-9B-Chat": 0.8808664259927798,
            "Qwen/Qwen1.5-1.8B": 0.776173285198556,
            "openai-community/gpt2-xl": 0.6064981949458483,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.9133574007220217,
            "google/gemma-2b-it": 0.7833935018050542,
            "google/gemma-7b": 0.8700361010830325,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8664259927797834,
            "Qwen/Qwen2.5-14B-Instruct": 0.9061371841155235,
            "EleutherAI/pythia-160m-deduped": 0.6101083032490975,
            "meta-llama/Llama-3.2-1B-Instruct": 0.779783393501805,
            "meta-llama/Llama-3.2-3B-Instruct": 0.8447653429602888,
            "openai-community/gpt2": 0.5306859205776173,
            "Qwen/Qwen1.5-7B": 0.8953068592057761,
            "Qwen/Qwen2.5-0.5B": 0.7509025270758123,
            "Qwen/Qwen2.5-14B": 0.8772563176895307,
            "google/gemma-2-9b": 0.8953068592057761,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.8122743682310469,
            "Qwen/Qwen2.5-1.5B": 0.8014440433212996,
            "Qwen/Qwen2-1.5B-Instruct": 0.8231046931407943,
            "01-ai/Yi-1.5-6B": 0.851985559566787,
            "Qwen/Qwen1.5-0.5B": 0.7472924187725631,
            "openai-community/gpt2-large": 0.5523465703971119,
            "EleutherAI/pythia-6.9b-deduped": 0.7509025270758123,
            "openai-community/gpt2-medium": 0.5270758122743683,
            "Qwen/Qwen2.5-3B-Instruct": 0.8664259927797834,
            "google/gemma-2-9b-it": 0.8989169675090253,
            "google/gemma-2-2b-it": 0.851985559566787,
            "Qwen/Qwen1.5-1.8B-Chat": 0.779783393501805,
            "Qwen/Qwen2-7B": 0.8880866425992779,
            "google/gemma-2b": 0.7833935018050542,
            "EleutherAI/pythia-12b": 0.7906137184115524,
            "Qwen/Qwen2.5-7B": 0.8592057761732852,
            "EleutherAI/pythia-70m-deduped": 0.5379061371841155
        },
        "arc_easy": {
            "google/gemma-2-2b": 0.8333333333333334,
            "Qwen/Qwen1.5-4B-Chat": 0.7828282828282829,
            "Qwen/Qwen1.5-14B-Chat": 0.827020202020202,
            "Qwen/Qwen2-7B-Instruct": 0.8531144781144782,
            "01-ai/Yi-9B": 0.8425925925925926,
            "Qwen/Qwen2-1.5B": 0.7537878787878788,
            "EleutherAI/pythia-1b-deduped": 0.632996632996633,
            "Qwen/Qwen2.5-7B-Instruct": 0.8552188552188552,
            "meta-llama/Llama-3.2-1B": 0.7344276094276094,
            "meta-llama/Meta-Llama-3-8B": 0.8644781144781145,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.6957070707070707,
            "01-ai/Yi-1.5-9B": 0.8585858585858586,
            "EleutherAI/pythia-1.4b-deduped": 0.6708754208754208,
            "Qwen/Qwen1.5-4B": 0.7933501683501684,
            "meta-llama/Llama-3.2-3B": 0.8215488215488216,
            "Qwen/Qwen1.5-0.5B-Chat": 0.6005892255892256,
            "EleutherAI/pythia-2.8b-deduped": 0.70496632996633,
            "Qwen/Qwen2-0.5B": 0.6498316498316499,
            "01-ai/Yi-6B": 0.8181818181818182,
            "Qwen/Qwen1.5-7B-Chat": 0.8051346801346801,
            "Qwen/Qwen2.5-3B": 0.8316498316498316,
            "Qwen/Qwen2-0.5B-Instruct": 0.6300505050505051,
            "01-ai/Yi-6B-Chat": 0.8177609427609428,
            "google/gemma-7b-it": 0.8076599326599326,
            "Qwen/Qwen1.5-14B": 0.8442760942760943,
            "meta-llama/Llama-3.1-8B": 0.8674242424242424,
            "01-ai/Yi-1.5-6B-Chat": 0.8379629629629629,
            "EleutherAI/pythia-410m-deduped": 0.5542929292929293,
            "01-ai/Yi-1.5-9B-Chat": 0.8480639730639731,
            "Qwen/Qwen1.5-1.8B": 0.7218013468013468,
            "openai-community/gpt2-xl": 0.6296296296296297,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.8484848484848485,
            "google/gemma-2b-it": 0.7117003367003367,
            "google/gemma-7b": 0.8775252525252525,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8611111111111112,
            "Qwen/Qwen2.5-14B-Instruct": 0.8935185185185185,
            "EleutherAI/pythia-160m-deduped": 0.41792929292929293,
            "meta-llama/Llama-3.2-1B-Instruct": 0.7243265993265994,
            "meta-llama/Llama-3.2-3B-Instruct": 0.8211279461279462,
            "openai-community/gpt2": 0.4537037037037037,
            "Qwen/Qwen1.5-7B": 0.8228114478114478,
            "Qwen/Qwen2.5-0.5B": 0.7015993265993266,
            "Qwen/Qwen2.5-14B": 0.8981481481481481,
            "google/gemma-2-9b": 0.8985690235690236,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7988215488215489,
            "Qwen/Qwen2.5-1.5B": 0.8143939393939394,
            "Qwen/Qwen2-1.5B-Instruct": 0.7436868686868687,
            "01-ai/Yi-1.5-6B": 0.8375420875420876,
            "Qwen/Qwen1.5-0.5B": 0.63510101010101,
            "openai-community/gpt2-large": 0.5972222222222222,
            "EleutherAI/pythia-6.9b-deduped": 0.7495791245791246,
            "openai-community/gpt2-medium": 0.5353535353535354,
            "Qwen/Qwen2.5-3B-Instruct": 0.8312289562289562,
            "google/gemma-2-9b-it": 0.8733164983164983,
            "google/gemma-2-2b-it": 0.8261784511784511,
            "Qwen/Qwen1.5-1.8B-Chat": 0.7070707070707071,
            "Qwen/Qwen2-7B": 0.8606902356902357,
            "google/gemma-2b": 0.7887205387205387,
            "EleutherAI/pythia-12b": 0.7643097643097643,
            "Qwen/Qwen2.5-7B": 0.8686868686868687,
            "EleutherAI/pythia-70m-deduped": 0.37962962962962965
        },
        "arc_challenge": {
            "google/gemma-2-2b": 0.5366894197952219,
            "Qwen/Qwen1.5-4B-Chat": 0.47696245733788395,
            "Qwen/Qwen1.5-14B-Chat": 0.5989761092150171,
            "Qwen/Qwen2-7B-Instruct": 0.5887372013651877,
            "01-ai/Yi-9B": 0.60580204778157,
            "Qwen/Qwen2-1.5B": 0.4308873720136519,
            "EleutherAI/pythia-1b-deduped": 0.2858361774744027,
            "Qwen/Qwen2.5-7B-Instruct": 0.5921501706484642,
            "meta-llama/Llama-3.2-1B": 0.4069965870307167,
            "meta-llama/Meta-Llama-3-8B": 0.6271331058020477,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.36006825938566556,
            "01-ai/Yi-1.5-9B": 0.6040955631399317,
            "EleutherAI/pythia-1.4b-deduped": 0.3361774744027304,
            "Qwen/Qwen1.5-4B": 0.5102389078498294,
            "meta-llama/Llama-3.2-3B": 0.5332764505119454,
            "Qwen/Qwen1.5-0.5B-Chat": 0.2935153583617747,
            "EleutherAI/pythia-2.8b-deduped": 0.39505119453924914,
            "Qwen/Qwen2-0.5B": 0.30119453924914674,
            "01-ai/Yi-6B": 0.5392491467576792,
            "Qwen/Qwen1.5-7B-Chat": 0.5238907849829352,
            "Qwen/Qwen2.5-3B": 0.5477815699658704,
            "Qwen/Qwen2-0.5B-Instruct": 0.310580204778157,
            "01-ai/Yi-6B-Chat": 0.5247440273037542,
            "google/gemma-7b-it": 0.552901023890785,
            "Qwen/Qwen1.5-14B": 0.5998293515358362,
            "meta-llama/Llama-3.1-8B": 0.6271331058020477,
            "01-ai/Yi-1.5-6B-Chat": 0.5563139931740614,
            "EleutherAI/pythia-410m-deduped": 0.26109215017064846,
            "01-ai/Yi-1.5-9B-Chat": 0.591296928327645,
            "Qwen/Qwen1.5-1.8B": 0.41467576791808874,
            "openai-community/gpt2-xl": 0.32081911262798635,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.5989761092150171,
            "google/gemma-2b-it": 0.4351535836177474,
            "google/gemma-7b": 0.6228668941979523,
            "meta-llama/Llama-3.1-8B-Instruct": 0.6160409556313993,
            "Qwen/Qwen2.5-14B-Instruct": 0.6774744027303754,
            "EleutherAI/pythia-160m-deduped": 0.24658703071672355,
            "meta-llama/Llama-3.2-1B-Instruct": 0.3779863481228669,
            "meta-llama/Llama-3.2-3B-Instruct": 0.5187713310580204,
            "openai-community/gpt2": 0.23378839590443687,
            "Qwen/Qwen1.5-7B": 0.5691126279863481,
            "Qwen/Qwen2.5-0.5B": 0.3447098976109215,
            "Qwen/Qwen2.5-14B": 0.6860068259385665,
            "google/gemma-2-9b": 0.6919795221843004,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.5110921501706485,
            "Qwen/Qwen2.5-1.5B": 0.4974402730375427,
            "Qwen/Qwen2-1.5B-Instruct": 0.42662116040955633,
            "01-ai/Yi-1.5-6B": 0.575938566552901,
            "Qwen/Qwen1.5-0.5B": 0.3046075085324232,
            "openai-community/gpt2-large": 0.2508532423208191,
            "EleutherAI/pythia-6.9b-deduped": 0.41467576791808874,
            "openai-community/gpt2-medium": 0.25341296928327645,
            "Qwen/Qwen2.5-3B-Instruct": 0.5196245733788396,
            "google/gemma-2-9b-it": 0.6706484641638225,
            "google/gemma-2-2b-it": 0.5443686006825939,
            "Qwen/Qwen1.5-1.8B-Chat": 0.3848122866894198,
            "Qwen/Qwen2-7B": 0.5964163822525598,
            "google/gemma-2b": 0.4539249146757679,
            "EleutherAI/pythia-12b": 0.46245733788395904,
            "Qwen/Qwen2.5-7B": 0.6322525597269625,
            "EleutherAI/pythia-70m-deduped": 0.21843003412969283
        },
        "arxiv_2025": {
            "01-ai/Yi-1.5-6B": 0.7328097097416659,
            "01-ai/Yi-1.5-9B": 0.6848995446547363,
            "01-ai/Yi-6B": 0.7004934131699769,
            "01-ai/Yi-9B": 0.6868882700128423,
            "EleutherAI/pythia-1.4b-deduped": 0.7265719349341173,
            "EleutherAI/pythia-12b": 0.6569013361990073,
            "EleutherAI/pythia-160m-deduped": 0.9685952129298327,
            "EleutherAI/pythia-1b-deduped": 0.7450468649241133,
            "EleutherAI/pythia-2.8b-deduped": 0.6891383510688085,
            "EleutherAI/pythia-410m-deduped": 0.7906947368441035,
            "EleutherAI/pythia-6.9b-deduped": 0.6769968138757441,
            "EleutherAI/pythia-70m-deduped": 1.0265336296582486,
            "Qwen/Qwen1.5-0.5B": 0.7857882624479894,
            "Qwen/Qwen1.5-1.8B": 0.7245651225222899,
            "Qwen/Qwen1.5-14B": 0.614577038261813,
            "Qwen/Qwen1.5-4B": 0.6921979721236775,
            "Qwen/Qwen1.5-7B": 0.6305000615124727,
            "Qwen/Qwen2-0.5B": 0.7807549956425852,
            "Qwen/Qwen2-1.5B": 0.7063478589047787,
            "Qwen/Qwen2-7B": 0.6283489191340478,
            "Qwen/Qwen2.5-0.5B": 0.7458730448413332,
            "Qwen/Qwen2.5-1.5B": 0.6739475386052468,
            "Qwen/Qwen2.5-14B": 0.5923051032438537,
            "Qwen/Qwen2.5-3B": 0.668175640453833,
            "Qwen/Qwen2.5-7B": 0.6170818204177966,
            "meta-llama/Llama-3.1-8B": 0.6347134470124663,
            "meta-llama/Llama-3.2-1B": 0.7175679351561143,
            "meta-llama/Llama-3.2-3B": 0.6668359699689201,
            "meta-llama/Meta-Llama-3-8B": 0.6389072694896577,
            "openai-community/gpt2": 1.0078982707996509,
            "openai-community/gpt2-large": 0.8721857591754058,
            "openai-community/gpt2-medium": 0.918700903777167,
            "openai-community/gpt2-xl": 0.8418546532586123,
            "01-ai/Yi-1.5-6B-Chat": 0.6621470389811223,
            "01-ai/Yi-1.5-9B-Chat": 0.6458008099116124,
            "01-ai/Yi-6B-Chat": 0.6921127136587804,
            "Qwen/Qwen1.5-0.5B-Chat": 0.879109543210982,
            "Qwen/Qwen1.5-1.8B-Chat": 0.7486829952749048,
            "Qwen/Qwen1.5-14B-Chat": 0.6259823579600509,
            "Qwen/Qwen1.5-4B-Chat": 0.6687711650870056,
            "Qwen/Qwen1.5-7B-Chat": 0.6478532230361022,
            "Qwen/Qwen2-0.5B-Instruct": 0.7961375029133215,
            "Qwen/Qwen2-1.5B-Instruct": 0.7192308919199367,
            "Qwen/Qwen2-7B-Instruct": 0.6386953503739892,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.7654260462371546,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.6952453855812958,
            "Qwen/Qwen2.5-14B-Instruct": 0.6323720580142691,
            "Qwen/Qwen2.5-3B-Instruct": 0.6654381735143591,
            "Qwen/Qwen2.5-7B-Instruct": 0.6392817688008416,
            "meta-llama/Llama-3.1-8B-Instruct": 0.6435835131080477,
            "meta-llama/Llama-3.2-1B-Instruct": 0.7646731061503309,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7033578830504366,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.6498180049783754
        },
        "wiki_2025": {
            "01-ai/Yi-1.5-6B": 0.8394167201643122,
            "01-ai/Yi-1.5-9B": 0.8262760479092309,
            "01-ai/Yi-6B": 0.838476243988181,
            "01-ai/Yi-9B": 0.8650369670742234,
            "EleutherAI/pythia-1.4b-deduped": 0.9777891122431402,
            "EleutherAI/pythia-12b": 0.8880918947343257,
            "EleutherAI/pythia-160m-deduped": 1.1905951170795033,
            "EleutherAI/pythia-1b-deduped": 1.0005435128929467,
            "EleutherAI/pythia-2.8b-deduped": 0.9373814942112451,
            "EleutherAI/pythia-410m-deduped": 1.0654384470793847,
            "EleutherAI/pythia-6.9b-deduped": 0.9035930468829242,
            "EleutherAI/pythia-70m-deduped": 1.324995566640545,
            "Qwen/Qwen1.5-0.5B": 1.0565347759924704,
            "Qwen/Qwen1.5-1.8B": 0.9742810490300391,
            "Qwen/Qwen1.5-14B": 0.8260423676433664,
            "Qwen/Qwen1.5-4B": 0.8946438769550275,
            "Qwen/Qwen1.5-7B": 0.8461756498591796,
            "Qwen/Qwen2-0.5B": 1.032064221998884,
            "Qwen/Qwen2-1.5B": 0.9248401868061242,
            "Qwen/Qwen2-7B": 0.8197114534426819,
            "Qwen/Qwen2.5-0.5B": 1.0270603180961917,
            "Qwen/Qwen2.5-1.5B": 0.9184544621102289,
            "Qwen/Qwen2.5-14B": 0.760689931360483,
            "Qwen/Qwen2.5-3B": 0.8781311047151077,
            "Qwen/Qwen2.5-7B": 0.8251544398459143,
            "meta-llama/Llama-3.1-8B": 0.7668360393195531,
            "meta-llama/Llama-3.2-1B": 0.9166107305781516,
            "meta-llama/Llama-3.2-3B": 0.8357836607638042,
            "meta-llama/Meta-Llama-3-8B": 0.7651959333195755,
            "openai-community/gpt2": 1.1848874571274126,
            "openai-community/gpt2-large": 1.0379992113133274,
            "openai-community/gpt2-medium": 1.0873799691057244,
            "openai-community/gpt2-xl": 1.0044265640362622,
            "01-ai/Yi-1.5-6B-Chat": 0.8892999984972446,
            "01-ai/Yi-1.5-9B-Chat": 0.8714218079041919,
            "01-ai/Yi-6B-Chat": 0.8436196162550571,
            "Qwen/Qwen1.5-0.5B-Chat": 1.1875078287529781,
            "Qwen/Qwen1.5-1.8B-Chat": 0.9996582617305635,
            "Qwen/Qwen1.5-14B-Chat": 0.8458577305387511,
            "Qwen/Qwen1.5-4B-Chat": 0.9232266066255181,
            "Qwen/Qwen1.5-7B-Chat": 0.881292517950302,
            "Qwen/Qwen2-0.5B-Instruct": 1.0413523625804775,
            "Qwen/Qwen2-1.5B-Instruct": 0.9314584589507623,
            "Qwen/Qwen2-7B-Instruct": 0.830897925929078,
            "Qwen/Qwen2.5-0.5B-Instruct": 1.0403271502488312,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.9255473778127967,
            "Qwen/Qwen2.5-14B-Instruct": 0.7692691468209265,
            "Qwen/Qwen2.5-3B-Instruct": 0.8793428409000333,
            "Qwen/Qwen2.5-7B-Instruct": 0.8339851589534472,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8094337732110105,
            "meta-llama/Llama-3.2-1B-Instruct": 1.001291632818482,
            "meta-llama/Llama-3.2-3B-Instruct": 0.9066788313878769,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.8083069247556524
        },
        "stackexchange_2025": {
            "01-ai/Yi-1.5-6B": 0.7432102796738009,
            "01-ai/Yi-1.5-9B": 0.7110020913432951,
            "01-ai/Yi-6B": 0.7524124254966688,
            "01-ai/Yi-9B": 0.7032258486143741,
            "EleutherAI/pythia-1.4b-deduped": 0.8466356651828703,
            "EleutherAI/pythia-12b": 0.7578376243431615,
            "EleutherAI/pythia-160m-deduped": 1.127059258675558,
            "EleutherAI/pythia-1b-deduped": 0.8760201781706881,
            "EleutherAI/pythia-2.8b-deduped": 0.8035730488512066,
            "EleutherAI/pythia-410m-deduped": 0.9454629733759992,
            "EleutherAI/pythia-6.9b-deduped": 0.7767348273065674,
            "EleutherAI/pythia-70m-deduped": 1.283367195292987,
            "Qwen/Qwen1.5-0.5B": 0.8911210717812429,
            "Qwen/Qwen1.5-1.8B": 0.8046741132210025,
            "Qwen/Qwen1.5-14B": 0.6680981163258594,
            "Qwen/Qwen1.5-4B": 0.7440313583414766,
            "Qwen/Qwen1.5-7B": 0.6924296302334431,
            "Qwen/Qwen2-0.5B": 0.8522685151720497,
            "Qwen/Qwen2-1.5B": 0.7588936729181054,
            "Qwen/Qwen2-7B": 0.668515273055866,
            "Qwen/Qwen2.5-0.5B": 0.792122958169581,
            "Qwen/Qwen2.5-1.5B": 0.699471741121523,
            "Qwen/Qwen2.5-14B": 0.5909516425631631,
            "Qwen/Qwen2.5-3B": 0.6718536745873227,
            "Qwen/Qwen2.5-7B": 0.6200147541308172,
            "meta-llama/Llama-3.1-8B": 0.6497575431133537,
            "meta-llama/Llama-3.2-1B": 0.778043308452052,
            "meta-llama/Llama-3.2-3B": 0.7012385464681585,
            "meta-llama/Meta-Llama-3-8B": 0.6511319761828666,
            "openai-community/gpt2": 1.2630661935626148,
            "openai-community/gpt2-large": 1.0620555499482935,
            "openai-community/gpt2-medium": 1.1262144970408028,
            "openai-community/gpt2-xl": 1.0196724480200525,
            "01-ai/Yi-1.5-6B-Chat": 0.744951321062894,
            "01-ai/Yi-1.5-9B-Chat": 0.7160430190010197,
            "01-ai/Yi-6B-Chat": 0.7526675341174087,
            "Qwen/Qwen1.5-0.5B-Chat": 1.0803171190636358,
            "Qwen/Qwen1.5-1.8B-Chat": 0.8346460634238881,
            "Qwen/Qwen1.5-14B-Chat": 0.6879989000261119,
            "Qwen/Qwen1.5-4B-Chat": 0.7650419104763634,
            "Qwen/Qwen1.5-7B-Chat": 0.7236490024812379,
            "Qwen/Qwen2-0.5B-Instruct": 0.8645595774859507,
            "Qwen/Qwen2-1.5B-Instruct": 0.7716066715336137,
            "Qwen/Qwen2-7B-Instruct": 0.6810129552245331,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.8110246238139677,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7139763260573175,
            "Qwen/Qwen2.5-14B-Instruct": 0.6158849853011623,
            "Qwen/Qwen2.5-3B-Instruct": 0.6826815458521754,
            "Qwen/Qwen2.5-7B-Instruct": 0.6441505553708736,
            "meta-llama/Llama-3.1-8B-Instruct": 0.6747965326706984,
            "meta-llama/Llama-3.2-1B-Instruct": 0.874991662945466,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7798887752520918,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.6861171323896127
        }
    },
    "direct_eval": {
        "mnli": {
            "google/gemma-2-2b": 0.4337238920020377,
            "Qwen/Qwen1.5-4B-Chat": 0.5685175751400917,
            "Qwen/Qwen1.5-14B-Chat": 0.7048395313295975,
            "Qwen/Qwen2-7B-Instruct": 0.6409577177789099,
            "01-ai/Yi-9B": 0.47345899133978603,
            "Qwen/Qwen2-1.5B": 0.40733571064696894,
            "EleutherAI/pythia-1b-deduped": 0.3412124299541518,
            "Qwen/Qwen2.5-7B-Instruct": 0.7242995415180845,
            "meta-llama/Llama-3.2-1B": 0.3580234335201223,
            "meta-llama/Meta-Llama-3-8B": 0.4836474783494651,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.41253183902190527,
            "01-ai/Yi-1.5-9B": 0.5163525216505349,
            "EleutherAI/pythia-1.4b-deduped": 0.31859398879266426,
            "Qwen/Qwen1.5-4B": 0.5209373408048905,
            "meta-llama/Llama-3.2-3B": 0.3444727457972491,
            "Qwen/Qwen1.5-0.5B-Chat": 0.4684666327050433,
            "EleutherAI/pythia-2.8b-deduped": 0.3617931737137035,
            "Qwen/Qwen2-0.5B": 0.4246561385634233,
            "01-ai/Yi-6B": 0.5320427916454407,
            "Qwen/Qwen1.5-7B-Chat": 0.6626591951095262,
            "Qwen/Qwen2.5-3B": 0.5515028018339276,
            "Qwen/Qwen2-0.5B-Instruct": 0.5298013245033113,
            "01-ai/Yi-6B-Chat": 0.4892511462047886,
            "google/gemma-7b-it": 0.5993886907794193,
            "Qwen/Qwen1.5-14B": 0.6013245033112583,
            "meta-llama/Llama-3.1-8B": 0.5316352521650535,
            "01-ai/Yi-1.5-6B-Chat": 0.6343352012226184,
            "EleutherAI/pythia-410m-deduped": 0.3495669893020886,
            "01-ai/Yi-1.5-9B-Chat": 0.6236372898624555,
            "Qwen/Qwen1.5-1.8B": 0.37982679572083544,
            "openai-community/gpt2-xl": 0.3653591441670912,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.5821701477330616,
            "google/gemma-2b-it": 0.5400916963830871,
            "google/gemma-7b": 0.43178807947019865,
            "meta-llama/Llama-3.1-8B-Instruct": 0.5790117167600611,
            "Qwen/Qwen2.5-14B-Instruct": 0.7604686704024453,
            "EleutherAI/pythia-160m-deduped": 0.3361181864493123,
            "meta-llama/Llama-3.2-1B-Instruct": 0.48181355068772286,
            "meta-llama/Llama-3.2-3B-Instruct": 0.5395822720326031,
            "openai-community/gpt2": 0.337238920020377,
            "Qwen/Qwen1.5-7B": 0.5827814569536424,
            "Qwen/Qwen2.5-0.5B": 0.3860417727967397,
            "Qwen/Qwen2.5-14B": 0.6709118695873663,
            "google/gemma-2-9b": 0.48619460010188487,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.6027508914926133,
            "Qwen/Qwen2.5-1.5B": 0.5249108507386653,
            "Qwen/Qwen2-1.5B-Instruct": 0.5163525216505349,
            "01-ai/Yi-1.5-6B": 0.544065206316862,
            "Qwen/Qwen1.5-0.5B": 0.3943963321446765,
            "openai-community/gpt2-large": 0.3590422822210902,
            "EleutherAI/pythia-6.9b-deduped": 0.38818135506877227,
            "openai-community/gpt2-medium": 0.35180845644421804,
            "Qwen/Qwen2.5-3B-Instruct": 0.6268976057055528,
            "google/gemma-2-9b-it": 0.6241467142129393,
            "google/gemma-2-2b-it": 0.5555781966377993,
            "Qwen/Qwen1.5-1.8B-Chat": 0.4991339786041773,
            "Qwen/Qwen2-7B": 0.5811512990320937,
            "google/gemma-2b": 0.4021395822720326,
            "EleutherAI/pythia-12b": 0.3740193581253184,
            "Qwen/Qwen2.5-7B": 0.6279164544065207,
            "EleutherAI/pythia-70m-deduped": 0.32766174223127864
        },
        "qqp": {
            "google/gemma-2-2b": 0.4577,
            "Qwen/Qwen1.5-4B-Chat": 0.7484,
            "Qwen/Qwen1.5-14B-Chat": 0.7932,
            "Qwen/Qwen2-7B-Instruct": 0.7722,
            "01-ai/Yi-9B": 0.7446,
            "Qwen/Qwen2-1.5B": 0.6332,
            "EleutherAI/pythia-1b-deduped": 0.3692,
            "Qwen/Qwen2.5-7B-Instruct": 0.8407,
            "meta-llama/Llama-3.2-1B": 0.4916,
            "meta-llama/Meta-Llama-3-8B": 0.4609,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.7025,
            "01-ai/Yi-1.5-9B": 0.4617,
            "EleutherAI/pythia-1.4b-deduped": 0.5656,
            "Qwen/Qwen1.5-4B": 0.7765,
            "meta-llama/Llama-3.2-3B": 0.3781,
            "Qwen/Qwen1.5-0.5B-Chat": 0.6317,
            "EleutherAI/pythia-2.8b-deduped": 0.4337,
            "Qwen/Qwen2-0.5B": 0.6322,
            "01-ai/Yi-6B": 0.3789,
            "Qwen/Qwen1.5-7B-Chat": 0.827,
            "Qwen/Qwen2.5-3B": 0.8535,
            "Qwen/Qwen2-0.5B-Instruct": 0.6617,
            "01-ai/Yi-6B-Chat": 0.7218,
            "google/gemma-7b-it": 0.4057,
            "Qwen/Qwen1.5-14B": 0.7765,
            "meta-llama/Llama-3.1-8B": 0.3983,
            "01-ai/Yi-1.5-6B-Chat": 0.7777,
            "EleutherAI/pythia-410m-deduped": 0.5212,
            "01-ai/Yi-1.5-9B-Chat": 0.8162,
            "Qwen/Qwen1.5-1.8B": 0.639,
            "openai-community/gpt2-xl": 0.3718,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7628,
            "google/gemma-2b-it": 0.4982,
            "google/gemma-7b": 0.5457,
            "meta-llama/Llama-3.1-8B-Instruct": 0.7462,
            "Qwen/Qwen2.5-14B-Instruct": 0.854,
            "EleutherAI/pythia-160m-deduped": 0.3687,
            "meta-llama/Llama-3.2-1B-Instruct": 0.5911,
            "meta-llama/Llama-3.2-3B-Instruct": 0.6461,
            "openai-community/gpt2": 0.374,
            "Qwen/Qwen1.5-7B": 0.8248,
            "Qwen/Qwen2.5-0.5B": 0.6815,
            "Qwen/Qwen2.5-14B": 0.866,
            "google/gemma-2-9b": 0.4051,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.8284,
            "Qwen/Qwen2.5-1.5B": 0.7541,
            "Qwen/Qwen2-1.5B-Instruct": 0.7547,
            "01-ai/Yi-1.5-6B": 0.5826,
            "Qwen/Qwen1.5-0.5B": 0.6322,
            "openai-community/gpt2-large": 0.3746,
            "EleutherAI/pythia-6.9b-deduped": 0.3681,
            "openai-community/gpt2-medium": 0.3678,
            "Qwen/Qwen2.5-3B-Instruct": 0.8232,
            "google/gemma-2-9b-it": 0.7605,
            "google/gemma-2-2b-it": 0.7411,
            "Qwen/Qwen1.5-1.8B-Chat": 0.7011,
            "Qwen/Qwen2-7B": 0.7705,
            "google/gemma-2b": 0.3706,
            "EleutherAI/pythia-12b": 0.4097,
            "Qwen/Qwen2.5-7B": 0.8594,
            "EleutherAI/pythia-70m-deduped": 0.3676
        },
        "medmcqa": {
            "google/gemma-2-2b": 0.4030600047812575,
            "Qwen/Qwen1.5-4B-Chat": 0.42385847477886684,
            "Qwen/Qwen1.5-14B-Chat": 0.49629452546019603,
            "Qwen/Qwen2-7B-Instruct": 0.5503227348792733,
            "01-ai/Yi-9B": 0.5302414535022711,
            "Qwen/Qwen2-1.5B": 0.4111881424814726,
            "EleutherAI/pythia-1b-deduped": 0.3038489122639254,
            "Qwen/Qwen2.5-7B-Instruct": 0.5634711929237389,
            "meta-llama/Llama-3.2-1B": 0.3638536935213961,
            "meta-llama/Meta-Llama-3-8B": 0.5828352856801339,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.36361463064786037,
            "01-ai/Yi-1.5-9B": 0.527611761893378,
            "EleutherAI/pythia-1.4b-deduped": 0.3098254841023189,
            "Qwen/Qwen1.5-4B": 0.43772412144393974,
            "meta-llama/Llama-3.2-3B": 0.50729141764284,
            "Qwen/Qwen1.5-0.5B-Chat": 0.318909873296677,
            "EleutherAI/pythia-2.8b-deduped": 0.2596222806598135,
            "Qwen/Qwen2-0.5B": 0.3435333492708582,
            "01-ai/Yi-6B": 0.46569447764762134,
            "Qwen/Qwen1.5-7B-Chat": 0.45350227109729857,
            "Qwen/Qwen2.5-3B": 0.526655510399235,
            "Qwen/Qwen2-0.5B-Instruct": 0.35142242409753766,
            "01-ai/Yi-6B-Chat": 0.46999760937126467,
            "google/gemma-7b-it": 0.4219459717905809,
            "Qwen/Qwen1.5-14B": 0.5333492708582357,
            "meta-llama/Llama-3.1-8B": 0.5840306000478126,
            "01-ai/Yi-1.5-6B-Chat": 0.45876165431508487,
            "EleutherAI/pythia-410m-deduped": 0.32177862777910593,
            "01-ai/Yi-1.5-9B-Chat": 0.4884054506335166,
            "Qwen/Qwen1.5-1.8B": 0.36600525938321776,
            "openai-community/gpt2-xl": 0.3086301697346402,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.6067415730337079,
            "google/gemma-2b-it": 0.3449677265120727,
            "google/gemma-7b": 0.4896007650011953,
            "meta-llama/Llama-3.1-8B-Instruct": 0.5914415491274205,
            "Qwen/Qwen2.5-14B-Instruct": 0.6368634950992111,
            "EleutherAI/pythia-160m-deduped": 0.31436767869949794,
            "meta-llama/Llama-3.2-1B-Instruct": 0.4427444417881903,
            "meta-llama/Llama-3.2-3B-Instruct": 0.5519961749940234,
            "openai-community/gpt2": 0.318909873296677,
            "Qwen/Qwen1.5-7B": 0.5010757829309108,
            "Qwen/Qwen2.5-0.5B": 0.3662443222567535,
            "Qwen/Qwen2.5-14B": 0.6339947406167822,
            "google/gemma-2-9b": 0.5773368395888119,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.46569447764762134,
            "Qwen/Qwen2.5-1.5B": 0.46712885488883577,
            "Qwen/Qwen2-1.5B-Instruct": 0.4188381544346163,
            "01-ai/Yi-1.5-6B": 0.4884054506335166,
            "Qwen/Qwen1.5-0.5B": 0.32249581639971314,
            "openai-community/gpt2-large": 0.3169973703083911,
            "EleutherAI/pythia-6.9b-deduped": 0.21611283767630887,
            "openai-community/gpt2-medium": 0.3158020559407124,
            "Qwen/Qwen2.5-3B-Instruct": 0.5151804924695195,
            "google/gemma-2-9b-it": 0.5665790102797036,
            "google/gemma-2-2b-it": 0.42768348075543866,
            "Qwen/Qwen1.5-1.8B-Chat": 0.3511833612240019,
            "Qwen/Qwen2-7B": 0.5694477647621324,
            "google/gemma-2b": 0.2978723404255319,
            "EleutherAI/pythia-12b": 0.23021754721491752,
            "Qwen/Qwen2.5-7B": 0.6002868754482429,
            "EleutherAI/pythia-70m-deduped": 0.32034425053789145
        },
        "qnli": {
            "google/gemma-2-2b": 0.5550064067362255,
            "Qwen/Qwen1.5-4B-Chat": 0.7512355848434926,
            "Qwen/Qwen1.5-14B-Chat": 0.8123741533955702,
            "Qwen/Qwen2-7B-Instruct": 0.6650192202086765,
            "01-ai/Yi-9B": 0.547318323265605,
            "Qwen/Qwen2-1.5B": 0.5680029287937031,
            "EleutherAI/pythia-1b-deduped": 0.49478308621636463,
            "Qwen/Qwen2.5-7B-Instruct": 0.8348892549881017,
            "meta-llama/Llama-3.2-1B": 0.5110745011898224,
            "meta-llama/Meta-Llama-3-8B": 0.4984440783452316,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.537799743730551,
            "01-ai/Yi-1.5-9B": 0.5185795350539997,
            "EleutherAI/pythia-1.4b-deduped": 0.5086948563060589,
            "Qwen/Qwen1.5-4B": 0.6655683690280065,
            "meta-llama/Llama-3.2-3B": 0.4977118799194582,
            "Qwen/Qwen1.5-0.5B-Chat": 0.5453047775947282,
            "EleutherAI/pythia-2.8b-deduped": 0.5132710964671426,
            "Qwen/Qwen2-0.5B": 0.5570199524071023,
            "01-ai/Yi-6B": 0.5447556287753982,
            "Qwen/Qwen1.5-7B-Chat": 0.7318323265604979,
            "Qwen/Qwen2.5-3B": 0.6723412044664104,
            "Qwen/Qwen2-0.5B-Instruct": 0.5451217279882848,
            "01-ai/Yi-6B-Chat": 0.5028372688998719,
            "google/gemma-7b-it": 0.7589236683141132,
            "Qwen/Qwen1.5-14B": 0.6661175178473366,
            "meta-llama/Llama-3.1-8B": 0.49679663188724144,
            "01-ai/Yi-1.5-6B-Chat": 0.6857038257367747,
            "EleutherAI/pythia-410m-deduped": 0.5015559216547685,
            "01-ai/Yi-1.5-9B-Chat": 0.8407468423942889,
            "Qwen/Qwen1.5-1.8B": 0.5451217279882848,
            "openai-community/gpt2-xl": 0.5143693941058026,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7547135273659161,
            "google/gemma-2b-it": 0.6906461651107451,
            "google/gemma-7b": 0.5145524437122461,
            "meta-llama/Llama-3.1-8B-Instruct": 0.6463481603514553,
            "Qwen/Qwen2.5-14B-Instruct": 0.8495332235035694,
            "EleutherAI/pythia-160m-deduped": 0.4933186893648179,
            "meta-llama/Llama-3.2-1B-Instruct": 0.5723961193483434,
            "meta-llama/Llama-3.2-3B-Instruct": 0.6159619256818598,
            "openai-community/gpt2": 0.5017389712612118,
            "Qwen/Qwen1.5-7B": 0.5912502288120081,
            "Qwen/Qwen2.5-0.5B": 0.5487827201171518,
            "Qwen/Qwen2.5-14B": 0.6622734761120264,
            "google/gemma-2-9b": 0.49478308621636463,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.6558667398865092,
            "Qwen/Qwen2.5-1.5B": 0.5500640673622552,
            "Qwen/Qwen2-1.5B-Instruct": 0.5500640673622552,
            "01-ai/Yi-1.5-6B": 0.6060772469339191,
            "Qwen/Qwen1.5-0.5B": 0.5436573311367381,
            "openai-community/gpt2-large": 0.4935017389712612,
            "EleutherAI/pythia-6.9b-deduped": 0.5205930807248764,
            "openai-community/gpt2-medium": 0.49441698700347797,
            "Qwen/Qwen2.5-3B-Instruct": 0.7968149368478857,
            "google/gemma-2-9b-it": 0.8520959179937763,
            "google/gemma-2-2b-it": 0.7508694856306058,
            "Qwen/Qwen1.5-1.8B-Chat": 0.5414607358594179,
            "Qwen/Qwen2-7B": 0.5879553358960278,
            "google/gemma-2b": 0.5196778326926597,
            "EleutherAI/pythia-12b": 0.5165659893831228,
            "Qwen/Qwen2.5-7B": 0.653670144609189,
            "EleutherAI/pythia-70m-deduped": 0.4946000366099213
        },
        "nq_open": {
            "google/gemma-2-2b": 0.15734072022160664,
            "Qwen/Qwen1.5-4B-Chat": 0.014404432132963989,
            "Qwen/Qwen1.5-14B-Chat": 0.000554016620498615,
            "Qwen/Qwen2-7B-Instruct": 0.01301939058171745,
            "01-ai/Yi-9B": 0.19889196675900278,
            "Qwen/Qwen2-1.5B": 0.000554016620498615,
            "EleutherAI/pythia-1b-deduped": 0.02299168975069252,
            "Qwen/Qwen2.5-7B-Instruct": 0.04598337950138504,
            "meta-llama/Llama-3.2-1B": 0.058725761772853186,
            "meta-llama/Meta-Llama-3-8B": 0.21745152354570638,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.020221606648199445,
            "01-ai/Yi-1.5-9B": 0.1481994459833795,
            "EleutherAI/pythia-1.4b-deduped": 0.028254847645429362,
            "Qwen/Qwen1.5-4B": 0.0008310249307479224,
            "meta-llama/Llama-3.2-3B": 0.16537396121883657,
            "Qwen/Qwen1.5-0.5B-Chat": 0.002493074792243767,
            "EleutherAI/pythia-2.8b-deduped": 0.03822714681440443,
            "Qwen/Qwen2-0.5B": 0.005817174515235457,
            "01-ai/Yi-6B": 0.20221606648199447,
            "Qwen/Qwen1.5-7B-Chat": 0.0002770083102493075,
            "Qwen/Qwen2.5-3B": 0.16509695290858725,
            "Qwen/Qwen2-0.5B-Instruct": 0.025761772853185594,
            "01-ai/Yi-6B-Chat": 0.011634349030470914,
            "google/gemma-7b-it": 0.09168975069252078,
            "Qwen/Qwen1.5-14B": 0.00110803324099723,
            "meta-llama/Llama-3.1-8B": 0.196398891966759,
            "01-ai/Yi-1.5-6B-Chat": 0.025761772853185594,
            "EleutherAI/pythia-410m-deduped": 0.006648199445983379,
            "01-ai/Yi-1.5-9B-Chat": 0.009695290858725761,
            "Qwen/Qwen1.5-1.8B": 0.000554016620498615,
            "openai-community/gpt2-xl": 0.023545706371191136,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.14265927977839335,
            "google/gemma-2b-it": 0.03407202216066482,
            "google/gemma-7b": 0.21578947368421053,
            "meta-llama/Llama-3.1-8B-Instruct": 0.17590027700831026,
            "Qwen/Qwen2.5-14B-Instruct": 0.047922437673130196,
            "EleutherAI/pythia-160m-deduped": 0.0019390581717451524,
            "meta-llama/Llama-3.2-1B-Instruct": 0.046814404432132965,
            "meta-llama/Llama-3.2-3B-Instruct": 0.1700831024930748,
            "openai-community/gpt2": 0.00221606648199446,
            "Qwen/Qwen1.5-7B": 0.0019390581717451524,
            "Qwen/Qwen2.5-0.5B": 0.04764542936288089,
            "Qwen/Qwen2.5-14B": 0.26011080332409975,
            "google/gemma-2-9b": 0.26038781163434904,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.04293628808864266,
            "Qwen/Qwen2.5-1.5B": 0.0778393351800554,
            "Qwen/Qwen2-1.5B-Instruct": 0.009141274238227148,
            "01-ai/Yi-1.5-6B": 0.17756232686980608,
            "Qwen/Qwen1.5-0.5B": 0.000554016620498615,
            "openai-community/gpt2-large": 0.013573407202216066,
            "EleutherAI/pythia-6.9b-deduped": 0.04626038781163435,
            "openai-community/gpt2-medium": 0.008587257617728532,
            "Qwen/Qwen2.5-3B-Instruct": 0.009141274238227148,
            "google/gemma-2-9b-it": 0.12825484764542935,
            "google/gemma-2-2b-it": 0.1077562326869806,
            "Qwen/Qwen1.5-1.8B-Chat": 0.008587257617728532,
            "Qwen/Qwen2-7B": 0.01218836565096953,
            "google/gemma-2b": 0.10554016620498614,
            "EleutherAI/pythia-12b": 0.05900277008310249,
            "Qwen/Qwen2.5-7B": 0.23185595567867037,
            "EleutherAI/pythia-70m-deduped": 0.0
        },
        "sst2": {
            "google/gemma-2-2b": 0.6938073394495413,
            "Qwen/Qwen1.5-4B-Chat": 0.9174311926605505,
            "Qwen/Qwen1.5-14B-Chat": 0.9403669724770642,
            "Qwen/Qwen2-7B-Instruct": 0.9220183486238532,
            "01-ai/Yi-9B": 0.9334862385321101,
            "Qwen/Qwen2-1.5B": 0.8979357798165137,
            "EleutherAI/pythia-1b-deduped": 0.6536697247706422,
            "Qwen/Qwen2.5-7B-Instruct": 0.9357798165137615,
            "meta-llama/Llama-3.2-1B": 0.6158256880733946,
            "meta-llama/Meta-Llama-3-8B": 0.6456422018348624,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.7626146788990825,
            "01-ai/Yi-1.5-9B": 0.9151376146788991,
            "EleutherAI/pythia-1.4b-deduped": 0.5149082568807339,
            "Qwen/Qwen1.5-4B": 0.9002293577981652,
            "meta-llama/Llama-3.2-3B": 0.7110091743119266,
            "Qwen/Qwen1.5-0.5B-Chat": 0.8130733944954128,
            "EleutherAI/pythia-2.8b-deduped": 0.7270642201834863,
            "Qwen/Qwen2-0.5B": 0.7580275229357798,
            "01-ai/Yi-6B": 0.930045871559633,
            "Qwen/Qwen1.5-7B-Chat": 0.9323394495412844,
            "Qwen/Qwen2.5-3B": 0.9013761467889908,
            "Qwen/Qwen2-0.5B-Instruct": 0.7649082568807339,
            "01-ai/Yi-6B-Chat": 0.9231651376146789,
            "google/gemma-7b-it": 0.9174311926605505,
            "Qwen/Qwen1.5-14B": 0.9403669724770642,
            "meta-llama/Llama-3.1-8B": 0.6846330275229358,
            "01-ai/Yi-1.5-6B-Chat": 0.9243119266055045,
            "EleutherAI/pythia-410m-deduped": 0.694954128440367,
            "01-ai/Yi-1.5-9B-Chat": 0.9128440366972477,
            "Qwen/Qwen1.5-1.8B": 0.6192660550458715,
            "openai-community/gpt2-xl": 0.4908256880733945,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.9288990825688074,
            "google/gemma-2b-it": 0.7522935779816514,
            "google/gemma-7b": 0.7603211009174312,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8635321100917431,
            "Qwen/Qwen2.5-14B-Instruct": 0.9220183486238532,
            "EleutherAI/pythia-160m-deduped": 0.5091743119266054,
            "meta-llama/Llama-3.2-1B-Instruct": 0.7087155963302753,
            "meta-llama/Llama-3.2-3B-Instruct": 0.8681192660550459,
            "openai-community/gpt2": 0.5504587155963303,
            "Qwen/Qwen1.5-7B": 0.9071100917431193,
            "Qwen/Qwen2.5-0.5B": 0.5412844036697247,
            "Qwen/Qwen2.5-14B": 0.8956422018348624,
            "google/gemma-2-9b": 0.8577981651376146,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.8944954128440367,
            "Qwen/Qwen2.5-1.5B": 0.8841743119266054,
            "Qwen/Qwen2-1.5B-Instruct": 0.8761467889908257,
            "01-ai/Yi-1.5-6B": 0.8669724770642202,
            "Qwen/Qwen1.5-0.5B": 0.4908256880733945,
            "openai-community/gpt2-large": 0.5,
            "EleutherAI/pythia-6.9b-deduped": 0.5217889908256881,
            "openai-community/gpt2-medium": 0.6135321100917431,
            "Qwen/Qwen2.5-3B-Instruct": 0.8876146788990825,
            "google/gemma-2-9b-it": 0.9208715596330275,
            "google/gemma-2-2b-it": 0.9220183486238532,
            "Qwen/Qwen1.5-1.8B-Chat": 0.8612385321100917,
            "Qwen/Qwen2-7B": 0.926605504587156,
            "google/gemma-2b": 0.5607798165137615,
            "EleutherAI/pythia-12b": 0.6181192660550459,
            "Qwen/Qwen2.5-7B": 0.9185779816513762,
            "EleutherAI/pythia-70m-deduped": 0.49655963302752293
        },
        "winogrande": {
            "google/gemma-2-2b": 0.6858721389108129,
            "Qwen/Qwen1.5-4B-Chat": 0.6661404893449092,
            "Qwen/Qwen1.5-14B-Chat": 0.6898184688239937,
            "Qwen/Qwen2-7B-Instruct": 0.7008681925808997,
            "01-ai/Yi-9B": 0.7277032359905288,
            "Qwen/Qwen2-1.5B": 0.65982636148382,
            "EleutherAI/pythia-1b-deduped": 0.5280189423835833,
            "Qwen/Qwen2.5-7B-Instruct": 0.7063930544593529,
            "meta-llama/Llama-3.2-1B": 0.6093133385951065,
            "meta-llama/Meta-Llama-3-8B": 0.7403314917127072,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.5595895816890292,
            "01-ai/Yi-1.5-9B": 0.7332280978689818,
            "EleutherAI/pythia-1.4b-deduped": 0.5651144435674822,
            "Qwen/Qwen1.5-4B": 0.6424625098658248,
            "meta-llama/Llama-3.2-3B": 0.6953433307024467,
            "Qwen/Qwen1.5-0.5B-Chat": 0.5501183898973955,
            "EleutherAI/pythia-2.8b-deduped": 0.584846093133386,
            "Qwen/Qwen2-0.5B": 0.5737963693764798,
            "01-ai/Yi-6B": 0.7095501183898973,
            "Qwen/Qwen1.5-7B-Chat": 0.6527229676400947,
            "Qwen/Qwen2.5-3B": 0.6850828729281768,
            "Qwen/Qwen2-0.5B-Instruct": 0.5595895816890292,
            "01-ai/Yi-6B-Chat": 0.7142857142857143,
            "google/gemma-7b-it": 0.6866614048934491,
            "Qwen/Qwen1.5-14B": 0.7095501183898973,
            "meta-llama/Llama-3.1-8B": 0.7458563535911602,
            "01-ai/Yi-1.5-6B-Chat": 0.712707182320442,
            "EleutherAI/pythia-410m-deduped": 0.5343330702446725,
            "01-ai/Yi-1.5-9B-Chat": 0.749802683504341,
            "Qwen/Qwen1.5-1.8B": 0.6108918705603789,
            "openai-community/gpt2-xl": 0.5832675611681136,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7158642462509865,
            "google/gemma-2b-it": 0.6266771902131019,
            "google/gemma-7b": 0.7513812154696132,
            "meta-llama/Llama-3.1-8B-Instruct": 0.7355958958168903,
            "Qwen/Qwen2.5-14B-Instruct": 0.7600631412786109,
            "EleutherAI/pythia-160m-deduped": 0.4956590370955012,
            "meta-llama/Llama-3.2-1B-Instruct": 0.6140489344909235,
            "meta-llama/Llama-3.2-3B-Instruct": 0.6866614048934491,
            "openai-community/gpt2": 0.516179952644041,
            "Qwen/Qwen1.5-7B": 0.6606156274664562,
            "Qwen/Qwen2.5-0.5B": 0.5643251775848461,
            "Qwen/Qwen2.5-14B": 0.7521704814522494,
            "google/gemma-2-9b": 0.7419100236779794,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.6282557221783741,
            "Qwen/Qwen2.5-1.5B": 0.6337805840568271,
            "Qwen/Qwen2-1.5B-Instruct": 0.6511444356748224,
            "01-ai/Yi-1.5-6B": 0.7198105761641673,
            "Qwen/Qwen1.5-0.5B": 0.5524861878453039,
            "openai-community/gpt2-large": 0.55327545382794,
            "EleutherAI/pythia-6.9b-deduped": 0.6266771902131019,
            "openai-community/gpt2-medium": 0.5311760063141279,
            "Qwen/Qwen2.5-3B-Instruct": 0.691397000789266,
            "google/gemma-2-9b-it": 0.760852407261247,
            "google/gemma-2-2b-it": 0.6961325966850829,
            "Qwen/Qwen1.5-1.8B-Chat": 0.5951065509076559,
            "Qwen/Qwen2-7B": 0.7237569060773481,
            "google/gemma-2b": 0.648776637726914,
            "EleutherAI/pythia-12b": 0.6385161799526441,
            "Qwen/Qwen2.5-7B": 0.7292817679558011,
            "EleutherAI/pythia-70m-deduped": 0.4861878453038674
        },
        "hellaswag": {
            "google/gemma-2-2b": 0.7295,
            "Qwen/Qwen1.5-4B-Chat": 0.6952,
            "Qwen/Qwen1.5-14B-Chat": 0.802,
            "Qwen/Qwen2-7B-Instruct": 0.8065,
            "01-ai/Yi-9B": 0.7582,
            "Qwen/Qwen2-1.5B": 0.6539,
            "EleutherAI/pythia-1b-deduped": 0.4907,
            "Qwen/Qwen2.5-7B-Instruct": 0.8047,
            "meta-llama/Llama-3.2-1B": 0.6421,
            "meta-llama/Meta-Llama-3-8B": 0.792,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.5242,
            "01-ai/Yi-1.5-9B": 0.779,
            "EleutherAI/pythia-1.4b-deduped": 0.5429,
            "Qwen/Qwen1.5-4B": 0.714,
            "meta-llama/Llama-3.2-3B": 0.7416,
            "Qwen/Qwen1.5-0.5B-Chat": 0.4442,
            "EleutherAI/pythia-2.8b-deduped": 0.5942,
            "Qwen/Qwen2-0.5B": 0.4901,
            "01-ai/Yi-6B": 0.7497,
            "Qwen/Qwen1.5-7B-Chat": 0.77,
            "Qwen/Qwen2.5-3B": 0.7354,
            "Qwen/Qwen2-0.5B-Instruct": 0.4996,
            "01-ai/Yi-6B-Chat": 0.7562,
            "google/gemma-7b-it": 0.7283,
            "Qwen/Qwen1.5-14B": 0.7939,
            "meta-llama/Llama-3.1-8B": 0.7929,
            "01-ai/Yi-1.5-6B-Chat": 0.7669,
            "EleutherAI/pythia-410m-deduped": 0.4127,
            "01-ai/Yi-1.5-9B-Chat": 0.787,
            "Qwen/Qwen1.5-1.8B": 0.6094,
            "openai-community/gpt2-xl": 0.5086,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7555,
            "google/gemma-2b-it": 0.6411,
            "google/gemma-7b": 0.8092,
            "meta-llama/Llama-3.1-8B-Instruct": 0.7948,
            "Qwen/Qwen2.5-14B-Instruct": 0.8431,
            "EleutherAI/pythia-160m-deduped": 0.3132,
            "meta-llama/Llama-3.2-1B-Instruct": 0.6171,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7168,
            "openai-community/gpt2": 0.3111,
            "Qwen/Qwen1.5-7B": 0.7695,
            "Qwen/Qwen2.5-0.5B": 0.521,
            "Qwen/Qwen2.5-14B": 0.8288,
            "google/gemma-2-9b": 0.7983,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.6833,
            "Qwen/Qwen2.5-1.5B": 0.6775,
            "Qwen/Qwen2-1.5B-Instruct": 0.6582,
            "01-ai/Yi-1.5-6B": 0.7535,
            "Qwen/Qwen1.5-0.5B": 0.4921,
            "openai-community/gpt2-large": 0.4532,
            "EleutherAI/pythia-6.9b-deduped": 0.6589,
            "openai-community/gpt2-medium": 0.3934,
            "Qwen/Qwen2.5-3B-Instruct": 0.7503,
            "google/gemma-2-9b-it": 0.8007,
            "google/gemma-2-2b-it": 0.7255,
            "Qwen/Qwen1.5-1.8B-Chat": 0.5993,
            "Qwen/Qwen2-7B": 0.7876,
            "google/gemma-2b": 0.7142,
            "EleutherAI/pythia-12b": 0.6743,
            "Qwen/Qwen2.5-7B": 0.7894,
            "EleutherAI/pythia-70m-deduped": 0.2757
        },
        "social_iqa": {
            "google/gemma-2-2b": 0.5133060388945753,
            "Qwen/Qwen1.5-4B-Chat": 0.4687819856704197,
            "Qwen/Qwen1.5-14B-Chat": 0.5174002047082907,
            "Qwen/Qwen2-7B-Instruct": 0.5235414534288638,
            "01-ai/Yi-9B": 0.529682702149437,
            "Qwen/Qwen2-1.5B": 0.4580348004094166,
            "EleutherAI/pythia-1b-deduped": 0.40276356192425794,
            "Qwen/Qwen2.5-7B-Instruct": 0.5174002047082907,
            "meta-llama/Llama-3.2-1B": 0.4273285568065507,
            "meta-llama/Meta-Llama-3-8B": 0.4657113613101331,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.46827021494370524,
            "01-ai/Yi-1.5-9B": 0.5214943705220061,
            "EleutherAI/pythia-1.4b-deduped": 0.3991811668372569,
            "Qwen/Qwen1.5-4B": 0.49334698055271237,
            "meta-llama/Llama-3.2-3B": 0.4672466734902764,
            "Qwen/Qwen1.5-0.5B-Chat": 0.4216990788126919,
            "EleutherAI/pythia-2.8b-deduped": 0.4083930399181167,
            "Qwen/Qwen2-0.5B": 0.42681678607983625,
            "01-ai/Yi-6B": 0.4841351074718526,
            "Qwen/Qwen1.5-7B-Chat": 0.5158648925281474,
            "Qwen/Qwen2.5-3B": 0.5,
            "Qwen/Qwen2-0.5B-Instruct": 0.43091095189355166,
            "01-ai/Yi-6B-Chat": 0.49590583418628453,
            "google/gemma-7b-it": 0.4662231320368475,
            "Qwen/Qwen1.5-14B": 0.5322415557830092,
            "meta-llama/Llama-3.1-8B": 0.4836233367451382,
            "01-ai/Yi-1.5-6B-Chat": 0.49488229273285567,
            "EleutherAI/pythia-410m-deduped": 0.4002047082906858,
            "01-ai/Yi-1.5-9B-Chat": 0.5455475946775844,
            "Qwen/Qwen1.5-1.8B": 0.4518935516888434,
            "openai-community/gpt2-xl": 0.40276356192425794,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.5076765609007164,
            "google/gemma-2b-it": 0.4718526100307062,
            "google/gemma-7b": 0.48771750255885365,
            "meta-llama/Llama-3.1-8B-Instruct": 0.4969293756397134,
            "Qwen/Qwen2.5-14B-Instruct": 0.5419651995905834,
            "EleutherAI/pythia-160m-deduped": 0.3751279426816786,
            "meta-llama/Llama-3.2-1B-Instruct": 0.43244626407369496,
            "meta-llama/Llama-3.2-3B-Instruct": 0.46980552712384854,
            "openai-community/gpt2": 0.3664278403275333,
            "Qwen/Qwen1.5-7B": 0.5168884339815762,
            "Qwen/Qwen2.5-0.5B": 0.4421699078812692,
            "Qwen/Qwen2.5-14B": 0.5516888433981576,
            "google/gemma-2-9b": 0.5557830092118731,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.5025588536335721,
            "Qwen/Qwen2.5-1.5B": 0.48925281473899696,
            "Qwen/Qwen2-1.5B-Instruct": 0.49437052200614123,
            "01-ai/Yi-1.5-6B": 0.4795291709314227,
            "Qwen/Qwen1.5-0.5B": 0.4227226202661208,
            "openai-community/gpt2-large": 0.3955987717502559,
            "EleutherAI/pythia-6.9b-deduped": 0.42374616171954965,
            "openai-community/gpt2-medium": 0.390992835209826,
            "Qwen/Qwen2.5-3B-Instruct": 0.5204708290685772,
            "google/gemma-2-9b-it": 0.5762538382804504,
            "google/gemma-2-2b-it": 0.49948822927328557,
            "Qwen/Qwen1.5-1.8B-Chat": 0.44472876151484136,
            "Qwen/Qwen2-7B": 0.48618219037871035,
            "google/gemma-2b": 0.48311156601842375,
            "EleutherAI/pythia-12b": 0.4293756397134084,
            "Qwen/Qwen2.5-7B": 0.5481064483111566,
            "EleutherAI/pythia-70m-deduped": 0.35977482088024565
        },
        "mathqa": {
            "google/gemma-2-2b": 0.33098827470686765,
            "Qwen/Qwen1.5-4B-Chat": 0.3269681742043551,
            "Qwen/Qwen1.5-14B-Chat": 0.3932998324958124,
            "Qwen/Qwen2-7B-Instruct": 0.4201005025125628,
            "01-ai/Yi-9B": 0.39095477386934674,
            "Qwen/Qwen2-1.5B": 0.3165829145728643,
            "EleutherAI/pythia-1b-deduped": 0.24355108877721943,
            "Qwen/Qwen2.5-7B-Instruct": 0.4040201005025126,
            "meta-llama/Llama-3.2-1B": 0.28743718592964823,
            "meta-llama/Meta-Llama-3-8B": 0.39597989949748746,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.297822445561139,
            "01-ai/Yi-1.5-9B": 0.44254606365159127,
            "EleutherAI/pythia-1.4b-deduped": 0.24857621440536012,
            "Qwen/Qwen1.5-4B": 0.32160804020100503,
            "meta-llama/Llama-3.2-3B": 0.3403685092127303,
            "Qwen/Qwen1.5-0.5B-Chat": 0.26700167504187605,
            "EleutherAI/pythia-2.8b-deduped": 0.24656616415410385,
            "Qwen/Qwen2-0.5B": 0.26566164154103855,
            "01-ai/Yi-6B": 0.3410385259631491,
            "Qwen/Qwen1.5-7B-Chat": 0.38927973199329985,
            "Qwen/Qwen2.5-3B": 0.37286432160804023,
            "Qwen/Qwen2-0.5B-Instruct": 0.2663316582914573,
            "01-ai/Yi-6B-Chat": 0.34003350083752093,
            "google/gemma-7b-it": 0.3507537688442211,
            "Qwen/Qwen1.5-14B": 0.4113902847571189,
            "meta-llama/Llama-3.1-8B": 0.39731993299832497,
            "01-ai/Yi-1.5-6B-Chat": 0.40904522613065325,
            "EleutherAI/pythia-410m-deduped": 0.22981574539363483,
            "01-ai/Yi-1.5-9B-Chat": 0.44355108877721944,
            "Qwen/Qwen1.5-1.8B": 0.2981574539363484,
            "openai-community/gpt2-xl": 0.23819095477386934,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.41742043551088776,
            "google/gemma-2b-it": 0.32294807370184253,
            "google/gemma-7b": 0.38860971524288107,
            "meta-llama/Llama-3.1-8B-Instruct": 0.39028475711892796,
            "Qwen/Qwen2.5-14B-Instruct": 0.4844221105527638,
            "EleutherAI/pythia-160m-deduped": 0.21775544388609716,
            "meta-llama/Llama-3.2-1B-Instruct": 0.3303182579564489,
            "meta-llama/Llama-3.2-3B-Instruct": 0.37353433835845895,
            "openai-community/gpt2": 0.20904522613065327,
            "Qwen/Qwen1.5-7B": 0.37520938023450584,
            "Qwen/Qwen2.5-0.5B": 0.2891122278056951,
            "Qwen/Qwen2.5-14B": 0.5179229480737019,
            "google/gemma-2-9b": 0.4629815745393635,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.3430485762144054,
            "Qwen/Qwen2.5-1.5B": 0.35175879396984927,
            "Qwen/Qwen2-1.5B-Instruct": 0.3316582914572864,
            "01-ai/Yi-1.5-6B": 0.41708542713567837,
            "Qwen/Qwen1.5-0.5B": 0.26666666666666666,
            "openai-community/gpt2-large": 0.22311557788944725,
            "EleutherAI/pythia-6.9b-deduped": 0.2549413735343384,
            "openai-community/gpt2-medium": 0.22948073701842547,
            "Qwen/Qwen2.5-3B-Instruct": 0.33969849246231154,
            "google/gemma-2-9b-it": 0.42311557788944726,
            "google/gemma-2-2b-it": 0.3242881072026801,
            "Qwen/Qwen1.5-1.8B-Chat": 0.30318257956448913,
            "Qwen/Qwen2-7B": 0.42311557788944726,
            "google/gemma-2b": 0.31222780569514236,
            "EleutherAI/pythia-12b": 0.25326633165829143,
            "Qwen/Qwen2.5-7B": 0.4355108877721943,
            "EleutherAI/pythia-70m-deduped": 0.20402010050251257
        },
        "anli_r1": {
            "google/gemma-2-2b": 0.343,
            "Qwen/Qwen1.5-4B-Chat": 0.437,
            "Qwen/Qwen1.5-14B-Chat": 0.57,
            "Qwen/Qwen2-7B-Instruct": 0.608,
            "01-ai/Yi-9B": 0.53,
            "Qwen/Qwen2-1.5B": 0.363,
            "EleutherAI/pythia-1b-deduped": 0.332,
            "Qwen/Qwen2.5-7B-Instruct": 0.703,
            "meta-llama/Llama-3.2-1B": 0.356,
            "meta-llama/Meta-Llama-3-8B": 0.336,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.323,
            "01-ai/Yi-1.5-9B": 0.551,
            "EleutherAI/pythia-1.4b-deduped": 0.349,
            "Qwen/Qwen1.5-4B": 0.407,
            "meta-llama/Llama-3.2-3B": 0.342,
            "Qwen/Qwen1.5-0.5B-Chat": 0.357,
            "EleutherAI/pythia-2.8b-deduped": 0.327,
            "Qwen/Qwen2-0.5B": 0.293,
            "01-ai/Yi-6B": 0.424,
            "Qwen/Qwen1.5-7B-Chat": 0.576,
            "Qwen/Qwen2.5-3B": 0.467,
            "Qwen/Qwen2-0.5B-Instruct": 0.316,
            "01-ai/Yi-6B-Chat": 0.447,
            "google/gemma-7b-it": 0.536,
            "Qwen/Qwen1.5-14B": 0.513,
            "meta-llama/Llama-3.1-8B": 0.355,
            "01-ai/Yi-1.5-6B-Chat": 0.513,
            "EleutherAI/pythia-410m-deduped": 0.324,
            "01-ai/Yi-1.5-9B-Chat": 0.546,
            "Qwen/Qwen1.5-1.8B": 0.333,
            "openai-community/gpt2-xl": 0.337,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.515,
            "google/gemma-2b-it": 0.348,
            "google/gemma-7b": 0.425,
            "meta-llama/Llama-3.1-8B-Instruct": 0.527,
            "Qwen/Qwen2.5-14B-Instruct": 0.704,
            "EleutherAI/pythia-160m-deduped": 0.332,
            "meta-llama/Llama-3.2-1B-Instruct": 0.323,
            "meta-llama/Llama-3.2-3B-Instruct": 0.44,
            "openai-community/gpt2": 0.341,
            "Qwen/Qwen1.5-7B": 0.508,
            "Qwen/Qwen2.5-0.5B": 0.312,
            "Qwen/Qwen2.5-14B": 0.611,
            "google/gemma-2-9b": 0.426,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.447,
            "Qwen/Qwen2.5-1.5B": 0.402,
            "Qwen/Qwen2-1.5B-Instruct": 0.458,
            "01-ai/Yi-1.5-6B": 0.451,
            "Qwen/Qwen1.5-0.5B": 0.301,
            "openai-community/gpt2-large": 0.323,
            "EleutherAI/pythia-6.9b-deduped": 0.317,
            "openai-community/gpt2-medium": 0.336,
            "Qwen/Qwen2.5-3B-Instruct": 0.57,
            "google/gemma-2-9b-it": 0.703,
            "google/gemma-2-2b-it": 0.512,
            "Qwen/Qwen1.5-1.8B-Chat": 0.338,
            "Qwen/Qwen2-7B": 0.467,
            "google/gemma-2b": 0.34,
            "EleutherAI/pythia-12b": 0.31,
            "Qwen/Qwen2.5-7B": 0.53,
            "EleutherAI/pythia-70m-deduped": 0.329
        },
        "piqa": {
            "google/gemma-2-2b": 0.7916213275299239,
            "Qwen/Qwen1.5-4B-Chat": 0.7551686615886833,
            "Qwen/Qwen1.5-14B-Chat": 0.763873775843308,
            "Qwen/Qwen2-7B-Instruct": 0.8068552774755169,
            "01-ai/Yi-9B": 0.7927094668117519,
            "Qwen/Qwen2-1.5B": 0.7535364526659413,
            "EleutherAI/pythia-1b-deduped": 0.7023939064200218,
            "Qwen/Qwen2.5-7B-Instruct": 0.8035908596300326,
            "meta-llama/Llama-3.2-1B": 0.7486398258977149,
            "meta-llama/Meta-Llama-3-8B": 0.8063112078346029,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.7013057671381937,
            "01-ai/Yi-1.5-9B": 0.8079434167573449,
            "EleutherAI/pythia-1.4b-deduped": 0.7274211099020674,
            "Qwen/Qwen1.5-4B": 0.7704026115342764,
            "meta-llama/Llama-3.2-3B": 0.780739934711643,
            "Qwen/Qwen1.5-0.5B-Chat": 0.6653971708378672,
            "EleutherAI/pythia-2.8b-deduped": 0.7393906420021763,
            "Qwen/Qwen2-0.5B": 0.6931447225244831,
            "01-ai/Yi-6B": 0.7878128400435256,
            "Qwen/Qwen1.5-7B-Chat": 0.7589771490750816,
            "Qwen/Qwen2.5-3B": 0.7883569096844396,
            "Qwen/Qwen2-0.5B-Instruct": 0.6980413492927094,
            "01-ai/Yi-6B-Chat": 0.7633297062023939,
            "google/gemma-7b-it": 0.7758433079434167,
            "Qwen/Qwen1.5-14B": 0.7981501632208923,
            "meta-llama/Llama-3.1-8B": 0.8117519042437432,
            "01-ai/Yi-1.5-6B-Chat": 0.7883569096844396,
            "EleutherAI/pythia-410m-deduped": 0.6713819368879217,
            "01-ai/Yi-1.5-9B-Chat": 0.8019586507072906,
            "Qwen/Qwen1.5-1.8B": 0.7431991294885746,
            "openai-community/gpt2-xl": 0.705114254624592,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7883569096844396,
            "google/gemma-2b-it": 0.7529923830250272,
            "google/gemma-7b": 0.8220892274211099,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8144722524483133,
            "Qwen/Qwen2.5-14B-Instruct": 0.8182807399347116,
            "EleutherAI/pythia-160m-deduped": 0.6207834602829162,
            "meta-llama/Llama-3.2-1B-Instruct": 0.7480957562568009,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7704026115342764,
            "openai-community/gpt2": 0.6251360174102285,
            "Qwen/Qwen1.5-7B": 0.7921653971708379,
            "Qwen/Qwen2.5-0.5B": 0.6996735582154516,
            "Qwen/Qwen2.5-14B": 0.8210010881392819,
            "google/gemma-2-9b": 0.8297062023939065,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7600652883569097,
            "Qwen/Qwen2.5-1.5B": 0.7606093579978237,
            "Qwen/Qwen2-1.5B-Instruct": 0.7595212187159956,
            "01-ai/Yi-1.5-6B": 0.7992383025027203,
            "Qwen/Qwen1.5-0.5B": 0.6926006528835691,
            "openai-community/gpt2-large": 0.6920565832426551,
            "EleutherAI/pythia-6.9b-deduped": 0.7671381936887922,
            "openai-community/gpt2-medium": 0.6637649619151251,
            "Qwen/Qwen2.5-3B-Instruct": 0.7834602829162133,
            "google/gemma-2-9b-it": 0.8008705114254625,
            "google/gemma-2-2b-it": 0.794885745375408,
            "Qwen/Qwen1.5-1.8B-Chat": 0.7312295973884657,
            "Qwen/Qwen2-7B": 0.8101196953210011,
            "google/gemma-2b": 0.7834602829162133,
            "EleutherAI/pythia-12b": 0.7687704026115343,
            "Qwen/Qwen2.5-7B": 0.7970620239390642,
            "EleutherAI/pythia-70m-deduped": 0.5837867247007617
        },
        "sciq": {
            "google/gemma-2-2b": 0.957,
            "Qwen/Qwen1.5-4B-Chat": 0.766,
            "Qwen/Qwen1.5-14B-Chat": 0.873,
            "Qwen/Qwen2-7B-Instruct": 0.915,
            "01-ai/Yi-9B": 0.966,
            "Qwen/Qwen2-1.5B": 0.922,
            "EleutherAI/pythia-1b-deduped": 0.841,
            "Qwen/Qwen2.5-7B-Instruct": 0.937,
            "meta-llama/Llama-3.2-1B": 0.912,
            "meta-llama/Meta-Llama-3-8B": 0.946,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.88,
            "01-ai/Yi-1.5-9B": 0.954,
            "EleutherAI/pythia-1.4b-deduped": 0.776,
            "Qwen/Qwen1.5-4B": 0.898,
            "meta-llama/Llama-3.2-3B": 0.935,
            "Qwen/Qwen1.5-0.5B-Chat": 0.782,
            "EleutherAI/pythia-2.8b-deduped": 0.83,
            "Qwen/Qwen2-0.5B": 0.877,
            "01-ai/Yi-6B": 0.947,
            "Qwen/Qwen1.5-7B-Chat": 0.834,
            "Qwen/Qwen2.5-3B": 0.954,
            "Qwen/Qwen2-0.5B-Instruct": 0.884,
            "01-ai/Yi-6B-Chat": 0.854,
            "google/gemma-7b-it": 0.923,
            "Qwen/Qwen1.5-14B": 0.912,
            "meta-llama/Llama-3.1-8B": 0.956,
            "01-ai/Yi-1.5-6B-Chat": 0.934,
            "EleutherAI/pythia-410m-deduped": 0.742,
            "01-ai/Yi-1.5-9B-Chat": 0.954,
            "Qwen/Qwen1.5-1.8B": 0.894,
            "openai-community/gpt2-xl": 0.76,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.94,
            "google/gemma-2b-it": 0.871,
            "google/gemma-7b": 0.943,
            "meta-llama/Llama-3.1-8B-Instruct": 0.957,
            "Qwen/Qwen2.5-14B-Instruct": 0.936,
            "EleutherAI/pythia-160m-deduped": 0.639,
            "meta-llama/Llama-3.2-1B-Instruct": 0.921,
            "meta-llama/Llama-3.2-3B-Instruct": 0.934,
            "openai-community/gpt2": 0.644,
            "Qwen/Qwen1.5-7B": 0.872,
            "Qwen/Qwen2.5-0.5B": 0.904,
            "Qwen/Qwen2.5-14B": 0.956,
            "google/gemma-2-9b": 0.971,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.941,
            "Qwen/Qwen2.5-1.5B": 0.932,
            "Qwen/Qwen2-1.5B-Instruct": 0.924,
            "01-ai/Yi-1.5-6B": 0.941,
            "Qwen/Qwen1.5-0.5B": 0.826,
            "openai-community/gpt2-large": 0.693,
            "EleutherAI/pythia-6.9b-deduped": 0.861,
            "openai-community/gpt2-medium": 0.672,
            "Qwen/Qwen2.5-3B-Instruct": 0.913,
            "google/gemma-2-9b-it": 0.957,
            "google/gemma-2-2b-it": 0.923,
            "Qwen/Qwen1.5-1.8B-Chat": 0.87,
            "Qwen/Qwen2-7B": 0.935,
            "google/gemma-2b": 0.914,
            "EleutherAI/pythia-12b": 0.85,
            "Qwen/Qwen2.5-7B": 0.95,
            "EleutherAI/pythia-70m-deduped": 0.549
        },
        "commonsense_qa": {
            "google/gemma-2-2b": 0.5151515151515151,
            "Qwen/Qwen1.5-4B-Chat": 0.7444717444717445,
            "Qwen/Qwen1.5-14B-Chat": 0.8296478296478297,
            "Qwen/Qwen2-7B-Instruct": 0.80999180999181,
            "01-ai/Yi-9B": 0.7927927927927928,
            "Qwen/Qwen2-1.5B": 0.674037674037674,
            "EleutherAI/pythia-1b-deduped": 0.19328419328419327,
            "Qwen/Qwen2.5-7B-Instruct": 0.8255528255528255,
            "meta-llama/Llama-3.2-1B": 0.5184275184275184,
            "meta-llama/Meta-Llama-3-8B": 0.6961506961506961,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.5716625716625716,
            "01-ai/Yi-1.5-9B": 0.782964782964783,
            "EleutherAI/pythia-1.4b-deduped": 0.18755118755118755,
            "Qwen/Qwen1.5-4B": 0.7387387387387387,
            "meta-llama/Llama-3.2-3B": 0.6633906633906634,
            "Qwen/Qwen1.5-0.5B-Chat": 0.44471744471744473,
            "EleutherAI/pythia-2.8b-deduped": 0.20966420966420968,
            "Qwen/Qwen2-0.5B": 0.5053235053235053,
            "01-ai/Yi-6B": 0.7289107289107289,
            "Qwen/Qwen1.5-7B-Chat": 0.8050778050778051,
            "Qwen/Qwen2.5-3B": 0.7755937755937756,
            "Qwen/Qwen2-0.5B-Instruct": 0.5274365274365275,
            "01-ai/Yi-6B-Chat": 0.7583947583947583,
            "google/gemma-7b-it": 0.7002457002457002,
            "Qwen/Qwen1.5-14B": 0.8271908271908271,
            "meta-llama/Llama-3.1-8B": 0.7067977067977068,
            "01-ai/Yi-1.5-6B-Chat": 0.7542997542997543,
            "EleutherAI/pythia-410m-deduped": 0.19082719082719082,
            "01-ai/Yi-1.5-9B-Chat": 0.8083538083538083,
            "Qwen/Qwen1.5-1.8B": 0.6552006552006552,
            "openai-community/gpt2-xl": 0.19574119574119575,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7436527436527437,
            "google/gemma-2b-it": 0.5004095004095004,
            "google/gemma-7b": 0.588042588042588,
            "meta-llama/Llama-3.1-8B-Instruct": 0.76003276003276,
            "Qwen/Qwen2.5-14B-Instruct": 0.8419328419328419,
            "EleutherAI/pythia-160m-deduped": 0.1941031941031941,
            "meta-llama/Llama-3.2-1B-Instruct": 0.5864045864045864,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7395577395577395,
            "openai-community/gpt2": 0.19574119574119575,
            "Qwen/Qwen1.5-7B": 0.7993447993447993,
            "Qwen/Qwen2.5-0.5B": 0.5462735462735463,
            "Qwen/Qwen2.5-14B": 0.846027846027846,
            "google/gemma-2-9b": 0.6895986895986896,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7510237510237511,
            "Qwen/Qwen2.5-1.5B": 0.7477477477477478,
            "Qwen/Qwen2-1.5B-Instruct": 0.7076167076167076,
            "01-ai/Yi-1.5-6B": 0.7289107289107289,
            "Qwen/Qwen1.5-0.5B": 0.4668304668304668,
            "openai-community/gpt2-large": 0.19901719901719903,
            "EleutherAI/pythia-6.9b-deduped": 0.20638820638820637,
            "openai-community/gpt2-medium": 0.19492219492219492,
            "Qwen/Qwen2.5-3B-Instruct": 0.7895167895167895,
            "google/gemma-2-9b-it": 0.800982800982801,
            "google/gemma-2-2b-it": 0.7002457002457002,
            "Qwen/Qwen1.5-1.8B-Chat": 0.7051597051597052,
            "Qwen/Qwen2-7B": 0.8165438165438166,
            "google/gemma-2b": 0.2800982800982801,
            "EleutherAI/pythia-12b": 0.17526617526617527,
            "Qwen/Qwen2.5-7B": 0.8542178542178542,
            "EleutherAI/pythia-70m-deduped": 0.19656019656019655
        },
        "boolq": {
            "google/gemma-2-2b": 0.7363914373088685,
            "Qwen/Qwen1.5-4B-Chat": 0.7951070336391437,
            "Qwen/Qwen1.5-14B-Chat": 0.8663608562691132,
            "Qwen/Qwen2-7B-Instruct": 0.8648318042813455,
            "01-ai/Yi-9B": 0.8535168195718654,
            "Qwen/Qwen2-1.5B": 0.726605504587156,
            "EleutherAI/pythia-1b-deduped": 0.6085626911314985,
            "Qwen/Qwen2.5-7B-Instruct": 0.864525993883792,
            "meta-llama/Llama-3.2-1B": 0.6400611620795107,
            "meta-llama/Meta-Llama-3-8B": 0.8223241590214068,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.6639143730886851,
            "01-ai/Yi-1.5-9B": 0.8535168195718654,
            "EleutherAI/pythia-1.4b-deduped": 0.582262996941896,
            "Qwen/Qwen1.5-4B": 0.7779816513761468,
            "meta-llama/Llama-3.2-3B": 0.7409785932721713,
            "Qwen/Qwen1.5-0.5B-Chat": 0.4948012232415902,
            "EleutherAI/pythia-2.8b-deduped": 0.6440366972477064,
            "Qwen/Qwen2-0.5B": 0.6143730886850153,
            "01-ai/Yi-6B": 0.755045871559633,
            "Qwen/Qwen1.5-7B-Chat": 0.8519877675840979,
            "Qwen/Qwen2.5-3B": 0.7730886850152905,
            "Qwen/Qwen2-0.5B-Instruct": 0.6504587155963303,
            "01-ai/Yi-6B-Chat": 0.8290519877675842,
            "google/gemma-7b-it": 0.818348623853211,
            "Qwen/Qwen1.5-14B": 0.8553516819571866,
            "meta-llama/Llama-3.1-8B": 0.8318042813455657,
            "01-ai/Yi-1.5-6B-Chat": 0.8464831804281345,
            "EleutherAI/pythia-410m-deduped": 0.5819571865443425,
            "01-ai/Yi-1.5-9B-Chat": 0.881651376146789,
            "Qwen/Qwen1.5-1.8B": 0.6639143730886851,
            "openai-community/gpt2-xl": 0.617737003058104,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.84434250764526,
            "google/gemma-2b-it": 0.6363914373088685,
            "google/gemma-7b": 0.8333333333333334,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8538226299694189,
            "Qwen/Qwen2.5-14B-Instruct": 0.8801223241590214,
            "EleutherAI/pythia-160m-deduped": 0.5122324159021406,
            "meta-llama/Llama-3.2-1B-Instruct": 0.7131498470948012,
            "meta-llama/Llama-3.2-3B-Instruct": 0.789296636085627,
            "openai-community/gpt2": 0.4871559633027523,
            "Qwen/Qwen1.5-7B": 0.8247706422018348,
            "Qwen/Qwen2.5-0.5B": 0.6235474006116208,
            "Qwen/Qwen2.5-14B": 0.8529051987767584,
            "google/gemma-2-9b": 0.8397553516819571,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7801223241590214,
            "Qwen/Qwen2.5-1.5B": 0.7299694189602447,
            "Qwen/Qwen2-1.5B-Instruct": 0.7636085626911315,
            "01-ai/Yi-1.5-6B": 0.8042813455657493,
            "Qwen/Qwen1.5-0.5B": 0.5045871559633027,
            "openai-community/gpt2-large": 0.6048929663608563,
            "EleutherAI/pythia-6.9b-deduped": 0.6446483180428134,
            "openai-community/gpt2-medium": 0.5859327217125382,
            "Qwen/Qwen2.5-3B-Instruct": 0.8012232415902141,
            "google/gemma-2-9b-it": 0.8889908256880734,
            "google/gemma-2-2b-it": 0.8388379204892966,
            "Qwen/Qwen1.5-1.8B-Chat": 0.7394495412844037,
            "Qwen/Qwen2-7B": 0.8489296636085627,
            "google/gemma-2b": 0.6935779816513762,
            "EleutherAI/pythia-12b": 0.6718654434250765,
            "Qwen/Qwen2.5-7B": 0.8470948012232415,
            "EleutherAI/pythia-70m-deduped": 0.6201834862385321
        },
        "cola": {
            "google/gemma-2-2b": -0.09445766197949668,
            "Qwen/Qwen1.5-4B-Chat": 0.18252778020931956,
            "Qwen/Qwen1.5-14B-Chat": 0.2757733028139512,
            "Qwen/Qwen2-7B-Instruct": 0.26015749162243623,
            "01-ai/Yi-9B": 0.04765118573947667,
            "Qwen/Qwen2-1.5B": 0.07080473081055227,
            "EleutherAI/pythia-1b-deduped": 0.0,
            "Qwen/Qwen2.5-7B-Instruct": 0.39973604521075146,
            "meta-llama/Llama-3.2-1B": -0.023589227289894175,
            "meta-llama/Meta-Llama-3-8B": 0.00823665460608448,
            "Qwen/Qwen2.5-0.5B-Instruct": -0.007169428310789672,
            "01-ai/Yi-1.5-9B": 0.05164174103833181,
            "EleutherAI/pythia-1.4b-deduped": -0.04337864317162568,
            "Qwen/Qwen1.5-4B": 0.06513742181007601,
            "meta-llama/Llama-3.2-3B": -0.06304121165576894,
            "Qwen/Qwen1.5-0.5B-Chat": 0.051096648192392596,
            "EleutherAI/pythia-2.8b-deduped": 0.00286100001416597,
            "Qwen/Qwen2-0.5B": -0.03734239808153189,
            "01-ai/Yi-6B": 0.028735542333227265,
            "Qwen/Qwen1.5-7B-Chat": 0.3317278108908034,
            "Qwen/Qwen2.5-3B": 0.15677745345652094,
            "Qwen/Qwen2-0.5B-Instruct": 0.004969753950229529,
            "01-ai/Yi-6B-Chat": 0.23945393344577987,
            "google/gemma-7b-it": 0.043079231876207554,
            "Qwen/Qwen1.5-14B": 0.44322524287141646,
            "meta-llama/Llama-3.1-8B": 0.0521965015430992,
            "01-ai/Yi-1.5-6B-Chat": 0.2323370968956266,
            "EleutherAI/pythia-410m-deduped": 0.006970123547161724,
            "01-ai/Yi-1.5-9B-Chat": 0.3523220668858657,
            "Qwen/Qwen1.5-1.8B": 0.04198805607880316,
            "openai-community/gpt2-xl": 0.0,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.3026489736543776,
            "google/gemma-2b-it": 0.05209299552087377,
            "google/gemma-7b": 0.004969753950229529,
            "meta-llama/Llama-3.1-8B-Instruct": 0.15371097143232507,
            "Qwen/Qwen2.5-14B-Instruct": 0.5935102226878771,
            "EleutherAI/pythia-160m-deduped": 0.0,
            "meta-llama/Llama-3.2-1B-Instruct": 0.061984654931636324,
            "meta-llama/Llama-3.2-3B-Instruct": 0.14162820848759872,
            "openai-community/gpt2": 0.012634604474917733,
            "Qwen/Qwen1.5-7B": 0.23760933190411845,
            "Qwen/Qwen2.5-0.5B": 0.055363200855729496,
            "Qwen/Qwen2.5-14B": 0.34793236321044063,
            "google/gemma-2-9b": 0.004051913348362995,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.12823243820443286,
            "Qwen/Qwen2.5-1.5B": 0.0077280164937402335,
            "Qwen/Qwen2-1.5B-Instruct": 0.07039008149265093,
            "01-ai/Yi-1.5-6B": 0.02798911999810672,
            "Qwen/Qwen1.5-0.5B": 0.052940466621066426,
            "openai-community/gpt2-large": -0.02929206145132745,
            "EleutherAI/pythia-6.9b-deduped": 0.07187304217678255,
            "openai-community/gpt2-medium": 0.0,
            "Qwen/Qwen2.5-3B-Instruct": 0.31581597457470395,
            "google/gemma-2-9b-it": 0.501661777957133,
            "google/gemma-2-2b-it": 0.2902346632882852,
            "Qwen/Qwen1.5-1.8B-Chat": 0.07633246483868904,
            "Qwen/Qwen2-7B": 0.15389827967867825,
            "google/gemma-2b": -0.03589254563226399,
            "EleutherAI/pythia-12b": -0.002454398881171239,
            "Qwen/Qwen2.5-7B": 0.2610560070016465,
            "EleutherAI/pythia-70m-deduped": 0.0
        },
        "gsm8k": {
            "google/gemma-2-2b": 0.05989385898407885,
            "Qwen/Qwen1.5-4B-Chat": 0.3858984078847612,
            "Qwen/Qwen1.5-14B-Chat": 0.5367702805155421,
            "Qwen/Qwen2-7B-Instruct": 0.5860500379075056,
            "01-ai/Yi-9B": 0.2221379833206975,
            "Qwen/Qwen2-1.5B": 0.16603487490523122,
            "EleutherAI/pythia-1b-deduped": 0.02122820318423048,
            "Qwen/Qwen2.5-7B-Instruct": 0.7081122062168309,
            "meta-llama/Llama-3.2-1B": 0.030326004548900682,
            "meta-llama/Meta-Llama-3-8B": 0.13419257012888552,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.25928733889310085,
            "01-ai/Yi-1.5-9B": 0.4450341167551175,
            "EleutherAI/pythia-1.4b-deduped": 0.01592115238817286,
            "Qwen/Qwen1.5-4B": 0.4715693707354056,
            "meta-llama/Llama-3.2-3B": 0.10386656557998483,
            "Qwen/Qwen1.5-0.5B-Chat": 0.08263836239575435,
            "EleutherAI/pythia-2.8b-deduped": 0.022744503411675512,
            "Qwen/Qwen2-0.5B": 0.10007581501137225,
            "01-ai/Yi-6B": 0.3237300985595148,
            "Qwen/Qwen1.5-7B-Chat": 0.5056861258529188,
            "Qwen/Qwen2.5-3B": 0.07354056103108415,
            "Qwen/Qwen2-0.5B-Instruct": 0.23805913570887036,
            "01-ai/Yi-6B-Chat": 0.3260045489006823,
            "google/gemma-7b-it": 0.3479909021986353,
            "Qwen/Qwen1.5-14B": 0.5913570887035633,
            "meta-llama/Llama-3.1-8B": 0.24564063684609552,
            "01-ai/Yi-1.5-6B-Chat": 0.4935557240333586,
            "EleutherAI/pythia-410m-deduped": 0.015163002274450341,
            "01-ai/Yi-1.5-9B-Chat": 0.5519332827899924,
            "Qwen/Qwen1.5-1.8B": 0.3009855951478393,
            "openai-community/gpt2-xl": 0.017437452615617893,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7520849128127369,
            "google/gemma-2b-it": 0.09552691432903715,
            "google/gemma-7b": 0.2001516300227445,
            "meta-llama/Llama-3.1-8B-Instruct": 0.7376800606520091,
            "Qwen/Qwen2.5-14B-Instruct": 0.6489764973464746,
            "EleutherAI/pythia-160m-deduped": 0.012130401819560273,
            "meta-llama/Llama-3.2-1B-Instruct": 0.35178165276724793,
            "meta-llama/Llama-3.2-3B-Instruct": 0.6360879454131918,
            "openai-community/gpt2": 0.01819560272934041,
            "Qwen/Qwen1.5-7B": 0.5140257771038665,
            "Qwen/Qwen2.5-0.5B": 0.050037907505686124,
            "Qwen/Qwen2.5-14B": 0.1561789234268385,
            "google/gemma-2-9b": 0.21607278241091737,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.4533737680060652,
            "Qwen/Qwen2.5-1.5B": 0.09173616376042457,
            "Qwen/Qwen2-1.5B-Instruct": 0.332827899924185,
            "01-ai/Yi-1.5-6B": 0.3980288097043215,
            "Qwen/Qwen1.5-0.5B": 0.21304018195602728,
            "openai-community/gpt2-large": 0.019711902956785442,
            "EleutherAI/pythia-6.9b-deduped": 0.02047005307050796,
            "openai-community/gpt2-medium": 0.016679302501895376,
            "Qwen/Qwen2.5-3B-Instruct": 0.5860500379075056,
            "google/gemma-2-9b-it": 0.7407126611068992,
            "google/gemma-2-2b-it": 0.5572403335860501,
            "Qwen/Qwen1.5-1.8B-Chat": 0.3078089461713419,
            "Qwen/Qwen2-7B": 0.400303260045489,
            "google/gemma-2b": 0.052312357846853674,
            "EleutherAI/pythia-12b": 0.018953752843062926,
            "Qwen/Qwen2.5-7B": 0.11675511751326763,
            "EleutherAI/pythia-70m-deduped": 0.013646702047005308
        },
        "wic": {
            "google/gemma-2-2b": 0.4952978056426332,
            "Qwen/Qwen1.5-4B-Chat": 0.5297805642633229,
            "Qwen/Qwen1.5-14B-Chat": 0.6504702194357367,
            "Qwen/Qwen2-7B-Instruct": 0.6379310344827587,
            "01-ai/Yi-9B": 0.5062695924764891,
            "Qwen/Qwen2-1.5B": 0.5376175548589341,
            "EleutherAI/pythia-1b-deduped": 0.5,
            "Qwen/Qwen2.5-7B-Instruct": 0.5532915360501567,
            "meta-llama/Llama-3.2-1B": 0.4482758620689655,
            "meta-llama/Meta-Llama-3-8B": 0.49686520376175547,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.5094043887147336,
            "01-ai/Yi-1.5-9B": 0.6018808777429467,
            "EleutherAI/pythia-1.4b-deduped": 0.4952978056426332,
            "Qwen/Qwen1.5-4B": 0.6426332288401254,
            "meta-llama/Llama-3.2-3B": 0.49686520376175547,
            "Qwen/Qwen1.5-0.5B-Chat": 0.5,
            "EleutherAI/pythia-2.8b-deduped": 0.5,
            "Qwen/Qwen2-0.5B": 0.49843260188087773,
            "01-ai/Yi-6B": 0.5313479623824452,
            "Qwen/Qwen1.5-7B-Chat": 0.6739811912225705,
            "Qwen/Qwen2.5-3B": 0.6285266457680251,
            "Qwen/Qwen2-0.5B-Instruct": 0.5078369905956113,
            "01-ai/Yi-6B-Chat": 0.5705329153605015,
            "google/gemma-7b-it": 0.6269592476489029,
            "Qwen/Qwen1.5-14B": 0.6238244514106583,
            "meta-llama/Llama-3.1-8B": 0.5062695924764891,
            "01-ai/Yi-1.5-6B-Chat": 0.6379310344827587,
            "EleutherAI/pythia-410m-deduped": 0.5141065830721003,
            "01-ai/Yi-1.5-9B-Chat": 0.6269592476489029,
            "Qwen/Qwen1.5-1.8B": 0.5141065830721003,
            "openai-community/gpt2-xl": 0.49843260188087773,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.5517241379310345,
            "google/gemma-2b-it": 0.493730407523511,
            "google/gemma-7b": 0.49843260188087773,
            "meta-llama/Llama-3.1-8B-Instruct": 0.6332288401253918,
            "Qwen/Qwen2.5-14B-Instruct": 0.5830721003134797,
            "EleutherAI/pythia-160m-deduped": 0.5,
            "meta-llama/Llama-3.2-1B-Instruct": 0.4890282131661442,
            "meta-llama/Llama-3.2-3B-Instruct": 0.5047021943573667,
            "openai-community/gpt2": 0.49216300940438873,
            "Qwen/Qwen1.5-7B": 0.6880877742946708,
            "Qwen/Qwen2.5-0.5B": 0.49216300940438873,
            "Qwen/Qwen2.5-14B": 0.5172413793103449,
            "google/gemma-2-9b": 0.512539184952978,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.6347962382445141,
            "Qwen/Qwen2.5-1.5B": 0.5313479623824452,
            "Qwen/Qwen2-1.5B-Instruct": 0.5611285266457681,
            "01-ai/Yi-1.5-6B": 0.5,
            "Qwen/Qwen1.5-0.5B": 0.49843260188087773,
            "openai-community/gpt2-large": 0.49686520376175547,
            "EleutherAI/pythia-6.9b-deduped": 0.5,
            "openai-community/gpt2-medium": 0.5,
            "Qwen/Qwen2.5-3B-Instruct": 0.6065830721003135,
            "google/gemma-2-9b-it": 0.5611285266457681,
            "google/gemma-2-2b-it": 0.5344827586206896,
            "Qwen/Qwen1.5-1.8B-Chat": 0.5470219435736677,
            "Qwen/Qwen2-7B": 0.5376175548589341,
            "google/gemma-2b": 0.49843260188087773,
            "EleutherAI/pythia-12b": 0.493730407523511,
            "Qwen/Qwen2.5-7B": 0.5815047021943573,
            "EleutherAI/pythia-70m-deduped": 0.5
        },
        "openbookqa": {
            "google/gemma-2-2b": 0.418,
            "Qwen/Qwen1.5-4B-Chat": 0.432,
            "Qwen/Qwen1.5-14B-Chat": 0.462,
            "Qwen/Qwen2-7B-Instruct": 0.458,
            "01-ai/Yi-9B": 0.422,
            "Qwen/Qwen2-1.5B": 0.364,
            "EleutherAI/pythia-1b-deduped": 0.33,
            "Qwen/Qwen2.5-7B-Instruct": 0.484,
            "meta-llama/Llama-3.2-1B": 0.372,
            "meta-llama/Meta-Llama-3-8B": 0.448,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.348,
            "01-ai/Yi-1.5-9B": 0.452,
            "EleutherAI/pythia-1.4b-deduped": 0.33,
            "Qwen/Qwen1.5-4B": 0.4,
            "meta-llama/Llama-3.2-3B": 0.408,
            "Qwen/Qwen1.5-0.5B-Chat": 0.344,
            "EleutherAI/pythia-2.8b-deduped": 0.35,
            "Qwen/Qwen2-0.5B": 0.33,
            "01-ai/Yi-6B": 0.41,
            "Qwen/Qwen1.5-7B-Chat": 0.438,
            "Qwen/Qwen2.5-3B": 0.42,
            "Qwen/Qwen2-0.5B-Instruct": 0.364,
            "01-ai/Yi-6B-Chat": 0.428,
            "google/gemma-7b-it": 0.448,
            "Qwen/Qwen1.5-14B": 0.434,
            "meta-llama/Llama-3.1-8B": 0.454,
            "01-ai/Yi-1.5-6B-Chat": 0.436,
            "EleutherAI/pythia-410m-deduped": 0.3,
            "01-ai/Yi-1.5-9B-Chat": 0.436,
            "Qwen/Qwen1.5-1.8B": 0.344,
            "openai-community/gpt2-xl": 0.32,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.444,
            "google/gemma-2b-it": 0.404,
            "google/gemma-7b": 0.442,
            "meta-llama/Llama-3.1-8B-Instruct": 0.448,
            "Qwen/Qwen2.5-14B-Instruct": 0.478,
            "EleutherAI/pythia-160m-deduped": 0.268,
            "meta-llama/Llama-3.2-1B-Instruct": 0.372,
            "meta-llama/Llama-3.2-3B-Instruct": 0.408,
            "openai-community/gpt2": 0.272,
            "Qwen/Qwen1.5-7B": 0.416,
            "Qwen/Qwen2.5-0.5B": 0.352,
            "Qwen/Qwen2.5-14B": 0.452,
            "google/gemma-2-9b": 0.472,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.404,
            "Qwen/Qwen2.5-1.5B": 0.408,
            "Qwen/Qwen2-1.5B-Instruct": 0.41,
            "01-ai/Yi-1.5-6B": 0.418,
            "Qwen/Qwen1.5-0.5B": 0.322,
            "openai-community/gpt2-large": 0.312,
            "EleutherAI/pythia-6.9b-deduped": 0.388,
            "openai-community/gpt2-medium": 0.302,
            "Qwen/Qwen2.5-3B-Instruct": 0.448,
            "google/gemma-2-9b-it": 0.5,
            "google/gemma-2-2b-it": 0.444,
            "Qwen/Qwen1.5-1.8B-Chat": 0.388,
            "Qwen/Qwen2-7B": 0.442,
            "google/gemma-2b": 0.4,
            "EleutherAI/pythia-12b": 0.38,
            "Qwen/Qwen2.5-7B": 0.472,
            "EleutherAI/pythia-70m-deduped": 0.246
        },
        "mrpc": {
            "google/gemma-2-2b": 0.36764705882352944,
            "Qwen/Qwen1.5-4B-Chat": 0.6887254901960784,
            "Qwen/Qwen1.5-14B-Chat": 0.803921568627451,
            "Qwen/Qwen2-7B-Instruct": 0.7696078431372549,
            "01-ai/Yi-9B": 0.6887254901960784,
            "Qwen/Qwen2-1.5B": 0.5661764705882353,
            "EleutherAI/pythia-1b-deduped": 0.6838235294117647,
            "Qwen/Qwen2.5-7B-Instruct": 0.6985294117647058,
            "meta-llama/Llama-3.2-1B": 0.6666666666666666,
            "meta-llama/Meta-Llama-3-8B": 0.6813725490196079,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.6838235294117647,
            "01-ai/Yi-1.5-9B": 0.7156862745098039,
            "EleutherAI/pythia-1.4b-deduped": 0.6764705882352942,
            "Qwen/Qwen1.5-4B": 0.7745098039215687,
            "meta-llama/Llama-3.2-3B": 0.6642156862745098,
            "Qwen/Qwen1.5-0.5B-Chat": 0.34068627450980393,
            "EleutherAI/pythia-2.8b-deduped": 0.6862745098039216,
            "Qwen/Qwen2-0.5B": 0.37745098039215685,
            "01-ai/Yi-6B": 0.75,
            "Qwen/Qwen1.5-7B-Chat": 0.7941176470588235,
            "Qwen/Qwen2.5-3B": 0.7671568627450981,
            "Qwen/Qwen2-0.5B-Instruct": 0.6838235294117647,
            "01-ai/Yi-6B-Chat": 0.7009803921568627,
            "google/gemma-7b-it": 0.6985294117647058,
            "Qwen/Qwen1.5-14B": 0.8088235294117647,
            "meta-llama/Llama-3.1-8B": 0.678921568627451,
            "01-ai/Yi-1.5-6B-Chat": 0.7696078431372549,
            "EleutherAI/pythia-410m-deduped": 0.4166666666666667,
            "01-ai/Yi-1.5-9B-Chat": 0.7524509803921569,
            "Qwen/Qwen1.5-1.8B": 0.6568627450980392,
            "openai-community/gpt2-xl": 0.6519607843137255,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7279411764705882,
            "google/gemma-2b-it": 0.3431372549019608,
            "google/gemma-7b": 0.7083333333333334,
            "meta-llama/Llama-3.1-8B-Instruct": 0.7107843137254902,
            "Qwen/Qwen2.5-14B-Instruct": 0.7745098039215687,
            "EleutherAI/pythia-160m-deduped": 0.6838235294117647,
            "meta-llama/Llama-3.2-1B-Instruct": 0.6053921568627451,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7254901960784313,
            "openai-community/gpt2": 0.5612745098039216,
            "Qwen/Qwen1.5-7B": 0.7892156862745098,
            "Qwen/Qwen2.5-0.5B": 0.6323529411764706,
            "Qwen/Qwen2.5-14B": 0.7965686274509803,
            "google/gemma-2-9b": 0.6862745098039216,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7647058823529411,
            "Qwen/Qwen2.5-1.5B": 0.7524509803921569,
            "Qwen/Qwen2-1.5B-Instruct": 0.7671568627450981,
            "01-ai/Yi-1.5-6B": 0.6642156862745098,
            "Qwen/Qwen1.5-0.5B": 0.6838235294117647,
            "openai-community/gpt2-large": 0.6666666666666666,
            "EleutherAI/pythia-6.9b-deduped": 0.6813725490196079,
            "openai-community/gpt2-medium": 0.6838235294117647,
            "Qwen/Qwen2.5-3B-Instruct": 0.6446078431372549,
            "google/gemma-2-9b-it": 0.7401960784313726,
            "google/gemma-2-2b-it": 0.6397058823529411,
            "Qwen/Qwen1.5-1.8B-Chat": 0.7230392156862745,
            "Qwen/Qwen2-7B": 0.5882352941176471,
            "google/gemma-2b": 0.6838235294117647,
            "EleutherAI/pythia-12b": 0.4068627450980392,
            "Qwen/Qwen2.5-7B": 0.6764705882352942,
            "EleutherAI/pythia-70m-deduped": 0.6838235294117647
        },
        "headqa_en": {
            "google/gemma-2-2b": 0.42815463165572576,
            "Qwen/Qwen1.5-4B-Chat": 0.3435448577680525,
            "Qwen/Qwen1.5-14B-Chat": 0.36797957695113054,
            "Qwen/Qwen2-7B-Instruct": 0.4325309992706054,
            "01-ai/Yi-9B": 0.3986141502552881,
            "Qwen/Qwen2-1.5B": 0.34427425237053244,
            "EleutherAI/pythia-1b-deduped": 0.32567469000729393,
            "Qwen/Qwen2.5-7B-Instruct": 0.4445660102115244,
            "meta-llama/Llama-3.2-1B": 0.34938001458789203,
            "meta-llama/Meta-Llama-3-8B": 0.43471918307804525,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.32202771699489424,
            "01-ai/Yi-1.5-9B": 0.4110138584974471,
            "EleutherAI/pythia-1.4b-deduped": 0.3464624361779723,
            "Qwen/Qwen1.5-4B": 0.3610503282275711,
            "meta-llama/Llama-3.2-3B": 0.40189642596644787,
            "Qwen/Qwen1.5-0.5B-Chat": 0.2910284463894967,
            "EleutherAI/pythia-2.8b-deduped": 0.3614150255288111,
            "Qwen/Qwen2-0.5B": 0.2975929978118162,
            "01-ai/Yi-6B": 0.41174325309992704,
            "Qwen/Qwen1.5-7B-Chat": 0.3599562363238512,
            "Qwen/Qwen2.5-3B": 0.40663749088256745,
            "Qwen/Qwen2-0.5B-Instruct": 0.3070751276440554,
            "01-ai/Yi-6B-Chat": 0.4033552151714077,
            "google/gemma-7b-it": 0.4062727935813275,
            "Qwen/Qwen1.5-14B": 0.40408460977388766,
            "meta-llama/Llama-3.1-8B": 0.4664478482859227,
            "01-ai/Yi-1.5-6B-Chat": 0.4059080962800875,
            "EleutherAI/pythia-410m-deduped": 0.3059810357403355,
            "01-ai/Yi-1.5-9B-Chat": 0.4270605397520058,
            "Qwen/Qwen1.5-1.8B": 0.33916849015317285,
            "openai-community/gpt2-xl": 0.30342815463165573,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.47155361050328226,
            "google/gemma-2b-it": 0.3665207877461707,
            "google/gemma-7b": 0.45441283734500365,
            "meta-llama/Llama-3.1-8B-Instruct": 0.4784828592268417,
            "Qwen/Qwen2.5-14B-Instruct": 0.4865061998541211,
            "EleutherAI/pythia-160m-deduped": 0.2760758570386579,
            "meta-llama/Llama-3.2-1B-Instruct": 0.337709700948213,
            "meta-llama/Llama-3.2-3B-Instruct": 0.4037199124726477,
            "openai-community/gpt2": 0.26549963530269877,
            "Qwen/Qwen1.5-7B": 0.37892049598832966,
            "Qwen/Qwen2.5-0.5B": 0.31436907366885486,
            "Qwen/Qwen2.5-14B": 0.4562363238512035,
            "google/gemma-2-9b": 0.5105762217359592,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.38694383661560905,
            "Qwen/Qwen2.5-1.5B": 0.3767323121808899,
            "Qwen/Qwen2-1.5B-Instruct": 0.3588621444201313,
            "01-ai/Yi-1.5-6B": 0.3847556528081692,
            "Qwen/Qwen1.5-0.5B": 0.30342815463165573,
            "openai-community/gpt2-large": 0.28191101385849743,
            "EleutherAI/pythia-6.9b-deduped": 0.38293216630196936,
            "openai-community/gpt2-medium": 0.2775346462436178,
            "Qwen/Qwen2.5-3B-Instruct": 0.40554339897884756,
            "google/gemma-2-9b-it": 0.5149525893508388,
            "google/gemma-2-2b-it": 0.4310722100656455,
            "Qwen/Qwen1.5-1.8B-Chat": 0.3362509117432531,
            "Qwen/Qwen2-7B": 0.42414296134208607,
            "google/gemma-2b": 0.39059080962800874,
            "EleutherAI/pythia-12b": 0.38584974471188915,
            "Qwen/Qwen2.5-7B": 0.43326039387308535,
            "EleutherAI/pythia-70m-deduped": 0.26659372720641866
        },
        "rte": {
            "google/gemma-2-2b": 0.6173285198555957,
            "Qwen/Qwen1.5-4B-Chat": 0.8158844765342961,
            "Qwen/Qwen1.5-14B-Chat": 0.8122743682310469,
            "Qwen/Qwen2-7B-Instruct": 0.8050541516245487,
            "01-ai/Yi-9B": 0.7328519855595668,
            "Qwen/Qwen2-1.5B": 0.6895306859205776,
            "EleutherAI/pythia-1b-deduped": 0.47653429602888087,
            "Qwen/Qwen2.5-7B-Instruct": 0.8447653429602888,
            "meta-llama/Llama-3.2-1B": 0.5631768953068592,
            "meta-llama/Meta-Llama-3-8B": 0.7003610108303249,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.6353790613718412,
            "01-ai/Yi-1.5-9B": 0.7833935018050542,
            "EleutherAI/pythia-1.4b-deduped": 0.5487364620938628,
            "Qwen/Qwen1.5-4B": 0.7328519855595668,
            "meta-llama/Llama-3.2-3B": 0.5379061371841155,
            "Qwen/Qwen1.5-0.5B-Chat": 0.5776173285198556,
            "EleutherAI/pythia-2.8b-deduped": 0.5234657039711191,
            "Qwen/Qwen2-0.5B": 0.6028880866425993,
            "01-ai/Yi-6B": 0.6895306859205776,
            "Qwen/Qwen1.5-7B-Chat": 0.8303249097472925,
            "Qwen/Qwen2.5-3B": 0.7545126353790613,
            "Qwen/Qwen2-0.5B-Instruct": 0.6570397111913358,
            "01-ai/Yi-6B-Chat": 0.7075812274368231,
            "google/gemma-7b-it": 0.7978339350180506,
            "Qwen/Qwen1.5-14B": 0.7906137184115524,
            "meta-llama/Llama-3.1-8B": 0.7111913357400722,
            "01-ai/Yi-1.5-6B-Chat": 0.7545126353790613,
            "EleutherAI/pythia-410m-deduped": 0.5379061371841155,
            "01-ai/Yi-1.5-9B-Chat": 0.779783393501805,
            "Qwen/Qwen1.5-1.8B": 0.5415162454873647,
            "openai-community/gpt2-xl": 0.5234657039711191,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7436823104693141,
            "google/gemma-2b-it": 0.7256317689530686,
            "google/gemma-7b": 0.6859205776173285,
            "meta-llama/Llama-3.1-8B-Instruct": 0.7111913357400722,
            "Qwen/Qwen2.5-14B-Instruct": 0.8411552346570397,
            "EleutherAI/pythia-160m-deduped": 0.5379061371841155,
            "meta-llama/Llama-3.2-1B-Instruct": 0.6389891696750902,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7617328519855595,
            "openai-community/gpt2": 0.5306859205776173,
            "Qwen/Qwen1.5-7B": 0.7581227436823105,
            "Qwen/Qwen2.5-0.5B": 0.5884476534296029,
            "Qwen/Qwen2.5-14B": 0.8014440433212996,
            "google/gemma-2-9b": 0.6859205776173285,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7509025270758123,
            "Qwen/Qwen2.5-1.5B": 0.7003610108303249,
            "Qwen/Qwen2-1.5B-Instruct": 0.779783393501805,
            "01-ai/Yi-1.5-6B": 0.740072202166065,
            "Qwen/Qwen1.5-0.5B": 0.6173285198555957,
            "openai-community/gpt2-large": 0.5270758122743683,
            "EleutherAI/pythia-6.9b-deduped": 0.5703971119133574,
            "openai-community/gpt2-medium": 0.5270758122743683,
            "Qwen/Qwen2.5-3B-Instruct": 0.8158844765342961,
            "google/gemma-2-9b-it": 0.779783393501805,
            "google/gemma-2-2b-it": 0.7581227436823105,
            "Qwen/Qwen1.5-1.8B-Chat": 0.6389891696750902,
            "Qwen/Qwen2-7B": 0.7292418772563177,
            "google/gemma-2b": 0.6498194945848376,
            "EleutherAI/pythia-12b": 0.5451263537906137,
            "Qwen/Qwen2.5-7B": 0.8158844765342961,
            "EleutherAI/pythia-70m-deduped": 0.5018050541516246
        },
        "arc_easy": {
            "google/gemma-2-2b": 0.8026094276094277,
            "Qwen/Qwen1.5-4B-Chat": 0.5707070707070707,
            "Qwen/Qwen1.5-14B-Chat": 0.6641414141414141,
            "Qwen/Qwen2-7B-Instruct": 0.7643097643097643,
            "01-ai/Yi-9B": 0.7984006734006734,
            "Qwen/Qwen2-1.5B": 0.6035353535353535,
            "EleutherAI/pythia-1b-deduped": 0.5202020202020202,
            "Qwen/Qwen2.5-7B-Instruct": 0.811026936026936,
            "meta-llama/Llama-3.2-1B": 0.6174242424242424,
            "meta-llama/Meta-Llama-3-8B": 0.7756734006734006,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.593013468013468,
            "01-ai/Yi-1.5-9B": 0.7895622895622896,
            "EleutherAI/pythia-1.4b-deduped": 0.5681818181818182,
            "Qwen/Qwen1.5-4B": 0.6157407407407407,
            "meta-llama/Llama-3.2-3B": 0.7209595959595959,
            "Qwen/Qwen1.5-0.5B-Chat": 0.44023569023569026,
            "EleutherAI/pythia-2.8b-deduped": 0.5913299663299664,
            "Qwen/Qwen2-0.5B": 0.5042087542087542,
            "01-ai/Yi-6B": 0.7748316498316499,
            "Qwen/Qwen1.5-7B-Chat": 0.6334175084175084,
            "Qwen/Qwen2.5-3B": 0.7310606060606061,
            "Qwen/Qwen2-0.5B-Instruct": 0.5513468013468014,
            "01-ai/Yi-6B-Chat": 0.6632996632996633,
            "google/gemma-7b-it": 0.7319023569023569,
            "Qwen/Qwen1.5-14B": 0.6839225589225589,
            "meta-llama/Llama-3.1-8B": 0.8253367003367004,
            "01-ai/Yi-1.5-6B-Chat": 0.7718855218855218,
            "EleutherAI/pythia-410m-deduped": 0.45707070707070707,
            "01-ai/Yi-1.5-9B-Chat": 0.7962962962962963,
            "Qwen/Qwen1.5-1.8B": 0.5888047138047138,
            "openai-community/gpt2-xl": 0.5105218855218855,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7861952861952862,
            "google/gemma-2b-it": 0.6632996632996633,
            "google/gemma-7b": 0.8106060606060606,
            "meta-llama/Llama-3.1-8B-Instruct": 0.797979797979798,
            "Qwen/Qwen2.5-14B-Instruct": 0.8152356902356902,
            "EleutherAI/pythia-160m-deduped": 0.390993265993266,
            "meta-llama/Llama-3.2-1B-Instruct": 0.6384680134680135,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7104377104377104,
            "openai-community/gpt2": 0.3947811447811448,
            "Qwen/Qwen1.5-7B": 0.622895622895623,
            "Qwen/Qwen2.5-0.5B": 0.5867003367003367,
            "Qwen/Qwen2.5-14B": 0.7912457912457912,
            "google/gemma-2-9b": 0.8804713804713805,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7592592592592593,
            "Qwen/Qwen2.5-1.5B": 0.7146464646464646,
            "Qwen/Qwen2-1.5B-Instruct": 0.6666666666666666,
            "01-ai/Yi-1.5-6B": 0.7382154882154882,
            "Qwen/Qwen1.5-0.5B": 0.5235690235690236,
            "openai-community/gpt2-large": 0.4663299663299663,
            "EleutherAI/pythia-6.9b-deduped": 0.6338383838383839,
            "openai-community/gpt2-medium": 0.43602693602693604,
            "Qwen/Qwen2.5-3B-Instruct": 0.7289562289562289,
            "google/gemma-2-9b-it": 0.843013468013468,
            "google/gemma-2-2b-it": 0.7853535353535354,
            "Qwen/Qwen1.5-1.8B-Chat": 0.5980639730639731,
            "Qwen/Qwen2-7B": 0.7466329966329966,
            "google/gemma-2b": 0.7226430976430976,
            "EleutherAI/pythia-12b": 0.6376262626262627,
            "Qwen/Qwen2.5-7B": 0.773989898989899,
            "EleutherAI/pythia-70m-deduped": 0.3611111111111111
        },
        "arc_challenge": {
            "google/gemma-2-2b": 0.4974402730375427,
            "Qwen/Qwen1.5-4B-Chat": 0.3873720136518771,
            "Qwen/Qwen1.5-14B-Chat": 0.48890784982935154,
            "Qwen/Qwen2-7B-Instruct": 0.5418088737201365,
            "01-ai/Yi-9B": 0.5469283276450512,
            "Qwen/Qwen2-1.5B": 0.3609215017064846,
            "EleutherAI/pythia-1b-deduped": 0.26535836177474403,
            "Qwen/Qwen2.5-7B-Instruct": 0.5503412969283277,
            "meta-llama/Llama-3.2-1B": 0.36860068259385664,
            "meta-llama/Meta-Llama-3-8B": 0.5409556313993175,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.3387372013651877,
            "01-ai/Yi-1.5-9B": 0.5435153583617748,
            "EleutherAI/pythia-1.4b-deduped": 0.30119453924914674,
            "Qwen/Qwen1.5-4B": 0.39590443686006827,
            "meta-llama/Llama-3.2-3B": 0.46331058020477817,
            "Qwen/Qwen1.5-0.5B-Chat": 0.2935153583617747,
            "EleutherAI/pythia-2.8b-deduped": 0.32849829351535836,
            "Qwen/Qwen2-0.5B": 0.2901023890784983,
            "01-ai/Yi-6B": 0.5042662116040956,
            "Qwen/Qwen1.5-7B-Chat": 0.4513651877133106,
            "Qwen/Qwen2.5-3B": 0.47440273037542663,
            "Qwen/Qwen2-0.5B-Instruct": 0.29436860068259385,
            "01-ai/Yi-6B-Chat": 0.4718430034129693,
            "google/gemma-7b-it": 0.48890784982935154,
            "Qwen/Qwen1.5-14B": 0.46928327645051193,
            "meta-llama/Llama-3.1-8B": 0.5494880546075085,
            "01-ai/Yi-1.5-6B-Chat": 0.5409556313993175,
            "EleutherAI/pythia-410m-deduped": 0.25426621160409557,
            "01-ai/Yi-1.5-9B-Chat": 0.5895904436860068,
            "Qwen/Qwen1.5-1.8B": 0.3464163822525597,
            "openai-community/gpt2-xl": 0.28498293515358364,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.5580204778156996,
            "google/gemma-2b-it": 0.42406143344709896,
            "google/gemma-7b": 0.53839590443686,
            "meta-llama/Llama-3.1-8B-Instruct": 0.5580204778156996,
            "Qwen/Qwen2.5-14B-Instruct": 0.621160409556314,
            "EleutherAI/pythia-160m-deduped": 0.23976109215017063,
            "meta-llama/Llama-3.2-1B-Instruct": 0.3779863481228669,
            "meta-llama/Llama-3.2-3B-Instruct": 0.4616040955631399,
            "openai-community/gpt2": 0.22696245733788395,
            "Qwen/Qwen1.5-7B": 0.4283276450511945,
            "Qwen/Qwen2.5-0.5B": 0.3242320819112628,
            "Qwen/Qwen2.5-14B": 0.5887372013651877,
            "google/gemma-2-9b": 0.6552901023890785,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.46501706484641636,
            "Qwen/Qwen2.5-1.5B": 0.4513651877133106,
            "Qwen/Qwen2-1.5B-Instruct": 0.3993174061433447,
            "01-ai/Yi-1.5-6B": 0.49402730375426623,
            "Qwen/Qwen1.5-0.5B": 0.2960750853242321,
            "openai-community/gpt2-large": 0.2508532423208191,
            "EleutherAI/pythia-6.9b-deduped": 0.3532423208191126,
            "openai-community/gpt2-medium": 0.25,
            "Qwen/Qwen2.5-3B-Instruct": 0.4812286689419795,
            "google/gemma-2-9b-it": 0.6510238907849829,
            "google/gemma-2-2b-it": 0.5264505119453925,
            "Qwen/Qwen1.5-1.8B-Chat": 0.31569965870307165,
            "Qwen/Qwen2-7B": 0.4991467576791809,
            "google/gemma-2b": 0.4180887372013652,
            "EleutherAI/pythia-12b": 0.3506825938566553,
            "Qwen/Qwen2.5-7B": 0.5110921501706485,
            "EleutherAI/pythia-70m-deduped": 0.21160409556313994
        },
        "arxiv_2025": {
            "01-ai/Yi-1.5-6B": 0.815396830182918,
            "01-ai/Yi-1.5-9B": 0.7145081852214616,
            "01-ai/Yi-6B": 0.7231032524908036,
            "01-ai/Yi-9B": 0.6868882700128423,
            "EleutherAI/pythia-1.4b-deduped": 0.7601401219574151,
            "EleutherAI/pythia-12b": 0.6939283588174721,
            "EleutherAI/pythia-160m-deduped": 0.9685952129298327,
            "EleutherAI/pythia-1b-deduped": 0.7796557763497047,
            "EleutherAI/pythia-2.8b-deduped": 0.7248732498923544,
            "EleutherAI/pythia-410m-deduped": 0.8271546375110937,
            "EleutherAI/pythia-6.9b-deduped": 0.7158959070947811,
            "EleutherAI/pythia-70m-deduped": 1.0504225229973452,
            "Qwen/Qwen1.5-0.5B": 0.8207543999563397,
            "Qwen/Qwen1.5-1.8B": 0.756704437326591,
            "Qwen/Qwen1.5-14B": 0.6443484217260981,
            "Qwen/Qwen1.5-4B": 0.7092815464622041,
            "Qwen/Qwen1.5-7B": 0.6625281880470623,
            "Qwen/Qwen2-0.5B": 0.806416261780809,
            "Qwen/Qwen2-1.5B": 0.7321705330781323,
            "Qwen/Qwen2-7B": 0.6529044954406215,
            "Qwen/Qwen2.5-0.5B": 0.76816768571439,
            "Qwen/Qwen2.5-1.5B": 0.696328485706332,
            "Qwen/Qwen2.5-14B": 0.6174194716438438,
            "Qwen/Qwen2.5-3B": 0.716165171258308,
            "Qwen/Qwen2.5-7B": 0.639467925184141,
            "meta-llama/Llama-3.1-8B": 0.6622316242586825,
            "meta-llama/Llama-3.2-1B": 0.7455282758570828,
            "meta-llama/Llama-3.2-3B": 0.6956829092931134,
            "meta-llama/Meta-Llama-3-8B": 0.6695173606997576,
            "openai-community/gpt2": 1.0514835178322128,
            "openai-community/gpt2-large": 0.9228853541704639,
            "openai-community/gpt2-medium": 0.9632440513458629,
            "openai-community/gpt2-xl": 0.8943044677888751,
            "01-ai/Yi-1.5-6B-Chat": 0.7802154762927608,
            "01-ai/Yi-1.5-9B-Chat": 0.7499342734697821,
            "01-ai/Yi-6B-Chat": 0.7586448398348429,
            "Qwen/Qwen1.5-0.5B-Chat": 1.0004849711341726,
            "Qwen/Qwen1.5-1.8B-Chat": 0.8794571671671635,
            "Qwen/Qwen1.5-14B-Chat": 0.7277732186504422,
            "Qwen/Qwen1.5-4B-Chat": 0.7306077823231941,
            "Qwen/Qwen1.5-7B-Chat": 0.7763515176275463,
            "Qwen/Qwen2-0.5B-Instruct": 0.8258821271477697,
            "Qwen/Qwen2-1.5B-Instruct": 0.7527919205378657,
            "Qwen/Qwen2-7B-Instruct": 0.6715872059683992,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.7910918465687378,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7210867223738776,
            "Qwen/Qwen2.5-14B-Instruct": 0.6493663704708655,
            "Qwen/Qwen2.5-3B-Instruct": 0.6965475312947544,
            "Qwen/Qwen2.5-7B-Instruct": 0.6724194782545492,
            "meta-llama/Llama-3.1-8B-Instruct": 0.681354676951373,
            "meta-llama/Llama-3.2-1B-Instruct": 0.8140513895927056,
            "meta-llama/Llama-3.2-3B-Instruct": 0.7578555495930065,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7420177111547617
        },
        "wiki_2025": {
            "01-ai/Yi-1.5-6B": 0.8794488599593853,
            "01-ai/Yi-1.5-9B": 0.8555666259202221,
            "01-ai/Yi-6B": 0.8755590021145132,
            "01-ai/Yi-9B": 0.8650369670742234,
            "EleutherAI/pythia-1.4b-deduped": 1.0107660451635967,
            "EleutherAI/pythia-12b": 0.9249663166020791,
            "EleutherAI/pythia-160m-deduped": 1.2135476769910576,
            "EleutherAI/pythia-1b-deduped": 1.0354484146765077,
            "EleutherAI/pythia-2.8b-deduped": 0.9745169084149702,
            "EleutherAI/pythia-410m-deduped": 1.094774081626704,
            "EleutherAI/pythia-6.9b-deduped": 0.9423597011883509,
            "EleutherAI/pythia-70m-deduped": 1.3432303665590715,
            "Qwen/Qwen1.5-0.5B": 1.0937515807488583,
            "Qwen/Qwen1.5-1.8B": 1.0143361631682288,
            "Qwen/Qwen1.5-14B": 0.877870670567981,
            "Qwen/Qwen1.5-4B": 0.9396143674666417,
            "Qwen/Qwen1.5-7B": 0.9001316907442295,
            "Qwen/Qwen2-0.5B": 1.0611655674534006,
            "Qwen/Qwen2-1.5B": 0.9573614704130436,
            "Qwen/Qwen2-7B": 0.8641181632252615,
            "Qwen/Qwen2.5-0.5B": 1.0597925934735475,
            "Qwen/Qwen2.5-1.5B": 0.9533233570883773,
            "Qwen/Qwen2.5-14B": 0.8027943301256586,
            "Qwen/Qwen2.5-3B": 0.9221457348431964,
            "Qwen/Qwen2.5-7B": 0.8663305776637532,
            "meta-llama/Llama-3.1-8B": 0.8030934001843121,
            "meta-llama/Llama-3.2-1B": 0.944024528270589,
            "meta-llama/Llama-3.2-3B": 0.8751455760700041,
            "meta-llama/Meta-Llama-3-8B": 0.8022850240412461,
            "openai-community/gpt2": 1.2074113933538833,
            "openai-community/gpt2-large": 1.079283727486792,
            "openai-community/gpt2-medium": 1.1184844273846462,
            "openai-community/gpt2-xl": 1.0510170455321421,
            "01-ai/Yi-1.5-6B-Chat": 1.0380156329276833,
            "01-ai/Yi-1.5-9B-Chat": 1.012803275655077,
            "01-ai/Yi-6B-Chat": 0.9089991418592184,
            "Qwen/Qwen1.5-0.5B-Chat": 1.3682997169921098,
            "Qwen/Qwen1.5-1.8B-Chat": 1.1215082720055323,
            "Qwen/Qwen1.5-14B-Chat": 0.976563184020957,
            "Qwen/Qwen1.5-4B-Chat": 1.0074882551443551,
            "Qwen/Qwen1.5-7B-Chat": 1.049266693408579,
            "Qwen/Qwen2-0.5B-Instruct": 1.0781037820386548,
            "Qwen/Qwen2-1.5B-Instruct": 0.9702198248328257,
            "Qwen/Qwen2-7B-Instruct": 0.8835053694199216,
            "Qwen/Qwen2.5-0.5B-Instruct": 1.0829596457175477,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.9661811545788063,
            "Qwen/Qwen2.5-14B-Instruct": 0.8228223742354641,
            "Qwen/Qwen2.5-3B-Instruct": 0.9357593440721365,
            "Qwen/Qwen2.5-7B-Instruct": 0.895394635916191,
            "meta-llama/Llama-3.1-8B-Instruct": 0.8588628949016002,
            "meta-llama/Llama-3.2-1B-Instruct": 1.0442290631023647,
            "meta-llama/Llama-3.2-3B-Instruct": 0.9663585750829193,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.9055322901043357
        },
        "stackexchange_2025": {
            "01-ai/Yi-1.5-6B": 0.7432102796738009,
            "01-ai/Yi-1.5-9B": 0.7110020913432951,
            "01-ai/Yi-6B": 0.7750269487138338,
            "01-ai/Yi-9B": 0.7527138666634229,
            "EleutherAI/pythia-1.4b-deduped": 0.8730562841374311,
            "EleutherAI/pythia-12b": 0.7833223529288351,
            "EleutherAI/pythia-160m-deduped": 1.143071050287651,
            "EleutherAI/pythia-1b-deduped": 0.9016790626549241,
            "EleutherAI/pythia-2.8b-deduped": 0.8274843777625307,
            "EleutherAI/pythia-410m-deduped": 0.9748780242534768,
            "EleutherAI/pythia-6.9b-deduped": 0.8035339365711915,
            "EleutherAI/pythia-70m-deduped": 1.3173153886498932,
            "Qwen/Qwen1.5-0.5B": 0.9174984730064984,
            "Qwen/Qwen1.5-1.8B": 0.8340531172466237,
            "Qwen/Qwen1.5-14B": 0.7042257363234898,
            "Qwen/Qwen1.5-4B": 0.7772996550575623,
            "Qwen/Qwen1.5-7B": 0.727035602304051,
            "Qwen/Qwen2-0.5B": 0.871419914169502,
            "Qwen/Qwen2-1.5B": 0.7796692890166157,
            "Qwen/Qwen2-7B": 0.6935031992675079,
            "Qwen/Qwen2.5-0.5B": 0.8118529328208938,
            "Qwen/Qwen2.5-1.5B": 0.7197439875000656,
            "Qwen/Qwen2.5-14B": 0.6161188299163584,
            "Qwen/Qwen2.5-3B": 0.6958837813569078,
            "Qwen/Qwen2.5-7B": 0.6431417744909724,
            "meta-llama/Llama-3.1-8B": 0.6762511272204267,
            "meta-llama/Llama-3.2-1B": 0.802007038620188,
            "meta-llama/Llama-3.2-3B": 0.7289424827925105,
            "meta-llama/Meta-Llama-3-8B": 0.6784214249693956,
            "openai-community/gpt2": 1.3477037106552667,
            "openai-community/gpt2-large": 1.1385031909787615,
            "openai-community/gpt2-medium": 1.1877234299136423,
            "openai-community/gpt2-xl": 1.0905134135067758,
            "01-ai/Yi-1.5-6B-Chat": 0.9266290814280863,
            "01-ai/Yi-1.5-9B-Chat": 0.8813036661308125,
            "01-ai/Yi-6B-Chat": 0.8208673741738588,
            "Qwen/Qwen1.5-0.5B-Chat": 1.249972814363385,
            "Qwen/Qwen1.5-1.8B-Chat": 0.9730409702085759,
            "Qwen/Qwen1.5-14B-Chat": 0.875052276013067,
            "Qwen/Qwen1.5-4B-Chat": 0.8493851354358088,
            "Qwen/Qwen1.5-7B-Chat": 0.918271871538491,
            "Qwen/Qwen2-0.5B-Instruct": 0.8942346361316897,
            "Qwen/Qwen2-1.5B-Instruct": 0.8005720973919266,
            "Qwen/Qwen2-7B-Instruct": 0.7205513968519249,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.8434688974478153,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.7405224392045627,
            "Qwen/Qwen2.5-14B-Instruct": 0.6562298313296909,
            "Qwen/Qwen2.5-3B-Instruct": 0.7231730645036942,
            "Qwen/Qwen2.5-7B-Instruct": 0.6976804750704657,
            "meta-llama/Llama-3.1-8B-Instruct": 0.7299480866586958,
            "meta-llama/Llama-3.2-1B-Instruct": 0.9359217669910536,
            "meta-llama/Llama-3.2-3B-Instruct": 0.869722495157419,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.7668465258369257
        }
    },
    "train_before_test_stderr": {
        "mnli": {
            "01-ai/Yi-1.5-6B": 0.003151152127638371,
            "01-ai/Yi-1.5-6B-Chat": 0.0031459981651430725,
            "01-ai/Yi-1.5-9B": 0.002993008610298062,
            "01-ai/Yi-1.5-9B-Chat": 0.003030351163282503,
            "01-ai/Yi-6B": 0.00327689460819118,
            "01-ai/Yi-6B-Chat": 0.003272069320732021,
            "01-ai/Yi-9B": 0.0030317205031939196,
            "EleutherAI/pythia-1.4b-deduped": 0.003945433971424419,
            "EleutherAI/pythia-12b": 0.0036301613340087675,
            "EleutherAI/pythia-160m-deduped": 0.004919798173220363,
            "EleutherAI/pythia-1b-deduped": 0.004172955404887113,
            "EleutherAI/pythia-2.8b-deduped": 0.0037370632434324744,
            "EleutherAI/pythia-410m-deduped": 0.004317606178410972,
            "EleutherAI/pythia-6.9b-deduped": 0.003682033388982874,
            "EleutherAI/pythia-70m-deduped": 0.005029899671583369,
            "Qwen/Qwen1.5-0.5B": 0.003958505770651034,
            "Qwen/Qwen1.5-0.5B-Chat": 0.003997851002420575,
            "Qwen/Qwen1.5-1.8B": 0.003711666665621404,
            "Qwen/Qwen1.5-1.8B-Chat": 0.0036479523104997373,
            "Qwen/Qwen1.5-14B": 0.0029549332893924513,
            "Qwen/Qwen1.5-14B-Chat": 0.0030055361867985116,
            "Qwen/Qwen1.5-4B": 0.003288904342677752,
            "Qwen/Qwen1.5-4B-Chat": 0.003330347296237872,
            "Qwen/Qwen1.5-7B": 0.0031703573246765404,
            "Qwen/Qwen1.5-7B-Chat": 0.0031729035674049172,
            "Qwen/Qwen2-0.5B": 0.003979510749872738,
            "Qwen/Qwen2-0.5B-Instruct": 0.003977905301670811,
            "Qwen/Qwen2-1.5B": 0.0034658432892195465,
            "Qwen/Qwen2-1.5B-Instruct": 0.003487489665961783,
            "Qwen/Qwen2-7B": 0.003096335123598559,
            "Qwen/Qwen2-7B-Instruct": 0.003133052534238729,
            "Qwen/Qwen2.5-0.5B": 0.0038654677126146717,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.0038637398701142035,
            "Qwen/Qwen2.5-1.5B": 0.003451634618367293,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.0034417330598127886,
            "Qwen/Qwen2.5-14B": 0.0029247942460041325,
            "Qwen/Qwen2.5-14B-Instruct": 0.002882389631195939,
            "Qwen/Qwen2.5-3B": 0.0031944112131547502,
            "Qwen/Qwen2.5-3B-Instruct": 0.0031741754229767556,
            "Qwen/Qwen2.5-7B": 0.0030910322750064144,
            "Qwen/Qwen2.5-7B-Instruct": 0.003044001206344428,
            "google/gemma-2-2b": 0.0033291757724303616,
            "google/gemma-2-2b-it": 0.003354781964643287,
            "google/gemma-2-9b": 0.0029102762884621308,
            "google/gemma-2-9b-it": 0.0029233473229110097,
            "google/gemma-2b": 0.0035602476846261955,
            "google/gemma-2b-it": 0.0036410551114402718,
            "google/gemma-7b": 0.0029789935636681595,
            "google/gemma-7b-it": 0.003139536233562422,
            "meta-llama/Llama-3.1-8B": 0.0031108432975892144,
            "meta-llama/Llama-3.1-8B-Instruct": 0.0029957995149335194,
            "meta-llama/Llama-3.2-1B": 0.0036211975793988393,
            "meta-llama/Llama-3.2-1B-Instruct": 0.003682997330584373,
            "meta-llama/Llama-3.2-3B": 0.003339693290686817,
            "meta-llama/Llama-3.2-3B-Instruct": 0.003240402520559028,
            "meta-llama/Meta-Llama-3-8B": 0.0031843200218838407,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.003072356851722074,
            "openai-community/gpt2": 0.004974889764260093,
            "openai-community/gpt2-large": 0.004212242108273915,
            "openai-community/gpt2-medium": 0.004649858028257702,
            "openai-community/gpt2-xl": 0.0039914972419911755
        },
        "qqp": {
            "01-ai/Yi-1.5-6B": 0.003240399052370216,
            "01-ai/Yi-1.5-6B-Chat": 0.003250946918297234,
            "01-ai/Yi-1.5-9B": 0.0031501275101707,
            "01-ai/Yi-1.5-9B-Chat": 0.003184334938240374,
            "01-ai/Yi-6B": 0.003234513442191926,
            "01-ai/Yi-6B-Chat": 0.0032167453652835938,
            "01-ai/Yi-9B": 0.003129054026045372,
            "EleutherAI/pythia-1.4b-deduped": 0.003533242757077432,
            "EleutherAI/pythia-12b": 0.003310753253975822,
            "EleutherAI/pythia-160m-deduped": 0.004101473175363213,
            "EleutherAI/pythia-1b-deduped": 0.003684692347505882,
            "EleutherAI/pythia-2.8b-deduped": 0.003432299822014992,
            "EleutherAI/pythia-410m-deduped": 0.0036578760238285533,
            "EleutherAI/pythia-6.9b-deduped": 0.0033969976389888823,
            "EleutherAI/pythia-70m-deduped": 0.004547507777090219,
            "Qwen/Qwen1.5-0.5B": 0.003516135850778592,
            "Qwen/Qwen1.5-0.5B-Chat": 0.0035422328750907895,
            "Qwen/Qwen1.5-1.8B": 0.003363202508489611,
            "Qwen/Qwen1.5-1.8B-Chat": 0.0034596382628376233,
            "Qwen/Qwen1.5-14B": 0.0031439536326807512,
            "Qwen/Qwen1.5-14B-Chat": 0.0031513598821637854,
            "Qwen/Qwen1.5-4B": 0.0033016761056331723,
            "Qwen/Qwen1.5-4B-Chat": 0.0032879768976083403,
            "Qwen/Qwen1.5-7B": 0.0031648634466691127,
            "Qwen/Qwen1.5-7B-Chat": 0.003223872723221605,
            "Qwen/Qwen2-0.5B": 0.0034988627015103834,
            "Qwen/Qwen2-0.5B-Instruct": 0.0035699122436473525,
            "Qwen/Qwen2-1.5B": 0.0033850769377647373,
            "Qwen/Qwen2-1.5B-Instruct": 0.0033730782329613705,
            "Qwen/Qwen2-7B": 0.0032226867007139753,
            "Qwen/Qwen2-7B-Instruct": 0.003193996111631568,
            "Qwen/Qwen2.5-0.5B": 0.003490675934808275,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.003482451542645576,
            "Qwen/Qwen2.5-1.5B": 0.0033343718754183086,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.0033643024318698437,
            "Qwen/Qwen2.5-14B": 0.0031488943382649037,
            "Qwen/Qwen2.5-14B-Instruct": 0.003134033537890695,
            "Qwen/Qwen2.5-3B": 0.0032660787998874787,
            "Qwen/Qwen2.5-3B-Instruct": 0.003326532365956819,
            "Qwen/Qwen2.5-7B": 0.0032309732154245,
            "Qwen/Qwen2.5-7B-Instruct": 0.003230973215424507,
            "google/gemma-2-2b": 0.0032914111470212,
            "google/gemma-2-2b-it": 0.0032509469182972358,
            "google/gemma-2-9b": 0.0030963660552777317,
            "google/gemma-2-9b-it": 0.00310016646379066,
            "google/gemma-2b": 0.003381812334454208,
            "google/gemma-2b-it": 0.0034460206769332392,
            "google/gemma-7b": 0.003101431586830064,
            "google/gemma-7b-it": 0.0032238727232216115,
            "meta-llama/Llama-3.1-8B": 0.0032415739664829195,
            "meta-llama/Llama-3.1-8B-Instruct": 0.0031215602531170865,
            "meta-llama/Llama-3.2-1B": 0.003610626353178245,
            "meta-llama/Llama-3.2-1B-Instruct": 0.003637246479989166,
            "meta-llama/Llama-3.2-3B": 0.0032345134421919264,
            "meta-llama/Llama-3.2-3B-Instruct": 0.003253282862731212,
            "meta-llama/Meta-Llama-3-8B": 0.0031891716920867115,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.0031673083500378756,
            "openai-community/gpt2": 0.004530874957752746,
            "openai-community/gpt2-large": 0.0038750356888885788,
            "openai-community/gpt2-medium": 0.004006187833101672,
            "openai-community/gpt2-xl": 0.0036911019253528616
        },
        "medmcqa": {
            "01-ai/Yi-1.5-6B": 0.007730510449139376,
            "01-ai/Yi-1.5-6B-Chat": 0.007731222837978419,
            "01-ai/Yi-1.5-9B": 0.007697901859616346,
            "01-ai/Yi-1.5-9B-Chat": 0.0077236890515628084,
            "01-ai/Yi-6B": 0.007731567518690546,
            "01-ai/Yi-6B-Chat": 0.007730761472051617,
            "01-ai/Yi-9B": 0.007704173159214641,
            "EleutherAI/pythia-1.4b-deduped": 0.007332381052559276,
            "EleutherAI/pythia-12b": 0.007557526665342863,
            "EleutherAI/pythia-160m-deduped": 0.007179142455150485,
            "EleutherAI/pythia-1b-deduped": 0.007300815183841823,
            "EleutherAI/pythia-2.8b-deduped": 0.007387089578379928,
            "EleutherAI/pythia-410m-deduped": 0.007257136149169803,
            "EleutherAI/pythia-6.9b-deduped": 0.007443773762172333,
            "EleutherAI/pythia-70m-deduped": 0.007215408940601057,
            "Qwen/Qwen1.5-0.5B": 0.007459124348338145,
            "Qwen/Qwen1.5-0.5B-Chat": 0.007464142651472144,
            "Qwen/Qwen1.5-1.8B": 0.007626764178557262,
            "Qwen/Qwen1.5-1.8B-Chat": 0.00760409054054968,
            "Qwen/Qwen1.5-14B": 0.007700287471840111,
            "Qwen/Qwen1.5-14B-Chat": 0.007705411199384129,
            "Qwen/Qwen1.5-4B": 0.007720560194692371,
            "Qwen/Qwen1.5-4B-Chat": 0.0077137866902373215,
            "Qwen/Qwen1.5-7B": 0.007731482675633091,
            "Qwen/Qwen1.5-7B-Chat": 0.00773174250455599,
            "Qwen/Qwen2-0.5B": 0.007507108791179476,
            "Qwen/Qwen2-0.5B-Instruct": 0.007505282704916293,
            "Qwen/Qwen2-1.5B": 0.0077019377977405835,
            "Qwen/Qwen2-1.5B-Instruct": 0.007682163855491931,
            "Qwen/Qwen2-7B": 0.0076427128231402915,
            "Qwen/Qwen2-7B-Instruct": 0.007652603577086075,
            "Qwen/Qwen2.5-0.5B": 0.007592257648880116,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.007597195206932143,
            "Qwen/Qwen2.5-1.5B": 0.007731417275141056,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.007731751342120646,
            "Qwen/Qwen2.5-14B": 0.007342207783909779,
            "Qwen/Qwen2.5-14B-Instruct": 0.0073494911138690154,
            "Qwen/Qwen2.5-3B": 0.0077025854096725,
            "Qwen/Qwen2.5-3B-Instruct": 0.00769790185961633,
            "Qwen/Qwen2.5-7B": 0.007519675437152963,
            "Qwen/Qwen2.5-7B-Instruct": 0.007545338214752293,
            "google/gemma-2-2b": 0.007724670982263927,
            "google/gemma-2-2b-it": 0.007725138019007774,
            "google/gemma-2-9b": 0.0074856410307129004,
            "google/gemma-2-9b-it": 0.007576143266316069,
            "google/gemma-2b": 0.007542849243390628,
            "google/gemma-2b-it": 0.007499758046017744,
            "google/gemma-7b": 0.007701611309710367,
            "google/gemma-7b-it": 0.007731222837978419,
            "meta-llama/Llama-3.1-8B": 0.007621781227555943,
            "meta-llama/Llama-3.1-8B-Instruct": 0.0075630687543374485,
            "meta-llama/Llama-3.2-1B": 0.0075813689208232395,
            "meta-llama/Llama-3.2-1B-Instruct": 0.007711442469747751,
            "meta-llama/Llama-3.2-3B": 0.007729499203862675,
            "meta-llama/Llama-3.2-3B-Instruct": 0.007674751072859456,
            "meta-llama/Meta-Llama-3-8B": 0.007610137463421738,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.00752494575380959,
            "openai-community/gpt2": 0.00720682971566475,
            "openai-community/gpt2-large": 0.007212557911816367,
            "openai-community/gpt2-medium": 0.007187971470479771,
            "openai-community/gpt2-xl": 0.0072969394448325915
        },
        "qnli": {
            "01-ai/Yi-1.5-6B": 0.0039572068992154005,
            "01-ai/Yi-1.5-6B-Chat": 0.004018305845766353,
            "01-ai/Yi-1.5-9B": 0.0036046415204373686,
            "01-ai/Yi-1.5-9B-Chat": 0.0036085723755247172,
            "01-ai/Yi-6B": 0.004018305845766351,
            "01-ai/Yi-6B-Chat": 0.003998098517044735,
            "01-ai/Yi-9B": 0.003639805721031519,
            "EleutherAI/pythia-1.4b-deduped": 0.004444170104000489,
            "EleutherAI/pythia-12b": 0.004306910949176775,
            "EleutherAI/pythia-160m-deduped": 0.0060045542486462,
            "EleutherAI/pythia-1b-deduped": 0.004842490124221214,
            "EleutherAI/pythia-2.8b-deduped": 0.004306910949176793,
            "EleutherAI/pythia-410m-deduped": 0.004934887599076953,
            "EleutherAI/pythia-6.9b-deduped": 0.004145956032516131,
            "EleutherAI/pythia-70m-deduped": 0.006607070916464524,
            "Qwen/Qwen1.5-0.5B": 0.004547216769536722,
            "Qwen/Qwen1.5-0.5B-Chat": 0.004625109710321971,
            "Qwen/Qwen1.5-1.8B": 0.004455516058616389,
            "Qwen/Qwen1.5-1.8B-Chat": 0.004401163672409669,
            "Qwen/Qwen1.5-14B": 0.003808806191016834,
            "Qwen/Qwen1.5-14B-Chat": 0.003412764013677147,
            "Qwen/Qwen1.5-4B": 0.0039261110558828135,
            "Qwen/Qwen1.5-4B-Chat": 0.0038341345677489536,
            "Qwen/Qwen1.5-7B": 0.004300903078130619,
            "Qwen/Qwen1.5-7B-Chat": 0.004184001028472643,
            "Qwen/Qwen2-0.5B": 0.004667055545693299,
            "Qwen/Qwen2-0.5B-Instruct": 0.0047412926145457375,
            "Qwen/Qwen2-1.5B": 0.004158699972126895,
            "Qwen/Qwen2-1.5B-Instruct": 0.004224593883138198,
            "Qwen/Qwen2-7B": 0.0039051722492340715,
            "Qwen/Qwen2-7B-Instruct": 0.0035002753381874543,
            "Qwen/Qwen2.5-0.5B": 0.004560822203299759,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.004659245141051089,
            "Qwen/Qwen2.5-1.5B": 0.004221493932907928,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.004252326825486579,
            "Qwen/Qwen2.5-14B": 0.003425450869142802,
            "Qwen/Qwen2.5-14B-Instruct": 0.0034838358688791715,
            "Qwen/Qwen2.5-3B": 0.0041650484823509614,
            "Qwen/Qwen2.5-3B-Instruct": 0.004184001028472643,
            "Qwen/Qwen2.5-7B": 0.004014948840281009,
            "Qwen/Qwen2.5-7B-Instruct": 0.0038269230094375587,
            "google/gemma-2-2b": 0.0040316906997442765,
            "google/gemma-2-2b-it": 0.0039051722492340676,
            "google/gemma-2-9b": 0.003348361487813718,
            "google/gemma-2-9b-it": 0.003382912860596221,
            "google/gemma-2b": 0.00429789385226696,
            "google/gemma-2b-it": 0.004500395762522918,
            "google/gemma-7b": 0.0035002753381874595,
            "google/gemma-7b-it": 0.003651421628182561,
            "meta-llama/Llama-3.1-8B": 0.0034422689920159512,
            "meta-llama/Llama-3.1-8B-Instruct": 0.003528793203420542,
            "meta-llama/Llama-3.2-1B": 0.004489250696075233,
            "meta-llama/Llama-3.2-1B-Instruct": 0.004392474149589471,
            "meta-llama/Llama-3.2-3B": 0.0037611032683173016,
            "meta-llama/Llama-3.2-3B-Instruct": 0.003670666364045661,
            "meta-llama/Meta-Llama-3-8B": 0.003592812906359811,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.0035247385704708814,
            "openai-community/gpt2": 0.006484078633675453,
            "openai-community/gpt2-large": 0.004771357299570262,
            "openai-community/gpt2-medium": 0.005191470121540631,
            "openai-community/gpt2-xl": 0.004212171655430906
        },
        "nq_open": {
            "01-ai/Yi-1.5-6B": 0.007122040691919676,
            "01-ai/Yi-1.5-6B-Chat": 0.006668701359410722,
            "01-ai/Yi-1.5-9B": 0.007119250342096245,
            "01-ai/Yi-1.5-9B-Chat": 0.0068634656923433806,
            "01-ai/Yi-6B": 0.007269358815419804,
            "01-ai/Yi-6B-Chat": 0.00724345705454912,
            "01-ai/Yi-9B": 0.006931957360088989,
            "EleutherAI/pythia-1.4b-deduped": 0.00439366535089773,
            "EleutherAI/pythia-12b": 0.00632980934806736,
            "EleutherAI/pythia-160m-deduped": 0.0007322856237378371,
            "EleutherAI/pythia-1b-deduped": 0.00416287223066696,
            "EleutherAI/pythia-2.8b-deduped": 0.00534828742564693,
            "EleutherAI/pythia-410m-deduped": 0.0031128788538948935,
            "EleutherAI/pythia-6.9b-deduped": 0.005914238146623014,
            "EleutherAI/pythia-70m-deduped": 0.00027700831024929465,
            "Qwen/Qwen1.5-0.5B": 0.004040762122902968,
            "Qwen/Qwen1.5-0.5B-Chat": 0.0036135679992750393,
            "Qwen/Qwen1.5-1.8B": 0.005586373744078811,
            "Qwen/Qwen1.5-1.8B-Chat": 0.005413578874179945,
            "Qwen/Qwen1.5-14B": 0.007193172503209453,
            "Qwen/Qwen1.5-14B-Chat": 0.007168856718678352,
            "Qwen/Qwen1.5-4B": 0.006430232396018775,
            "Qwen/Qwen1.5-4B-Chat": 0.006302109329371477,
            "Qwen/Qwen1.5-7B": 0.007163409353069921,
            "Qwen/Qwen1.5-7B-Chat": 0.006885494516318687,
            "Qwen/Qwen2-0.5B": 0.004194642030448928,
            "Qwen/Qwen2-0.5B-Instruct": 0.004090184022461513,
            "Qwen/Qwen2-1.5B": 0.005909668923441866,
            "Qwen/Qwen2-1.5B-Instruct": 0.0057062105252911124,
            "Qwen/Qwen2-7B": 0.00745395920155521,
            "Qwen/Qwen2-7B-Instruct": 0.007329966301285064,
            "Qwen/Qwen2.5-0.5B": 0.004415842989116645,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.004210406738090299,
            "Qwen/Qwen2.5-1.5B": 0.0057159868084659775,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.005303992642328075,
            "Qwen/Qwen2.5-14B": 0.007620020715279347,
            "Qwen/Qwen2.5-14B-Instruct": 0.007652007928608685,
            "Qwen/Qwen2.5-3B": 0.006512273009094542,
            "Qwen/Qwen2.5-3B-Instruct": 0.006188386539664677,
            "Qwen/Qwen2.5-7B": 0.007206542560563294,
            "Qwen/Qwen2.5-7B-Instruct": 0.007027777113360173,
            "google/gemma-2-2b": 0.006968410329911093,
            "google/gemma-2-2b-it": 0.006799288737208039,
            "google/gemma-2-9b": 0.007778685253168649,
            "google/gemma-2-9b-it": 0.0077891578015084955,
            "google/gemma-2b": 0.006099910582297896,
            "google/gemma-2b-it": 0.005375657787464505,
            "google/gemma-7b": 0.007615962616375114,
            "google/gemma-7b-it": 0.006989384476770957,
            "meta-llama/Llama-3.1-8B": 0.00769080970623956,
            "meta-llama/Llama-3.1-8B-Instruct": 0.007696517794921427,
            "meta-llama/Llama-3.2-1B": 0.006004148926495903,
            "meta-llama/Llama-3.2-1B-Instruct": 0.006479028484950475,
            "meta-llama/Llama-3.2-3B": 0.00726678596040361,
            "meta-llama/Llama-3.2-3B-Instruct": 0.007492386204905775,
            "meta-llama/Meta-Llama-3-8B": 0.007730157993934534,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.007595471646280537,
            "openai-community/gpt2": 0.002637102530600225,
            "openai-community/gpt2-large": 0.004264967337357165,
            "openai-community/gpt2-medium": 0.0036039851913301797,
            "openai-community/gpt2-xl": 0.004643258170908276
        },
        "sst2": {
            "01-ai/Yi-1.5-6B": 0.006650758661763594,
            "01-ai/Yi-1.5-6B-Chat": 0.006465652922909128,
            "01-ai/Yi-1.5-9B": 0.006741069840802485,
            "01-ai/Yi-1.5-9B-Chat": 0.007003727524286481,
            "01-ai/Yi-6B": 0.00646565292290913,
            "01-ai/Yi-6B-Chat": 0.006370728096817251,
            "01-ai/Yi-9B": 0.006829965930759219,
            "EleutherAI/pythia-1.4b-deduped": 0.007877625822323717,
            "EleutherAI/pythia-12b": 0.007574315252893994,
            "EleutherAI/pythia-160m-deduped": 0.010843320972287816,
            "EleutherAI/pythia-1b-deduped": 0.008899546636572709,
            "EleutherAI/pythia-2.8b-deduped": 0.007951171193360486,
            "EleutherAI/pythia-410m-deduped": 0.009325791021628792,
            "EleutherAI/pythia-6.9b-deduped": 0.007172439238806625,
            "EleutherAI/pythia-70m-deduped": 0.014319752619832407,
            "Qwen/Qwen1.5-0.5B": 0.00857685518570081,
            "Qwen/Qwen1.5-0.5B-Chat": 0.008642706843234276,
            "Qwen/Qwen1.5-1.8B": 0.007651566213462467,
            "Qwen/Qwen1.5-1.8B-Chat": 0.006829965930759219,
            "Qwen/Qwen1.5-14B": 0.006274126667738942,
            "Qwen/Qwen1.5-14B-Chat": 0.0059734423485802495,
            "Qwen/Qwen1.5-4B": 0.006829965930759218,
            "Qwen/Qwen1.5-4B-Chat": 0.0070886918283142464,
            "Qwen/Qwen1.5-7B": 0.006465652922909129,
            "Qwen/Qwen1.5-7B-Chat": 0.006741069840802477,
            "Qwen/Qwen2-0.5B": 0.00908566915284663,
            "Qwen/Qwen2-0.5B-Instruct": 0.008306413186332583,
            "Qwen/Qwen2-1.5B": 0.006829965930759219,
            "Qwen/Qwen2-1.5B-Instruct": 0.006829965930759219,
            "Qwen/Qwen2-7B": 0.006650758661763595,
            "Qwen/Qwen2-7B-Instruct": 0.006370728096817251,
            "Qwen/Qwen2.5-0.5B": 0.00902422217628586,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.00870788714183277,
            "Qwen/Qwen2.5-1.5B": 0.0072550118971052915,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.007172439238806625,
            "Qwen/Qwen2.5-14B": 0.00627412666773894,
            "Qwen/Qwen2.5-14B-Instruct": 0.006370728096817251,
            "Qwen/Qwen2.5-3B": 0.006741069840802484,
            "Qwen/Qwen2.5-3B-Instruct": 0.006741069840802485,
            "Qwen/Qwen2.5-7B": 0.00691750148733552,
            "Qwen/Qwen2.5-7B-Instruct": 0.0064656529229091255,
            "google/gemma-2-2b": 0.007003727524286476,
            "google/gemma-2-2b-it": 0.006829965930759219,
            "google/gemma-2-9b": 0.006175769959874657,
            "google/gemma-2-9b-it": 0.006558973940386769,
            "google/gemma-2b": 0.0066507586617636,
            "google/gemma-2b-it": 0.007496066820449868,
            "google/gemma-7b": 0.006650758661763597,
            "google/gemma-7b-it": 0.007003727524286477,
            "meta-llama/Llama-3.1-8B": 0.006829965930759219,
            "meta-llama/Llama-3.1-8B-Instruct": 0.007172439238806629,
            "meta-llama/Llama-3.2-1B": 0.007336449469266882,
            "meta-llama/Llama-3.2-1B-Instruct": 0.0077278496157066855,
            "meta-llama/Llama-3.2-3B": 0.006274126667738941,
            "meta-llama/Llama-3.2-3B-Instruct": 0.006465652922909131,
            "meta-llama/Meta-Llama-3-8B": 0.006741069840802488,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.0065589739403867755,
            "openai-community/gpt2": 0.010458867008246879,
            "openai-community/gpt2-large": 0.008642706843234258,
            "openai-community/gpt2-medium": 0.008707887141832765,
            "openai-community/gpt2-xl": 0.00802385432886917
        },
        "winogrande": {
            "01-ai/Yi-1.5-6B": 0.011585871710209411,
            "01-ai/Yi-1.5-6B-Chat": 0.011524466954090243,
            "01-ai/Yi-1.5-9B": 0.010814911009613981,
            "01-ai/Yi-1.5-9B-Chat": 0.011134099415938273,
            "01-ai/Yi-6B": 0.011493384687249794,
            "01-ai/Yi-6B-Chat": 0.011430450045881582,
            "01-ai/Yi-9B": 0.010941877955676206,
            "EleutherAI/pythia-1.4b-deduped": 0.013546284512919643,
            "EleutherAI/pythia-12b": 0.012789321118542613,
            "EleutherAI/pythia-160m-deduped": 0.014033980956108553,
            "EleutherAI/pythia-1b-deduped": 0.0137510925198067,
            "EleutherAI/pythia-2.8b-deduped": 0.013214432542517552,
            "EleutherAI/pythia-410m-deduped": 0.013946933444507032,
            "EleutherAI/pythia-6.9b-deduped": 0.012675392786772727,
            "EleutherAI/pythia-70m-deduped": 0.014047122916440415,
            "Qwen/Qwen1.5-0.5B": 0.01372240046200089,
            "Qwen/Qwen1.5-0.5B-Chat": 0.013829128358676869,
            "Qwen/Qwen1.5-1.8B": 0.013190169546797016,
            "Qwen/Qwen1.5-1.8B-Chat": 0.01330771492894175,
            "Qwen/Qwen1.5-14B": 0.010684179227706163,
            "Qwen/Qwen1.5-14B-Chat": 0.010887916013305889,
            "Qwen/Qwen1.5-4B": 0.012198489100259769,
            "Qwen/Qwen1.5-4B-Chat": 0.012121402942855563,
            "Qwen/Qwen1.5-7B": 0.011430450045881571,
            "Qwen/Qwen1.5-7B-Chat": 0.011601066079939324,
            "Qwen/Qwen2-0.5B": 0.013660946109442015,
            "Qwen/Qwen2-0.5B-Instruct": 0.013605544523788019,
            "Qwen/Qwen2-1.5B": 0.01275881344806461,
            "Qwen/Qwen2-1.5B-Instruct": 0.01259989664949388,
            "Qwen/Qwen2-7B": 0.010490608806828079,
            "Qwen/Qwen2-7B-Instruct": 0.010626964529971866,
            "Qwen/Qwen2.5-0.5B": 0.013655578215970425,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.013746404157154956,
            "Qwen/Qwen2.5-1.5B": 0.012654062850971383,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.012487904760626304,
            "Qwen/Qwen2.5-14B": 0.009650242900291598,
            "Qwen/Qwen2.5-14B-Instruct": 0.009579311739938538,
            "Qwen/Qwen2.5-3B": 0.012002078629485739,
            "Qwen/Qwen2.5-3B-Instruct": 0.012002078629485737,
            "Qwen/Qwen2.5-7B": 0.01068417922770615,
            "Qwen/Qwen2.5-7B-Instruct": 0.010740676861359202,
            "google/gemma-2-2b": 0.011524466954090254,
            "google/gemma-2-2b-it": 0.01135031570746207,
            "google/gemma-2-9b": 0.009310542237486195,
            "google/gemma-2-9b-it": 0.009650242900291591,
            "google/gemma-2b": 0.01238284929965847,
            "google/gemma-2b-it": 0.013148883320923151,
            "google/gemma-7b": 0.009285404952684427,
            "google/gemma-7b-it": 0.010851565594267204,
            "meta-llama/Llama-3.1-8B": 0.010034394804580809,
            "meta-llama/Llama-3.1-8B-Instruct": 0.009834691297450139,
            "meta-llama/Llama-3.2-1B": 0.012868639066091543,
            "meta-llama/Llama-3.2-1B-Instruct": 0.013097928420088771,
            "meta-llama/Llama-3.2-3B": 0.011555295286059282,
            "meta-llama/Llama-3.2-3B-Instruct": 0.011524466954090254,
            "meta-llama/Meta-Llama-3-8B": 0.009743307618298136,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.01005609463147968,
            "openai-community/gpt2": 0.014045126130978598,
            "openai-community/gpt2-large": 0.013833112857645937,
            "openai-community/gpt2-medium": 0.013901878072575055,
            "openai-community/gpt2-xl": 0.013422874824929713
        },
        "hellaswag": {
            "01-ai/Yi-1.5-6B": 0.003968351141353192,
            "01-ai/Yi-1.5-6B-Chat": 0.004059690518834021,
            "01-ai/Yi-1.5-9B": 0.003805837547760843,
            "01-ai/Yi-1.5-9B-Chat": 0.003858638219487952,
            "01-ai/Yi-6B": 0.00407542045747306,
            "01-ai/Yi-6B-Chat": 0.004081095996720994,
            "01-ai/Yi-9B": 0.003935012507266661,
            "EleutherAI/pythia-1.4b-deduped": 0.0049416872652263575,
            "EleutherAI/pythia-12b": 0.004451657300968953,
            "EleutherAI/pythia-160m-deduped": 0.004644992636771521,
            "EleutherAI/pythia-1b-deduped": 0.004997359038505391,
            "EleutherAI/pythia-2.8b-deduped": 0.004798778785043389,
            "EleutherAI/pythia-410m-deduped": 0.004959376527503515,
            "EleutherAI/pythia-6.9b-deduped": 0.004542462261410801,
            "EleutherAI/pythia-70m-deduped": 0.004468886672853918,
            "Qwen/Qwen1.5-0.5B": 0.004994864449320808,
            "Qwen/Qwen1.5-0.5B-Chat": 0.004997938969154628,
            "Qwen/Qwen1.5-1.8B": 0.004790491194083232,
            "Qwen/Qwen1.5-1.8B-Chat": 0.00481649985644012,
            "Qwen/Qwen1.5-14B": 0.0037670246943049203,
            "Qwen/Qwen1.5-14B-Chat": 0.003780931835480884,
            "Qwen/Qwen1.5-4B": 0.004314055760848356,
            "Qwen/Qwen1.5-4B-Chat": 0.004376664428437887,
            "Qwen/Qwen1.5-7B": 0.003991171375034779,
            "Qwen/Qwen1.5-7B-Chat": 0.004047411784612115,
            "Qwen/Qwen2-0.5B": 0.0049981469713600455,
            "Qwen/Qwen2-0.5B-Instruct": 0.004997846821110144,
            "Qwen/Qwen2-1.5B": 0.004623518323979133,
            "Qwen/Qwen2-1.5B-Instruct": 0.00463777855217202,
            "Qwen/Qwen2-7B": 0.0037765986376272626,
            "Qwen/Qwen2-7B-Instruct": 0.0038337148742405257,
            "Qwen/Qwen2.5-0.5B": 0.004979136288536068,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.00498532740639317,
            "Qwen/Qwen2.5-1.5B": 0.004552521119649508,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.004559756039253643,
            "Qwen/Qwen2.5-14B": 0.0034627662460825566,
            "Qwen/Qwen2.5-14B-Instruct": 0.003451270364186437,
            "Qwen/Qwen2.5-3B": 0.004231417550827675,
            "Qwen/Qwen2.5-3B-Instruct": 0.0042520168114314905,
            "Qwen/Qwen2.5-7B": 0.0038244766520615005,
            "Qwen/Qwen2.5-7B-Instruct": 0.0038528580886852265,
            "google/gemma-2-2b": 0.004106345967855155,
            "google/gemma-2-2b-it": 0.004164786374419881,
            "google/gemma-2-9b": 0.0034917013328491582,
            "google/gemma-2-9b-it": 0.0035161358507785974,
            "google/gemma-2b": 0.0043475268945700404,
            "google/gemma-2b-it": 0.004683982703789228,
            "google/gemma-7b": 0.0034565048448645993,
            "google/gemma-7b-it": 0.0039041193904417178,
            "meta-llama/Llama-3.1-8B": 0.003552168463076912,
            "meta-llama/Llama-3.1-8B-Instruct": 0.003725474857825543,
            "meta-llama/Llama-3.2-1B": 0.004632517892269899,
            "meta-llama/Llama-3.2-1B-Instruct": 0.004740355060183553,
            "meta-llama/Llama-3.2-3B": 0.004058251586655773,
            "meta-llama/Llama-3.2-3B-Instruct": 0.004237697465367181,
            "meta-llama/Meta-Llama-3-8B": 0.0035432289577647883,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.0037415118456434744,
            "openai-community/gpt2": 0.0046445939785223446,
            "openai-community/gpt2-large": 0.004993115672645018,
            "openai-community/gpt2-medium": 0.004923443411831069,
            "openai-community/gpt2-xl": 0.0049827461079084544
        },
        "social_iqa": {
            "01-ai/Yi-1.5-6B": 0.011208746100567539,
            "01-ai/Yi-1.5-6B-Chat": 0.011149563396737514,
            "01-ai/Yi-1.5-9B": 0.0111352831165402,
            "01-ai/Yi-1.5-9B-Chat": 0.01105216279972923,
            "01-ai/Yi-6B": 0.01121958660402261,
            "01-ai/Yi-6B-Chat": 0.011225513656335435,
            "01-ai/Yi-9B": 0.0111707785177056,
            "EleutherAI/pythia-1.4b-deduped": 0.01131215019955958,
            "EleutherAI/pythia-12b": 0.011262695440459563,
            "EleutherAI/pythia-160m-deduped": 0.01106715017116851,
            "EleutherAI/pythia-1b-deduped": 0.011313590496725468,
            "EleutherAI/pythia-2.8b-deduped": 0.01130152308089513,
            "EleutherAI/pythia-410m-deduped": 0.011290523693989227,
            "EleutherAI/pythia-6.9b-deduped": 0.011257008360485704,
            "EleutherAI/pythia-70m-deduped": 0.01086339710114478,
            "Qwen/Qwen1.5-0.5B": 0.011312150199559577,
            "Qwen/Qwen1.5-0.5B-Chat": 0.011305954237876725,
            "Qwen/Qwen1.5-1.8B": 0.011295469697754305,
            "Qwen/Qwen1.5-1.8B-Chat": 0.011295469697754305,
            "Qwen/Qwen1.5-14B": 0.01121655016704626,
            "Qwen/Qwen1.5-14B-Chat": 0.011213465070419024,
            "Qwen/Qwen1.5-4B": 0.01124343708855983,
            "Qwen/Qwen1.5-4B-Chat": 0.01123264945045846,
            "Qwen/Qwen1.5-7B": 0.011262695440459563,
            "Qwen/Qwen1.5-7B-Chat": 0.01127217546233142,
            "Qwen/Qwen2-0.5B": 0.011313922391063574,
            "Qwen/Qwen2-0.5B-Instruct": 0.011314017216229127,
            "Qwen/Qwen2-1.5B": 0.01125816983012228,
            "Qwen/Qwen2-1.5B-Instruct": 0.011274150206980896,
            "Qwen/Qwen2-7B": 0.011172633149198362,
            "Qwen/Qwen2-7B-Instruct": 0.011165140708170332,
            "Qwen/Qwen2.5-0.5B": 0.011311930878965485,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.011310365873459969,
            "Qwen/Qwen2.5-1.5B": 0.011306387176133572,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.011300971289127725,
            "Qwen/Qwen2.5-14B": 0.011124710055682831,
            "Qwen/Qwen2.5-14B-Instruct": 0.011091116859712414,
            "Qwen/Qwen2.5-3B": 0.011261582070818423,
            "Qwen/Qwen2.5-3B-Instruct": 0.011264886135301362,
            "Qwen/Qwen2.5-7B": 0.011202283451328801,
            "Qwen/Qwen2.5-7B-Instruct": 0.01122696506802993,
            "google/gemma-2-2b": 0.011181721793948341,
            "google/gemma-2-2b-it": 0.011203917417496408,
            "google/gemma-2-9b": 0.01103932371486307,
            "google/gemma-2-9b-it": 0.011018117166352584,
            "google/gemma-2b": 0.01124978669111037,
            "google/gemma-2b-it": 0.01127511960864089,
            "google/gemma-7b": 0.01103932371486307,
            "google/gemma-7b-it": 0.011208746100567539,
            "meta-llama/Llama-3.1-8B": 0.011076888352430788,
            "meta-llama/Llama-3.1-8B-Instruct": 0.011159391894922484,
            "meta-llama/Llama-3.2-1B": 0.011284155418573435,
            "meta-llama/Llama-3.2-1B-Instruct": 0.011288225113420688,
            "meta-llama/Llama-3.2-3B": 0.011207148736838415,
            "meta-llama/Llama-3.2-3B-Instruct": 0.01123264945045846,
            "meta-llama/Meta-Llama-3-8B": 0.011100350776719533,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.011023495621289051,
            "openai-community/gpt2": 0.01118172179394835,
            "openai-community/gpt2-large": 0.011311930878965485,
            "openai-community/gpt2-medium": 0.011310365873459967,
            "openai-community/gpt2-xl": 0.011313353423379519
        },
        "mathqa": {
            "01-ai/Yi-1.5-6B": 0.009133195033764802,
            "01-ai/Yi-1.5-6B-Chat": 0.009152829298704836,
            "01-ai/Yi-1.5-9B": 0.009152964901259409,
            "01-ai/Yi-1.5-9B-Chat": 0.008999295765896503,
            "01-ai/Yi-6B": 0.009013736214156801,
            "01-ai/Yi-6B-Chat": 0.008966965103553649,
            "01-ai/Yi-9B": 0.009151814270331219,
            "EleutherAI/pythia-1.4b-deduped": 0.008075828043828068,
            "EleutherAI/pythia-12b": 0.008607744513455914,
            "EleutherAI/pythia-160m-deduped": 0.00771742016397431,
            "EleutherAI/pythia-1b-deduped": 0.007929514491487077,
            "EleutherAI/pythia-2.8b-deduped": 0.008149508900211358,
            "EleutherAI/pythia-410m-deduped": 0.00770172129542906,
            "EleutherAI/pythia-6.9b-deduped": 0.008505336737478917,
            "EleutherAI/pythia-70m-deduped": 0.007649934243740958,
            "Qwen/Qwen1.5-0.5B": 0.00828194759084057,
            "Qwen/Qwen1.5-0.5B-Chat": 0.008130588103318487,
            "Qwen/Qwen1.5-1.8B": 0.00876411677630803,
            "Qwen/Qwen1.5-1.8B-Chat": 0.008801886007425446,
            "Qwen/Qwen1.5-14B": 0.009029494899856147,
            "Qwen/Qwen1.5-14B-Chat": 0.009050866889504896,
            "Qwen/Qwen1.5-4B": 0.009150260689063735,
            "Qwen/Qwen1.5-4B-Chat": 0.009128029560185102,
            "Qwen/Qwen1.5-7B": 0.009153125156233432,
            "Qwen/Qwen1.5-7B-Chat": 0.009152923809788317,
            "Qwen/Qwen2-0.5B": 0.008473198664496992,
            "Qwen/Qwen2-0.5B-Instruct": 0.008384979997770069,
            "Qwen/Qwen2-1.5B": 0.008960629362286622,
            "Qwen/Qwen2-1.5B-Instruct": 0.008959349082578243,
            "Qwen/Qwen2-7B": 0.009107115360699896,
            "Qwen/Qwen2-7B-Instruct": 0.00907907196890874,
            "Qwen/Qwen2.5-0.5B": 0.00868235658493748,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.008657447285509677,
            "Qwen/Qwen2.5-1.5B": 0.009078284844320902,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.009064258440573899,
            "Qwen/Qwen2.5-14B": 0.008515050796766767,
            "Qwen/Qwen2.5-14B-Instruct": 0.008524683195269084,
            "Qwen/Qwen2.5-3B": 0.009149779765210763,
            "Qwen/Qwen2.5-3B-Instruct": 0.009153137483422774,
            "Qwen/Qwen2.5-7B": 0.008914630187169306,
            "Qwen/Qwen2.5-7B-Instruct": 0.009002692899033464,
            "google/gemma-2-2b": 0.009038487527221499,
            "google/gemma-2-2b-it": 0.009051789361468615,
            "google/gemma-2-9b": 0.008898651183157292,
            "google/gemma-2-9b-it": 0.009059016293728623,
            "google/gemma-2b": 0.008773295678944346,
            "google/gemma-2b-it": 0.008638306737214718,
            "google/gemma-7b": 0.009069348265877526,
            "google/gemma-7b-it": 0.009149261818944321,
            "meta-llama/Llama-3.1-8B": 0.00915314570153999,
            "meta-llama/Llama-3.1-8B-Instruct": 0.00915292380978831,
            "meta-llama/Llama-3.2-1B": 0.008607744513455914,
            "meta-llama/Llama-3.2-1B-Instruct": 0.008682356584937467,
            "meta-llama/Llama-3.2-3B": 0.009095325337688257,
            "meta-llama/Llama-3.2-3B-Instruct": 0.009142344836973446,
            "meta-llama/Meta-Llama-3-8B": 0.009152656710730352,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.009153137483422778,
            "openai-community/gpt2": 0.007546978526071589,
            "openai-community/gpt2-large": 0.007748489498007528,
            "openai-community/gpt2-medium": 0.0076977793609442485,
            "openai-community/gpt2-xl": 0.007798054851247488
        },
        "anli_r1": {
            "01-ai/Yi-1.5-6B": 0.01484221315341124,
            "01-ai/Yi-1.5-6B-Chat": 0.014645596385722692,
            "01-ai/Yi-1.5-9B": 0.01429714686251791,
            "01-ai/Yi-1.5-9B-Chat": 0.014818724459095524,
            "01-ai/Yi-6B": 0.015019206922356951,
            "01-ai/Yi-6B-Chat": 0.015120172605483692,
            "01-ai/Yi-9B": 0.014593284892852625,
            "EleutherAI/pythia-1.4b-deduped": 0.015473313265859406,
            "EleutherAI/pythia-12b": 0.015812179641814895,
            "EleutherAI/pythia-160m-deduped": 0.015060472031706622,
            "EleutherAI/pythia-1b-deduped": 0.015438826294681776,
            "EleutherAI/pythia-2.8b-deduped": 0.015680876566375058,
            "EleutherAI/pythia-410m-deduped": 0.015402637476784373,
            "EleutherAI/pythia-6.9b-deduped": 0.015760691590136378,
            "EleutherAI/pythia-70m-deduped": 0.014865395385928369,
            "Qwen/Qwen1.5-0.5B": 0.015676630912181327,
            "Qwen/Qwen1.5-0.5B-Chat": 0.015693223928730377,
            "Qwen/Qwen1.5-1.8B": 0.01574315237958554,
            "Qwen/Qwen1.5-1.8B-Chat": 0.01578886595953901,
            "Qwen/Qwen1.5-14B": 0.014142984975740663,
            "Qwen/Qwen1.5-14B-Chat": 0.014190150117612028,
            "Qwen/Qwen1.5-4B": 0.015364734787007436,
            "Qwen/Qwen1.5-4B-Chat": 0.015480007449307985,
            "Qwen/Qwen1.5-7B": 0.014580006055436962,
            "Qwen/Qwen1.5-7B-Chat": 0.014526080235459543,
            "Qwen/Qwen2-0.5B": 0.015610338967577794,
            "Qwen/Qwen2-0.5B-Instruct": 0.0156403203170401,
            "Qwen/Qwen2-1.5B": 0.015672320237336206,
            "Qwen/Qwen2-1.5B-Instruct": 0.015693223928730377,
            "Qwen/Qwen2-7B": 0.01478291360099667,
            "Qwen/Qwen2-7B-Instruct": 0.014658474370509003,
            "Qwen/Qwen2.5-0.5B": 0.015693223928730377,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.01573017604600906,
            "Qwen/Qwen2.5-1.5B": 0.015712507211864197,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.015645087688113814,
            "Qwen/Qwen2.5-14B": 0.01347358666196722,
            "Qwen/Qwen2.5-14B-Instruct": 0.013434451402438676,
            "Qwen/Qwen2.5-3B": 0.015186527932040119,
            "Qwen/Qwen2.5-3B-Instruct": 0.015167928865407559,
            "Qwen/Qwen2.5-7B": 0.014385511563477352,
            "Qwen/Qwen2.5-7B-Instruct": 0.014370995982377939,
            "google/gemma-2-2b": 0.015599819048769616,
            "google/gemma-2-2b-it": 0.015549205052920675,
            "google/gemma-2-9b": 0.014236526215291338,
            "google/gemma-2-9b-it": 0.013663187134877665,
            "google/gemma-2b": 0.015818508944436656,
            "google/gemma-2b-it": 0.015708779894242676,
            "google/gemma-7b": 0.014282120955200478,
            "google/gemma-7b-it": 0.015080663991563093,
            "meta-llama/Llama-3.1-8B": 0.014696631960792506,
            "meta-llama/Llama-3.1-8B-Instruct": 0.014512395033543147,
            "meta-llama/Llama-3.2-1B": 0.01563058909047635,
            "meta-llama/Llama-3.2-1B-Instruct": 0.01574623586588068,
            "meta-llama/Llama-3.2-3B": 0.015549205052920675,
            "meta-llama/Llama-3.2-3B-Instruct": 0.015452824654081496,
            "meta-llama/Meta-Llama-3-8B": 0.014645596385722692,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.014658474370509001,
            "openai-community/gpt2": 0.015129868238451773,
            "openai-community/gpt2-large": 0.015167928865407557,
            "openai-community/gpt2-medium": 0.015380102325652694,
            "openai-community/gpt2-xl": 0.01534909100222535
        },
        "piqa": {
            "01-ai/Yi-1.5-6B": 0.008965417898903203,
            "01-ai/Yi-1.5-6B-Chat": 0.009069597302603998,
            "01-ai/Yi-1.5-9B": 0.008792353552929524,
            "01-ai/Yi-1.5-9B-Chat": 0.008803407033584013,
            "01-ai/Yi-6B": 0.009140767676615017,
            "01-ai/Yi-6B-Chat": 0.009269232237679918,
            "01-ai/Yi-9B": 0.009007448933095002,
            "EleutherAI/pythia-1.4b-deduped": 0.010316749863541369,
            "EleutherAI/pythia-12b": 0.009439460331609511,
            "EleutherAI/pythia-160m-deduped": 0.011294565805619019,
            "EleutherAI/pythia-1b-deduped": 0.010551314503108072,
            "EleutherAI/pythia-2.8b-deduped": 0.009971345364651074,
            "EleutherAI/pythia-410m-deduped": 0.010877964076613737,
            "EleutherAI/pythia-6.9b-deduped": 0.009521377378734174,
            "EleutherAI/pythia-70m-deduped": 0.011500864675166568,
            "Qwen/Qwen1.5-0.5B": 0.010581014740675607,
            "Qwen/Qwen1.5-0.5B-Chat": 0.010791876566843045,
            "Qwen/Qwen1.5-1.8B": 0.010164432237060478,
            "Qwen/Qwen1.5-1.8B-Chat": 0.010002002569708691,
            "Qwen/Qwen1.5-14B": 0.00897597103733804,
            "Qwen/Qwen1.5-14B-Chat": 0.00893357546306207,
            "Qwen/Qwen1.5-4B": 0.009466997964536386,
            "Qwen/Qwen1.5-4B-Chat": 0.009601236303553553,
            "Qwen/Qwen1.5-7B": 0.009259518041395774,
            "Qwen/Qwen1.5-7B-Chat": 0.00927891889800638,
            "Qwen/Qwen2-0.5B": 0.01073888904432516,
            "Qwen/Qwen2-0.5B-Instruct": 0.010695225308183138,
            "Qwen/Qwen2-1.5B": 0.009837063180625329,
            "Qwen/Qwen2-1.5B-Instruct": 0.009916841655042807,
            "Qwen/Qwen2-7B": 0.008792353552929528,
            "Qwen/Qwen2-7B-Instruct": 0.008901456201658624,
            "Qwen/Qwen2.5-0.5B": 0.010627574080514806,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.010644731559342459,
            "Qwen/Qwen2.5-1.5B": 0.009721489519176299,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.009738282586548365,
            "Qwen/Qwen2.5-14B": 0.008576062891075813,
            "Qwen/Qwen2.5-14B-Instruct": 0.008540788490471227,
            "Qwen/Qwen2.5-3B": 0.009411688039193577,
            "Qwen/Qwen2.5-3B-Instruct": 0.009430229076102505,
            "Qwen/Qwen2.5-7B": 0.00902828398468943,
            "Qwen/Qwen2.5-7B-Instruct": 0.008986493851714732,
            "google/gemma-2-2b": 0.009240006693317721,
            "google/gemma-2-2b-it": 0.009100273290473557,
            "google/gemma-2-9b": 0.008284765985226351,
            "google/gemma-2-9b-it": 0.008564339715636467,
            "google/gemma-2b": 0.009411688039193594,
            "google/gemma-2b-it": 0.0099010675864739,
            "google/gemma-7b": 0.008576062891075821,
            "google/gemma-7b-it": 0.009100273290473554,
            "meta-llama/Llama-3.1-8B": 0.00842089649424624,
            "meta-llama/Llama-3.1-8B-Instruct": 0.008691405463120394,
            "meta-llama/Llama-3.2-1B": 0.009661958616651764,
            "meta-llama/Llama-3.2-1B-Instruct": 0.010128421335088678,
            "meta-llama/Llama-3.2-3B": 0.009120578292758648,
            "meta-llama/Llama-3.2-3B-Instruct": 0.009439460331609507,
            "meta-llama/Meta-Llama-3-8B": 0.008469285282964496,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.008986493851714732,
            "openai-community/gpt2": 0.011260988628572336,
            "openai-community/gpt2-large": 0.010490509832327423,
            "openai-community/gpt2-medium": 0.011022346708970236,
            "openai-community/gpt2-xl": 0.010521147542454222
        },
        "sciq": {
            "01-ai/Yi-1.5-6B": 0.0051280890492752884,
            "01-ai/Yi-1.5-6B-Chat": 0.004536472151306486,
            "01-ai/Yi-1.5-9B": 0.004206387249611455,
            "01-ai/Yi-1.5-9B-Chat": 0.004939574819698482,
            "01-ai/Yi-6B": 0.004536472151306505,
            "01-ai/Yi-6B-Chat": 0.0049395748196984605,
            "01-ai/Yi-9B": 0.003969856390319407,
            "EleutherAI/pythia-1.4b-deduped": 0.006488921798427415,
            "EleutherAI/pythia-12b": 0.0049395748196984805,
            "EleutherAI/pythia-160m-deduped": 0.010499249222408035,
            "EleutherAI/pythia-1b-deduped": 0.006895472974897895,
            "EleutherAI/pythia-2.8b-deduped": 0.005397140829099187,
            "EleutherAI/pythia-410m-deduped": 0.007274401481697069,
            "EleutherAI/pythia-6.9b-deduped": 0.005893957816165541,
            "EleutherAI/pythia-70m-deduped": 0.014236526215291336,
            "Qwen/Qwen1.5-0.5B": 0.007395315455792963,
            "Qwen/Qwen1.5-0.5B-Chat": 0.007335175853706833,
            "Qwen/Qwen1.5-1.8B": 0.005972157622389642,
            "Qwen/Qwen1.5-1.8B-Chat": 0.006049181150584933,
            "Qwen/Qwen1.5-14B": 0.004640855259274701,
            "Qwen/Qwen1.5-14B-Chat": 0.0046408552592747026,
            "Qwen/Qwen1.5-4B": 0.004842256441727067,
            "Qwen/Qwen1.5-4B-Chat": 0.005309160685756975,
            "Qwen/Qwen1.5-7B": 0.005128089049275286,
            "Qwen/Qwen1.5-7B-Chat": 0.005309160685756969,
            "Qwen/Qwen2-0.5B": 0.007212976294639237,
            "Qwen/Qwen2-0.5B-Instruct": 0.007088105617246439,
            "Qwen/Qwen2-1.5B": 0.005733836139695438,
            "Qwen/Qwen2-1.5B-Instruct": 0.006125072776426104,
            "Qwen/Qwen2-7B": 0.004742730594656796,
            "Qwen/Qwen2-7B-Instruct": 0.005893957816165562,
            "Qwen/Qwen2.5-0.5B": 0.006273624021118759,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.006418114379799741,
            "Qwen/Qwen2.5-1.5B": 0.005483527064679195,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.006049181150584939,
            "Qwen/Qwen2.5-14B": 0.0034449771940998283,
            "Qwen/Qwen2.5-14B-Instruct": 0.0034449771940998296,
            "Qwen/Qwen2.5-3B": 0.004939574819698476,
            "Qwen/Qwen2.5-3B-Instruct": 0.005219506034410053,
            "Qwen/Qwen2.5-7B": 0.004742730594656795,
            "Qwen/Qwen2.5-7B-Instruct": 0.00442940398017834,
            "google/gemma-2-2b": 0.0038457495745029893,
            "google/gemma-2-2b-it": 0.004536472151306504,
            "google/gemma-2-9b": 0.0038457495745029893,
            "google/gemma-2-9b-it": 0.003717232548256568,
            "google/gemma-2b": 0.005483527064679197,
            "google/gemma-2b-it": 0.005483527064679196,
            "google/gemma-7b": 0.004206387249611457,
            "google/gemma-7b-it": 0.005034813735318225,
            "meta-llama/Llama-3.1-8B": 0.004206387249611445,
            "meta-llama/Llama-3.1-8B-Instruct": 0.004742730594656796,
            "meta-llama/Llama-3.2-1B": 0.005733836139695438,
            "meta-llama/Llama-3.2-1B-Instruct": 0.0056518088204523705,
            "meta-llama/Llama-3.2-3B": 0.004742730594656798,
            "meta-llama/Llama-3.2-3B-Instruct": 0.00530916068575698,
            "meta-llama/Meta-Llama-3-8B": 0.004319451082910631,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.004536472151306498,
            "openai-community/gpt2": 0.009899393819724444,
            "openai-community/gpt2-large": 0.007335175853706832,
            "openai-community/gpt2-medium": 0.008776162089491123,
            "openai-community/gpt2-xl": 0.0066959566781630425
        },
        "commonsense_qa": {
            "01-ai/Yi-1.5-6B": 0.01146601146601156,
            "01-ai/Yi-1.5-6B-Chat": 0.010944631509166471,
            "01-ai/Yi-1.5-9B": 0.010355597725566172,
            "01-ai/Yi-1.5-9B-Chat": 0.010310636908997377,
            "01-ai/Yi-6B": 0.011138085349810692,
            "01-ai/Yi-6B-Chat": 0.011377439773963998,
            "01-ai/Yi-9B": 0.010488065882609683,
            "EleutherAI/pythia-1.4b-deduped": 0.01181807998113251,
            "EleutherAI/pythia-12b": 0.013752163175220634,
            "EleutherAI/pythia-160m-deduped": 0.01132338158892044,
            "EleutherAI/pythia-1b-deduped": 0.011305207486827687,
            "EleutherAI/pythia-2.8b-deduped": 0.011654350093704639,
            "EleutherAI/pythia-410m-deduped": 0.011250215810979042,
            "EleutherAI/pythia-6.9b-deduped": 0.013710721907984807,
            "EleutherAI/pythia-70m-deduped": 0.011377439773963998,
            "Qwen/Qwen1.5-0.5B": 0.014103688261364239,
            "Qwen/Qwen1.5-0.5B-Chat": 0.014160295042824534,
            "Qwen/Qwen1.5-1.8B": 0.012702371110859815,
            "Qwen/Qwen1.5-1.8B-Chat": 0.012539269935510662,
            "Qwen/Qwen1.5-14B": 0.009583520162788628,
            "Qwen/Qwen1.5-14B-Chat": 0.009737356192047433,
            "Qwen/Qwen1.5-4B": 0.011250215810979056,
            "Qwen/Qwen1.5-4B-Chat": 0.011138085349810681,
            "Qwen/Qwen1.5-7B": 0.010400152719875544,
            "Qwen/Qwen1.5-7B-Chat": 0.010444307085591496,
            "Qwen/Qwen2-0.5B": 0.01400922779697557,
            "Qwen/Qwen2-0.5B-Instruct": 0.014095460431649807,
            "Qwen/Qwen2-1.5B": 0.012702371110859822,
            "Qwen/Qwen2-1.5B-Instruct": 0.01256498156855069,
            "Qwen/Qwen2-7B": 0.010008117273287272,
            "Qwen/Qwen2-7B-Instruct": 0.010196424045999063,
            "Qwen/Qwen2.5-0.5B": 0.013804994609275253,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.013885013183643134,
            "Qwen/Qwen2.5-1.5B": 0.011897367280936749,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.011959591224286237,
            "Qwen/Qwen2.5-14B": 0.009371194409542014,
            "Qwen/Qwen2.5-14B-Instruct": 0.009557438756843834,
            "Qwen/Qwen2.5-3B": 0.010944631509166443,
            "Qwen/Qwen2.5-3B-Instruct": 0.0110617062892271,
            "Qwen/Qwen2.5-7B": 0.009787648220812893,
            "Qwen/Qwen2.5-7B-Instruct": 0.010219476335668538,
            "google/gemma-2-2b": 0.012198105620413301,
            "google/gemma-2-2b-it": 0.012110575321206404,
            "google/gemma-2-9b": 0.01040015271987554,
            "google/gemma-2-9b-it": 0.010531434041771924,
            "google/gemma-2b": 0.013384596598191294,
            "google/gemma-2b-it": 0.013703662423177628,
            "google/gemma-7b": 0.011119113942559869,
            "google/gemma-7b-it": 0.011620759575652385,
            "meta-llama/Llama-3.1-8B": 0.011286955409752632,
            "meta-llama/Llama-3.1-8B-Instruct": 0.011194511993535687,
            "meta-llama/Llama-3.2-1B": 0.013638148645377822,
            "meta-llama/Llama-3.2-1B-Instruct": 0.013293298652678523,
            "meta-llama/Llama-3.2-3B": 0.012065956937275739,
            "meta-llama/Llama-3.2-3B-Instruct": 0.011802018846530008,
            "meta-llama/Meta-Llama-3-8B": 0.011175783964114738,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.01115697521917636,
            "openai-community/gpt2": 0.011769690686226967,
            "openai-community/gpt2-large": 0.011430809442838398,
            "openai-community/gpt2-medium": 0.011395305685091192,
            "openai-community/gpt2-xl": 0.011359497363584395
        },
        "boolq": {
            "01-ai/Yi-1.5-6B": 0.006058836805215607,
            "01-ai/Yi-1.5-6B-Chat": 0.006064398800434364,
            "01-ai/Yi-1.5-9B": 0.005668567656105763,
            "01-ai/Yi-1.5-9B-Chat": 0.005598715997431625,
            "01-ai/Yi-6B": 0.006157473358036365,
            "01-ai/Yi-6B-Chat": 0.00619500387506207,
            "01-ai/Yi-9B": 0.005533906722144422,
            "EleutherAI/pythia-1.4b-deduped": 0.007578066177621188,
            "EleutherAI/pythia-12b": 0.006881176207767817,
            "EleutherAI/pythia-160m-deduped": 0.00857485717167114,
            "EleutherAI/pythia-1b-deduped": 0.008126455592662892,
            "EleutherAI/pythia-2.8b-deduped": 0.007162771042787865,
            "EleutherAI/pythia-410m-deduped": 0.008184405497036666,
            "EleutherAI/pythia-6.9b-deduped": 0.007019998324744636,
            "EleutherAI/pythia-70m-deduped": 0.008488668235778606,
            "Qwen/Qwen1.5-0.5B": 0.007827672048734545,
            "Qwen/Qwen1.5-0.5B-Chat": 0.008060817222724522,
            "Qwen/Qwen1.5-1.8B": 0.007177709017498293,
            "Qwen/Qwen1.5-1.8B-Chat": 0.007247381540554087,
            "Qwen/Qwen1.5-14B": 0.005494404326399933,
            "Qwen/Qwen1.5-14B-Chat": 0.005649663619774152,
            "Qwen/Qwen1.5-4B": 0.006484496682279789,
            "Qwen/Qwen1.5-4B-Chat": 0.006345771299247062,
            "Qwen/Qwen1.5-7B": 0.00588727581405252,
            "Qwen/Qwen1.5-7B-Chat": 0.005933934730728073,
            "Qwen/Qwen2-0.5B": 0.007668245825988061,
            "Qwen/Qwen2-0.5B-Instruct": 0.007811603921650574,
            "Qwen/Qwen2-1.5B": 0.006817490804551452,
            "Qwen/Qwen2-1.5B-Instruct": 0.006756650144601172,
            "Qwen/Qwen2-7B": 0.005962755227936325,
            "Qwen/Qwen2-7B-Instruct": 0.005979923446403403,
            "Qwen/Qwen2.5-0.5B": 0.007632706635472526,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.00769154984743818,
            "Qwen/Qwen2.5-1.5B": 0.006607668323890537,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.006712343513449721,
            "Qwen/Qwen2.5-14B": 0.0052541569668459265,
            "Qwen/Qwen2.5-14B-Instruct": 0.005268359738949341,
            "Qwen/Qwen2.5-3B": 0.006108543856981417,
            "Qwen/Qwen2.5-3B-Instruct": 0.006069950986038657,
            "Qwen/Qwen2.5-7B": 0.005724635390906084,
            "Qwen/Qwen2.5-7B-Instruct": 0.005815995464335376,
            "google/gemma-2-2b": 0.00620564370061869,
            "google/gemma-2-2b-it": 0.006184327240690357,
            "google/gemma-2-9b": 0.005296586217287021,
            "google/gemma-2-9b-it": 0.005400367052923676,
            "google/gemma-2b": 0.0067522516301137024,
            "google/gemma-2b-it": 0.007059417421689211,
            "google/gemma-7b": 0.00527543865170794,
            "google/gemma-7b-it": 0.005779758379691729,
            "meta-llama/Llama-3.1-8B": 0.005579406099901818,
            "meta-llama/Llama-3.1-8B-Instruct": 0.005797927436388159,
            "meta-llama/Llama-3.2-1B": 0.0070476574653040615,
            "meta-llama/Llama-3.2-1B-Instruct": 0.007063324955682795,
            "meta-llama/Llama-3.2-3B": 0.0059397196503738125,
            "meta-llama/Llama-3.2-3B-Instruct": 0.006086548953378878,
            "meta-llama/Meta-Llama-3-8B": 0.005559982831707316,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.005592291889027319,
            "openai-community/gpt2": 0.008500443818876163,
            "openai-community/gpt2-large": 0.008204340208838751,
            "openai-community/gpt2-medium": 0.008388668034059417,
            "openai-community/gpt2-xl": 0.007792648863012159
        },
        "cola": {
            "01-ai/Yi-1.5-6B": 0.025450084039595137,
            "01-ai/Yi-1.5-6B-Chat": 0.028098260488116696,
            "01-ai/Yi-1.5-9B": 0.026594566116230477,
            "01-ai/Yi-1.5-9B-Chat": 0.02681497288971748,
            "01-ai/Yi-6B": 0.02631439767188486,
            "01-ai/Yi-6B-Chat": 0.026323329619472417,
            "01-ai/Yi-9B": 0.026457982658396037,
            "EleutherAI/pythia-1.4b-deduped": 0.03175901225803098,
            "EleutherAI/pythia-12b": 0.02837596307280356,
            "EleutherAI/pythia-160m-deduped": 0.03351654946641968,
            "EleutherAI/pythia-1b-deduped": 0.03177655477202764,
            "EleutherAI/pythia-2.8b-deduped": 0.029237050410856384,
            "EleutherAI/pythia-410m-deduped": 0.030997991107252907,
            "EleutherAI/pythia-6.9b-deduped": 0.029216651746935992,
            "EleutherAI/pythia-70m-deduped": 0.0,
            "Qwen/Qwen1.5-0.5B": 0.03073517074259324,
            "Qwen/Qwen1.5-0.5B-Chat": 0.03253104271270208,
            "Qwen/Qwen1.5-1.8B": 0.028859742816316054,
            "Qwen/Qwen1.5-1.8B-Chat": 0.02918924261223461,
            "Qwen/Qwen1.5-14B": 0.024446148470718545,
            "Qwen/Qwen1.5-14B-Chat": 0.025574852591536832,
            "Qwen/Qwen1.5-4B": 0.027277346819266794,
            "Qwen/Qwen1.5-4B-Chat": 0.026096412939855367,
            "Qwen/Qwen1.5-7B": 0.025184090783201076,
            "Qwen/Qwen1.5-7B-Chat": 0.025006169819840676,
            "Qwen/Qwen2-0.5B": 0.03158752661237388,
            "Qwen/Qwen2-0.5B-Instruct": 0.029783664277791437,
            "Qwen/Qwen2-1.5B": 0.028010421381200117,
            "Qwen/Qwen2-1.5B-Instruct": 0.027104603253243653,
            "Qwen/Qwen2-7B": 0.026164909151762675,
            "Qwen/Qwen2-7B-Instruct": 0.02382725325831468,
            "Qwen/Qwen2.5-0.5B": 0.03156199776500585,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.03203680153808743,
            "Qwen/Qwen2.5-1.5B": 0.027549950351499812,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.026472182292473258,
            "Qwen/Qwen2.5-14B": 0.024576369851483648,
            "Qwen/Qwen2.5-14B-Instruct": 0.024038659186002027,
            "Qwen/Qwen2.5-3B": 0.027032621595684998,
            "Qwen/Qwen2.5-3B-Instruct": 0.02755712069925106,
            "Qwen/Qwen2.5-7B": 0.02789258385180484,
            "Qwen/Qwen2.5-7B-Instruct": 0.025874661600209525,
            "google/gemma-2-2b": 0.02623014252847044,
            "google/gemma-2-2b-it": 0.02548752790943935,
            "google/gemma-2-9b": 0.025143503789254812,
            "google/gemma-2-9b-it": 0.02485404682809769,
            "google/gemma-2b": 0.027849506649029927,
            "google/gemma-2b-it": 0.03026402260821689,
            "google/gemma-7b": 0.024892764845434706,
            "google/gemma-7b-it": 0.02662355906473772,
            "meta-llama/Llama-3.1-8B": 0.025635247983980376,
            "meta-llama/Llama-3.1-8B-Instruct": 0.0260466022338645,
            "meta-llama/Llama-3.2-1B": 0.032374590523829766,
            "meta-llama/Llama-3.2-1B-Instruct": 0.03120591111478317,
            "meta-llama/Llama-3.2-3B": 0.02601767172716321,
            "meta-llama/Llama-3.2-3B-Instruct": 0.02684926634827015,
            "meta-llama/Meta-Llama-3-8B": 0.025948988976626317,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.02562602552089625,
            "openai-community/gpt2": 0.03388100741883993,
            "openai-community/gpt2-large": 0.0,
            "openai-community/gpt2-medium": 0.031520812021796366,
            "openai-community/gpt2-xl": 0.03317886594486574
        },
        "gsm8k": {
            "01-ai/Yi-1.5-6B": 0.013636344017393732,
            "01-ai/Yi-1.5-6B-Chat": 0.01293475801944961,
            "01-ai/Yi-1.5-9B": 0.013052097103299102,
            "01-ai/Yi-1.5-9B-Chat": 0.011718409178739444,
            "01-ai/Yi-6B": 0.013611632008810355,
            "01-ai/Yi-6B-Chat": 0.013524848894462116,
            "01-ai/Yi-9B": 0.013733636059107756,
            "EleutherAI/pythia-1.4b-deduped": 0.0066887625815327395,
            "EleutherAI/pythia-12b": 0.009650895723357603,
            "EleutherAI/pythia-160m-deduped": 0.00390041338591572,
            "EleutherAI/pythia-1b-deduped": 0.005647666449126458,
            "EleutherAI/pythia-2.8b-deduped": 0.008403622228924023,
            "EleutherAI/pythia-410m-deduped": 0.004365042953621816,
            "EleutherAI/pythia-6.9b-deduped": 0.009088880962028468,
            "EleutherAI/pythia-70m-deduped": 0.0034478192723890076,
            "Qwen/Qwen1.5-0.5B": 0.011505385424294627,
            "Qwen/Qwen1.5-0.5B-Chat": 0.009979689409499148,
            "Qwen/Qwen1.5-1.8B": 0.013298661207727129,
            "Qwen/Qwen1.5-1.8B-Chat": 0.012964999679688663,
            "Qwen/Qwen1.5-14B": 0.012919408108656426,
            "Qwen/Qwen1.5-14B-Chat": 0.01301646367998336,
            "Qwen/Qwen1.5-4B": 0.01376373837986793,
            "Qwen/Qwen1.5-4B-Chat": 0.013723629649844075,
            "Qwen/Qwen1.5-7B": 0.013588287284030887,
            "Qwen/Qwen1.5-7B-Chat": 0.013757748544245326,
            "Qwen/Qwen2-0.5B": 0.01297989249659828,
            "Qwen/Qwen2-0.5B-Instruct": 0.012493927348659629,
            "Qwen/Qwen2-1.5B": 0.013732048227016678,
            "Qwen/Qwen2-1.5B-Instruct": 0.013772290768858173,
            "Qwen/Qwen2-7B": 0.011930334350873347,
            "Qwen/Qwen2-7B-Instruct": 0.011930334350873359,
            "Qwen/Qwen2.5-0.5B": 0.01304504506766525,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.012696930106562912,
            "Qwen/Qwen2.5-1.5B": 0.013337170545742922,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.013771055751972868,
            "Qwen/Qwen2.5-14B": 0.010609827611527354,
            "Qwen/Qwen2.5-14B-Instruct": 0.010522533016890765,
            "Qwen/Qwen2.5-3B": 0.01290390475254392,
            "Qwen/Qwen2.5-3B-Instruct": 0.012872435481188778,
            "Qwen/Qwen2.5-7B": 0.011679491349994874,
            "Qwen/Qwen2.5-7B-Instruct": 0.011278447856900771,
            "google/gemma-2-2b": 0.013347858757829154,
            "google/gemma-2-2b-it": 0.013681937191764628,
            "google/gemma-2-9b": 0.012474469737197923,
            "google/gemma-2-9b-it": 0.011679491349994874,
            "google/gemma-2b": 0.011083227665267795,
            "google/gemma-2b-it": 0.011083227665267795,
            "google/gemma-7b": 0.013293019538066247,
            "google/gemma-7b-it": 0.01373966814754591,
            "meta-llama/Llama-3.1-8B": 0.013681937191764628,
            "meta-llama/Llama-3.1-8B-Instruct": 0.01211691241992571,
            "meta-llama/Llama-3.2-1B": 0.00911260143984964,
            "meta-llama/Llama-3.2-1B-Instruct": 0.013191685031357467,
            "meta-llama/Llama-3.2-3B": 0.013368818096960498,
            "meta-llama/Llama-3.2-3B-Instruct": 0.0132525392279662,
            "meta-llama/Meta-Llama-3-8B": 0.013679514492814583,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.011893980214826171,
            "openai-community/gpt2": 0.004172883669643979,
            "openai-community/gpt2-large": 0.004172883669643966,
            "openai-community/gpt2-medium": 0.004106620637749685,
            "openai-community/gpt2-xl": 0.005553837749990046
        },
        "wic": {
            "01-ai/Yi-1.5-6B": 0.01773971755936329,
            "01-ai/Yi-1.5-6B-Chat": 0.017581939727105412,
            "01-ai/Yi-1.5-9B": 0.01721003417159422,
            "01-ai/Yi-1.5-9B-Chat": 0.017417198212129913,
            "01-ai/Yi-6B": 0.01761404628103197,
            "01-ai/Yi-6B-Chat": 0.017483942871732945,
            "01-ai/Yi-9B": 0.017210034171594217,
            "EleutherAI/pythia-1.4b-deduped": 0.019224935042009696,
            "EleutherAI/pythia-12b": 0.019161437163076122,
            "EleutherAI/pythia-160m-deduped": 0.019691119425011446,
            "EleutherAI/pythia-1b-deduped": 0.019491899937012617,
            "EleutherAI/pythia-2.8b-deduped": 0.01911155652787343,
            "EleutherAI/pythia-410m-deduped": 0.019594518675279025,
            "EleutherAI/pythia-6.9b-deduped": 0.018832548146705784,
            "EleutherAI/pythia-70m-deduped": 0.01976355284279699,
            "Qwen/Qwen1.5-0.5B": 0.019355390973060372,
            "Qwen/Qwen1.5-0.5B-Chat": 0.01912839948322325,
            "Qwen/Qwen1.5-1.8B": 0.018931101762088596,
            "Qwen/Qwen1.5-1.8B-Chat": 0.018618347718723255,
            "Qwen/Qwen1.5-14B": 0.01713862293340346,
            "Qwen/Qwen1.5-14B-Chat": 0.017138622933403458,
            "Qwen/Qwen1.5-4B": 0.018199869129804796,
            "Qwen/Qwen1.5-4B-Chat": 0.017890715947548878,
            "Qwen/Qwen1.5-7B": 0.017800920613175168,
            "Qwen/Qwen1.5-7B-Chat": 0.01773971755936329,
            "Qwen/Qwen2-0.5B": 0.019145026173967922,
            "Qwen/Qwen2-0.5B-Instruct": 0.019077219524766206,
            "Qwen/Qwen2-1.5B": 0.0183806835536245,
            "Qwen/Qwen2-1.5B-Instruct": 0.01806320399560637,
            "Qwen/Qwen2-7B": 0.01731492839840711,
            "Qwen/Qwen2-7B-Instruct": 0.01695479903084289,
            "Qwen/Qwen2.5-0.5B": 0.018968956676665035,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.01872832851540424,
            "Qwen/Qwen2.5-1.5B": 0.018252769686469113,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.01861834771872325,
            "Qwen/Qwen2.5-14B": 0.016763209352943943,
            "Qwen/Qwen2.5-14B-Instruct": 0.017174477949858515,
            "Qwen/Qwen2.5-3B": 0.018199869129804796,
            "Qwen/Qwen2.5-3B-Instruct": 0.017739717559363287,
            "Qwen/Qwen2.5-7B": 0.01731492839840711,
            "Qwen/Qwen2.5-7B-Instruct": 0.01764587585679886,
            "google/gemma-2-2b": 0.018252769686469113,
            "google/gemma-2-2b-it": 0.017890715947548885,
            "google/gemma-2-9b": 0.016917110646390666,
            "google/gemma-2-9b-it": 0.01738339699197537,
            "google/gemma-2b": 0.01877070221505747,
            "google/gemma-2b-it": 0.018502503022054795,
            "google/gemma-7b": 0.017549554674841858,
            "google/gemma-7b-it": 0.017949255642255645,
            "meta-llama/Llama-3.1-8B": 0.01758193972710541,
            "meta-llama/Llama-3.1-8B-Instruct": 0.017677429950568063,
            "meta-llama/Llama-3.2-1B": 0.019565859392130985,
            "meta-llama/Llama-3.2-1B-Instruct": 0.019355390973060375,
            "meta-llama/Llama-3.2-3B": 0.018006748325781904,
            "meta-llama/Llama-3.2-3B-Instruct": 0.01794925564225564,
            "meta-llama/Meta-Llama-3-8B": 0.017245293446768537,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.017614046281031966,
            "openai-community/gpt2": 0.019809845219259773,
            "openai-community/gpt2-large": 0.019677012352567903,
            "openai-community/gpt2-medium": 0.019807216763271487,
            "openai-community/gpt2-xl": 0.01971695617658775
        },
        "openbookqa": {
            "01-ai/Yi-1.5-6B": 0.022380208834928035,
            "01-ai/Yi-1.5-6B-Chat": 0.022279694107843428,
            "01-ai/Yi-1.5-9B": 0.022288147591176952,
            "01-ai/Yi-1.5-9B-Chat": 0.022261697292270125,
            "01-ai/Yi-6B": 0.022380208834928028,
            "01-ai/Yi-6B-Chat": 0.022381462412439324,
            "01-ai/Yi-9B": 0.022279694107843424,
            "EleutherAI/pythia-1.4b-deduped": 0.021613289165165785,
            "EleutherAI/pythia-12b": 0.022311333245289673,
            "EleutherAI/pythia-160m-deduped": 0.019827714859587574,
            "EleutherAI/pythia-1b-deduped": 0.02104961216613481,
            "EleutherAI/pythia-2.8b-deduped": 0.0221989546414768,
            "EleutherAI/pythia-410m-deduped": 0.020514426225628046,
            "EleutherAI/pythia-6.9b-deduped": 0.02226169729227014,
            "EleutherAI/pythia-70m-deduped": 0.019332342821239103,
            "Qwen/Qwen1.5-0.5B": 0.02117566569520941,
            "Qwen/Qwen1.5-0.5B-Chat": 0.02126575803797874,
            "Qwen/Qwen1.5-1.8B": 0.022210326363977417,
            "Qwen/Qwen1.5-1.8B-Chat": 0.022080014812228137,
            "Qwen/Qwen1.5-14B": 0.022210326363977417,
            "Qwen/Qwen1.5-14B-Chat": 0.022210326363977417,
            "Qwen/Qwen1.5-4B": 0.022380208834928028,
            "Qwen/Qwen1.5-4B-Chat": 0.02236139673920786,
            "Qwen/Qwen1.5-7B": 0.022221331534143015,
            "Qwen/Qwen1.5-7B-Chat": 0.02236139673920788,
            "Qwen/Qwen2-0.5B": 0.021564276850201614,
            "Qwen/Qwen2-0.5B-Instruct": 0.0215391706373177,
            "Qwen/Qwen2-1.5B": 0.022162634426652835,
            "Qwen/Qwen2-1.5B-Instruct": 0.022064943313928876,
            "Qwen/Qwen2-7B": 0.022231970696321122,
            "Qwen/Qwen2-7B-Instruct": 0.02218721580302901,
            "Qwen/Qwen2.5-0.5B": 0.02168382753928611,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.02170655082451818,
            "Qwen/Qwen2.5-1.5B": 0.022361396739207867,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.02228814759117695,
            "Qwen/Qwen2.5-14B": 0.02156427685020162,
            "Qwen/Qwen2.5-14B-Instruct": 0.021834685869369205,
            "Qwen/Qwen2.5-3B": 0.02238235778196214,
            "Qwen/Qwen2.5-3B-Instruct": 0.02236856511738799,
            "Qwen/Qwen2.5-7B": 0.022000910893877193,
            "Qwen/Qwen2.5-7B-Instruct": 0.022303966774269948,
            "google/gemma-2-2b": 0.022357273881016403,
            "google/gemma-2-2b-it": 0.02230396677426994,
            "google/gemma-2-9b": 0.021706550824518184,
            "google/gemma-2-9b-it": 0.021706550824518184,
            "google/gemma-2b": 0.02238235778196213,
            "google/gemma-2b-it": 0.022000910893877196,
            "google/gemma-7b": 0.021854684955611256,
            "google/gemma-7b-it": 0.022162634426652835,
            "meta-llama/Llama-3.1-8B": 0.02191237788577997,
            "meta-llama/Llama-3.1-8B-Instruct": 0.022279694107843428,
            "meta-llama/Llama-3.2-1B": 0.022252153078595897,
            "meta-llama/Llama-3.2-1B-Instruct": 0.022187215803029004,
            "meta-llama/Llama-3.2-3B": 0.02236856511738799,
            "meta-llama/Llama-3.2-3B-Instruct": 0.0223716109825804,
            "meta-llama/Meta-Llama-3-8B": 0.022149790663861926,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.022303966774269938,
            "openai-community/gpt2": 0.019920483209566065,
            "openai-community/gpt2-large": 0.021352091786223104,
            "openai-community/gpt2-medium": 0.02055326917420919,
            "openai-community/gpt2-xl": 0.021513662527582408
        },
        "mrpc": {
            "01-ai/Yi-1.5-6B": 0.018026517751811688,
            "01-ai/Yi-1.5-6B-Chat": 0.018896375880916437,
            "01-ai/Yi-1.5-9B": 0.018998812901448246,
            "01-ai/Yi-1.5-9B-Chat": 0.01791110808112117,
            "01-ai/Yi-6B": 0.019679975237883465,
            "01-ai/Yi-6B-Chat": 0.018140379596178244,
            "01-ai/Yi-9B": 0.01767552357897546,
            "EleutherAI/pythia-1.4b-deduped": 0.021321511578472594,
            "EleutherAI/pythia-12b": 0.02102594605453768,
            "EleutherAI/pythia-160m-deduped": 0.02279883444316355,
            "EleutherAI/pythia-1b-deduped": 0.021932668544150193,
            "EleutherAI/pythia-2.8b-deduped": 0.02153332842706632,
            "EleutherAI/pythia-410m-deduped": 0.02258548906560779,
            "EleutherAI/pythia-6.9b-deduped": 0.02030274569370387,
            "EleutherAI/pythia-70m-deduped": 0.023048336668420193,
            "Qwen/Qwen1.5-0.5B": 0.020217143503271036,
            "Qwen/Qwen1.5-0.5B-Chat": 0.0209496418954691,
            "Qwen/Qwen1.5-1.8B": 0.019586377781824597,
            "Qwen/Qwen1.5-1.8B-Chat": 0.019395545192968957,
            "Qwen/Qwen1.5-14B": 0.016664594239032857,
            "Qwen/Qwen1.5-14B-Chat": 0.017184370133262756,
            "Qwen/Qwen1.5-4B": 0.018363574580958334,
            "Qwen/Qwen1.5-4B-Chat": 0.018896375880916458,
            "Qwen/Qwen1.5-7B": 0.018998812901448257,
            "Qwen/Qwen1.5-7B-Chat": 0.017675523578975456,
            "Qwen/Qwen2-0.5B": 0.020872351656743154,
            "Qwen/Qwen2-0.5B-Instruct": 0.020872351656743154,
            "Qwen/Qwen2-1.5B": 0.020553105287596032,
            "Qwen/Qwen2-1.5B-Instruct": 0.019772383169192068,
            "Qwen/Qwen2-7B": 0.017184370133262756,
            "Qwen/Qwen2-7B-Instruct": 0.017433370161428027,
            "Qwen/Qwen2.5-0.5B": 0.020042633287868965,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.02021714350327104,
            "Qwen/Qwen2.5-1.5B": 0.019199741465701962,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.019298274088736644,
            "Qwen/Qwen2.5-14B": 0.015220302790622746,
            "Qwen/Qwen2.5-14B-Instruct": 0.016393127942361817,
            "Qwen/Qwen2.5-3B": 0.018998812901448246,
            "Qwen/Qwen2.5-3B-Instruct": 0.020042633287868962,
            "Qwen/Qwen2.5-7B": 0.018026517751811688,
            "Qwen/Qwen2.5-7B-Instruct": 0.018472962438394722,
            "google/gemma-2-2b": 0.02071476864882411,
            "google/gemma-2-2b-it": 0.018896375880916447,
            "google/gemma-2-9b": 0.01625433281121045,
            "google/gemma-2-9b-it": 0.016529864863512392,
            "google/gemma-2b": 0.020634452949654675,
            "google/gemma-2b-it": 0.019863618177192136,
            "google/gemma-7b": 0.018472962438394715,
            "google/gemma-7b-it": 0.018363574580958338,
            "meta-llama/Llama-3.1-8B": 0.018687448225829042,
            "meta-llama/Llama-3.1-8B-Instruct": 0.018687448225829052,
            "meta-llama/Llama-3.2-1B": 0.022120630385010474,
            "meta-llama/Llama-3.2-1B-Instruct": 0.021321511578472594,
            "meta-llama/Llama-3.2-3B": 0.018896375880916465,
            "meta-llama/Llama-3.2-3B-Instruct": 0.018792595118179316,
            "meta-llama/Meta-Llama-3-8B": 0.01730974424981575,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.01847296243839472,
            "openai-community/gpt2": 0.023095996571841474,
            "openai-community/gpt2-large": 0.022585489065607783,
            "openai-community/gpt2-medium": 0.022417235676753924,
            "openai-community/gpt2-xl": 0.02253019934687401
        },
        "headqa_en": {
            "01-ai/Yi-1.5-6B": 0.009481692283636657,
            "01-ai/Yi-1.5-6B-Chat": 0.009458111556284956,
            "01-ai/Yi-1.5-9B": 0.00953816365919356,
            "01-ai/Yi-1.5-9B-Chat": 0.009509848704810317,
            "01-ai/Yi-6B": 0.009477430886071659,
            "01-ai/Yi-6B-Chat": 0.009462920088428825,
            "01-ai/Yi-9B": 0.009525334919481763,
            "EleutherAI/pythia-1.4b-deduped": 0.009108838601965518,
            "EleutherAI/pythia-12b": 0.009428761144088188,
            "EleutherAI/pythia-160m-deduped": 0.008538984536417878,
            "EleutherAI/pythia-1b-deduped": 0.009063766135398348,
            "EleutherAI/pythia-2.8b-deduped": 0.009335674609685783,
            "EleutherAI/pythia-410m-deduped": 0.008878782038520222,
            "EleutherAI/pythia-6.9b-deduped": 0.009366023967116784,
            "EleutherAI/pythia-70m-deduped": 0.00846413152496253,
            "Qwen/Qwen1.5-0.5B": 0.008859307453380072,
            "Qwen/Qwen1.5-0.5B-Chat": 0.008738909009807234,
            "Qwen/Qwen1.5-1.8B": 0.00911757090470043,
            "Qwen/Qwen1.5-1.8B-Chat": 0.009070677697729538,
            "Qwen/Qwen1.5-14B": 0.009527792552900292,
            "Qwen/Qwen1.5-14B-Chat": 0.009512379204888136,
            "Qwen/Qwen1.5-4B": 0.009326563811480807,
            "Qwen/Qwen1.5-4B-Chat": 0.009272927737895195,
            "Qwen/Qwen1.5-7B": 0.009481692283636661,
            "Qwen/Qwen1.5-7B-Chat": 0.009454170584359845,
            "Qwen/Qwen2-0.5B": 0.008906065904473024,
            "Qwen/Qwen2-0.5B-Instruct": 0.008876018971558998,
            "Qwen/Qwen2-1.5B": 0.00926252944608872,
            "Qwen/Qwen2-1.5B-Instruct": 0.009161888800497137,
            "Qwen/Qwen2-7B": 0.009534398279770252,
            "Qwen/Qwen2-7B-Instruct": 0.009532749186026982,
            "Qwen/Qwen2.5-0.5B": 0.009023586509638448,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.009040340553056568,
            "Qwen/Qwen2.5-1.5B": 0.00937561139900319,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.009325026267022335,
            "Qwen/Qwen2.5-14B": 0.009483360489348162,
            "Qwen/Qwen2.5-14B-Instruct": 0.009512998972730934,
            "Qwen/Qwen2.5-3B": 0.009512998972730908,
            "Qwen/Qwen2.5-3B-Instruct": 0.009508552583148222,
            "Qwen/Qwen2.5-7B": 0.00955014192555594,
            "Qwen/Qwen2.5-7B-Instruct": 0.009542296232733515,
            "google/gemma-2-2b": 0.009520588491617738,
            "google/gemma-2-2b-it": 0.009493698355398093,
            "google/gemma-2-9b": 0.009436485262335223,
            "google/gemma-2-9b-it": 0.009506569787496831,
            "google/gemma-2b": 0.00935186955834199,
            "google/gemma-2b-it": 0.00920366858743745,
            "google/gemma-7b": 0.009549146004408066,
            "google/gemma-7b-it": 0.00949595978039249,
            "meta-llama/Llama-3.1-8B": 0.009544652905490884,
            "meta-llama/Llama-3.1-8B-Instruct": 0.00954797973001112,
            "meta-llama/Llama-3.2-1B": 0.00932038087453828,
            "meta-llama/Llama-3.2-1B-Instruct": 0.009304540509172975,
            "meta-llama/Llama-3.2-3B": 0.00953101834873891,
            "meta-llama/Llama-3.2-3B-Instruct": 0.009488240608766029,
            "meta-llama/Meta-Llama-3-8B": 0.009545567961360647,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.009549694790133399,
            "openai-community/gpt2": 0.008449511492975258,
            "openai-community/gpt2-large": 0.008695267407681813,
            "openai-community/gpt2-medium": 0.008688925646923524,
            "openai-community/gpt2-xl": 0.008781250747331843
        },
        "rte": {
            "01-ai/Yi-1.5-6B": 0.021375368956596676,
            "01-ai/Yi-1.5-6B-Chat": 0.02220321882876407,
            "01-ai/Yi-1.5-9B": 0.017554530741679095,
            "01-ai/Yi-1.5-9B-Chat": 0.019499234986060737,
            "01-ai/Yi-6B": 0.0211577683845608,
            "01-ai/Yi-6B-Chat": 0.022002396597566205,
            "01-ai/Yi-9B": 0.017853261915048352,
            "EleutherAI/pythia-1.4b-deduped": 0.02717764557452113,
            "EleutherAI/pythia-12b": 0.024490730771774636,
            "EleutherAI/pythia-160m-deduped": 0.029357625083848045,
            "EleutherAI/pythia-1b-deduped": 0.028426021205818795,
            "EleutherAI/pythia-2.8b-deduped": 0.026746810842806404,
            "EleutherAI/pythia-410m-deduped": 0.02976495674177765,
            "EleutherAI/pythia-6.9b-deduped": 0.026032861194685897,
            "EleutherAI/pythia-70m-deduped": 0.030009848912529113,
            "Qwen/Qwen1.5-0.5B": 0.02615771975846462,
            "Qwen/Qwen1.5-0.5B-Chat": 0.026633581342891784,
            "Qwen/Qwen1.5-1.8B": 0.025088850556690093,
            "Qwen/Qwen1.5-1.8B-Chat": 0.024943505204487317,
            "Qwen/Qwen1.5-14B": 0.017554530741679078,
            "Qwen/Qwen1.5-14B-Chat": 0.017853261915048352,
            "Qwen/Qwen1.5-4B": 0.02137536895659668,
            "Qwen/Qwen1.5-4B-Chat": 0.02137536895659668,
            "Qwen/Qwen1.5-7B": 0.018428523011352407,
            "Qwen/Qwen1.5-7B-Chat": 0.02047727547612675,
            "Qwen/Qwen2-0.5B": 0.02628018840817812,
            "Qwen/Qwen2-0.5B-Instruct": 0.02651808776783053,
            "Qwen/Qwen2-1.5B": 0.023677052322414453,
            "Qwen/Qwen2-1.5B-Instruct": 0.022968421711280496,
            "Qwen/Qwen2-7B": 0.01897641154323034,
            "Qwen/Qwen2-7B-Instruct": 0.019240826402123323,
            "Qwen/Qwen2.5-0.5B": 0.0260328611946859,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.026280188408178123,
            "Qwen/Qwen2.5-1.5B": 0.02401173390286762,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.023504911523892457,
            "Qwen/Qwen2.5-14B": 0.019751873032017933,
            "Qwen/Qwen2.5-14B-Instruct": 0.01755453074167907,
            "Qwen/Qwen2.5-3B": 0.020477275476126745,
            "Qwen/Qwen2.5-3B-Instruct": 0.02047727547612675,
            "Qwen/Qwen2.5-7B": 0.020935651096280105,
            "Qwen/Qwen2.5-7B-Instruct": 0.020240696905362225,
            "google/gemma-2-2b": 0.02259324110170705,
            "google/gemma-2-2b-it": 0.02137536895659668,
            "google/gemma-2-9b": 0.018428523011352407,
            "google/gemma-2-9b-it": 0.01814447384964492,
            "google/gemma-2b": 0.024795403613230512,
            "google/gemma-2b-it": 0.02479540361323051,
            "google/gemma-7b": 0.020240696905362232,
            "google/gemma-7b-it": 0.022593241101707042,
            "meta-llama/Llama-3.1-8B": 0.020935651096280105,
            "meta-llama/Llama-3.1-8B-Instruct": 0.02047727547612675,
            "meta-llama/Llama-3.2-1B": 0.027850410392630694,
            "meta-llama/Llama-3.2-1B-Instruct": 0.024943505204487314,
            "meta-llama/Llama-3.2-3B": 0.022968421711280496,
            "meta-llama/Llama-3.2-3B-Instruct": 0.021797558224296017,
            "meta-llama/Meta-Llama-3-8B": 0.021375368956596676,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.016932908880229008,
            "openai-community/gpt2": 0.030039730592197812,
            "openai-community/gpt2-large": 0.02993107036293953,
            "openai-community/gpt2-medium": 0.030052303463143706,
            "openai-community/gpt2-xl": 0.029405839314203205
        },
        "arc_easy": {
            "01-ai/Yi-1.5-6B": 0.007569059988573497,
            "01-ai/Yi-1.5-6B-Chat": 0.007561148218715585,
            "01-ai/Yi-1.5-9B": 0.007150007199768,
            "01-ai/Yi-1.5-9B-Chat": 0.00736568060684635,
            "01-ai/Yi-6B": 0.007914286364836584,
            "01-ai/Yi-6B-Chat": 0.007921402939423292,
            "01-ai/Yi-9B": 0.00747290729025258,
            "EleutherAI/pythia-1.4b-deduped": 0.009642048058060992,
            "EleutherAI/pythia-12b": 0.008709108323214462,
            "EleutherAI/pythia-160m-deduped": 0.01012062821101788,
            "EleutherAI/pythia-1b-deduped": 0.009890173658452125,
            "EleutherAI/pythia-2.8b-deduped": 0.009358110551087425,
            "EleutherAI/pythia-410m-deduped": 0.01019911818332299,
            "EleutherAI/pythia-6.9b-deduped": 0.008890213675113967,
            "EleutherAI/pythia-70m-deduped": 0.009958037725468565,
            "Qwen/Qwen1.5-0.5B": 0.009878157021155647,
            "Qwen/Qwen1.5-0.5B-Chat": 0.010050018228742115,
            "Qwen/Qwen1.5-1.8B": 0.009195059601583897,
            "Qwen/Qwen1.5-1.8B-Chat": 0.009338583737393609,
            "Qwen/Qwen1.5-14B": 0.007440259500567545,
            "Qwen/Qwen1.5-14B-Chat": 0.00776111189729837,
            "Qwen/Qwen1.5-4B": 0.008308414979092741,
            "Qwen/Qwen1.5-4B-Chat": 0.008460637338999107,
            "Qwen/Qwen1.5-7B": 0.007834949209841088,
            "Qwen/Qwen1.5-7B-Chat": 0.00812773877996927,
            "Qwen/Qwen2-0.5B": 0.009788295410093144,
            "Qwen/Qwen2-0.5B-Instruct": 0.009906656266021151,
            "Qwen/Qwen2-1.5B": 0.00883990265677187,
            "Qwen/Qwen2-1.5B-Instruct": 0.00895877599791836,
            "Qwen/Qwen2-7B": 0.007105299841896234,
            "Qwen/Qwen2-7B-Instruct": 0.007263757628287282,
            "Qwen/Qwen2.5-0.5B": 0.00938885591404043,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.009441202922359185,
            "Qwen/Qwen2.5-1.5B": 0.00797777045420235,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.00822590726296516,
            "Qwen/Qwen2.5-14B": 0.006206212579299181,
            "Qwen/Qwen2.5-14B-Instruct": 0.0063293194307127544,
            "Qwen/Qwen2.5-3B": 0.007677948990566539,
            "Qwen/Qwen2.5-3B-Instruct": 0.0076855949618812045,
            "Qwen/Qwen2.5-7B": 0.0069303297668291365,
            "Qwen/Qwen2.5-7B-Instruct": 0.007220426139837213,
            "google/gemma-2-2b": 0.0076471911290186476,
            "google/gemma-2-2b-it": 0.007776012182869754,
            "google/gemma-2-9b": 0.006194827501145028,
            "google/gemma-2-9b-it": 0.006825179144275866,
            "google/gemma-2b": 0.008376419295817054,
            "google/gemma-2b-it": 0.00929477425202963,
            "google/gemma-7b": 0.0067269977257629465,
            "google/gemma-7b-it": 0.008087556805903158,
            "meta-llama/Llama-3.1-8B": 0.006958506375697437,
            "meta-llama/Llama-3.1-8B-Instruct": 0.007096293040649984,
            "meta-llama/Llama-3.2-1B": 0.009062210626971844,
            "meta-llama/Llama-3.2-1B-Instruct": 0.009169229476542572,
            "meta-llama/Llama-3.2-3B": 0.00785677998487711,
            "meta-llama/Llama-3.2-3B-Instruct": 0.007864024474332735,
            "meta-llama/Meta-Llama-3-8B": 0.007023440574367729,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.0073572967111137704,
            "openai-community/gpt2": 0.010215708295494117,
            "openai-community/gpt2-large": 0.010063960494989163,
            "openai-community/gpt2-medium": 0.010234104543411431,
            "openai-community/gpt2-xl": 0.009908978578665753
        },
        "arc_challenge": {
            "01-ai/Yi-1.5-6B": 0.0144418896274644,
            "01-ai/Yi-1.5-6B-Chat": 0.014518421825670449,
            "01-ai/Yi-1.5-9B": 0.014291228393536588,
            "01-ai/Yi-1.5-9B-Chat": 0.014365750345427005,
            "01-ai/Yi-6B": 0.014566303676636581,
            "01-ai/Yi-6B-Chat": 0.014593487694937738,
            "01-ai/Yi-9B": 0.014280522667467325,
            "EleutherAI/pythia-1.4b-deduped": 0.013804855026205766,
            "EleutherAI/pythia-12b": 0.014570144495075581,
            "EleutherAI/pythia-160m-deduped": 0.012595726268790115,
            "EleutherAI/pythia-1b-deduped": 0.013203196088537369,
            "EleutherAI/pythia-2.8b-deduped": 0.014285898292938175,
            "EleutherAI/pythia-410m-deduped": 0.012835523909473852,
            "EleutherAI/pythia-6.9b-deduped": 0.014397070564409174,
            "EleutherAI/pythia-70m-deduped": 0.012074291605700959,
            "Qwen/Qwen1.5-0.5B": 0.013449522109932487,
            "Qwen/Qwen1.5-0.5B-Chat": 0.013307250444941115,
            "Qwen/Qwen1.5-1.8B": 0.014397070564409174,
            "Qwen/Qwen1.5-1.8B-Chat": 0.014218371065251102,
            "Qwen/Qwen1.5-14B": 0.014317197787809165,
            "Qwen/Qwen1.5-14B-Chat": 0.014322255790719869,
            "Qwen/Qwen1.5-4B": 0.014608326906285015,
            "Qwen/Qwen1.5-4B-Chat": 0.014595873205358266,
            "Qwen/Qwen1.5-7B": 0.014471133392642468,
            "Qwen/Qwen1.5-7B-Chat": 0.014594701798071655,
            "Qwen/Qwen2-0.5B": 0.013406741767847626,
            "Qwen/Qwen2-0.5B-Instruct": 0.013522292098053052,
            "Qwen/Qwen2-1.5B": 0.014471133392642464,
            "Qwen/Qwen2-1.5B-Instruct": 0.014453185592920293,
            "Qwen/Qwen2-7B": 0.01433715891426844,
            "Qwen/Qwen2-7B-Instruct": 0.014379441068522084,
            "Qwen/Qwen2.5-0.5B": 0.01388881628678211,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.014027516814585188,
            "Qwen/Qwen2.5-1.5B": 0.014611199329843774,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.01460779491401306,
            "Qwen/Qwen2.5-14B": 0.013562691224726297,
            "Qwen/Qwen2.5-14B-Instruct": 0.013659980894277366,
            "Qwen/Qwen2.5-3B": 0.014544519880633827,
            "Qwen/Qwen2.5-3B-Instruct": 0.014600132075947092,
            "Qwen/Qwen2.5-7B": 0.014090995618168473,
            "Qwen/Qwen2.5-7B-Instruct": 0.014361097288449708,
            "google/gemma-2-2b": 0.014572000527756994,
            "google/gemma-2-2b-it": 0.014553749939306866,
            "google/gemma-2-9b": 0.01349142951729204,
            "google/gemma-2-9b-it": 0.013734057652635473,
            "google/gemma-2b": 0.014549221105171872,
            "google/gemma-2b-it": 0.014487986197186052,
            "google/gemma-7b": 0.0141633668961926,
            "google/gemma-7b-it": 0.014529380160526842,
            "meta-llama/Llama-3.1-8B": 0.014131176760131169,
            "meta-llama/Llama-3.1-8B-Instruct": 0.01421244498065189,
            "meta-llama/Llama-3.2-1B": 0.014356399418009131,
            "meta-llama/Llama-3.2-1B-Instruct": 0.014169664520303101,
            "meta-llama/Llama-3.2-3B": 0.014578995859605814,
            "meta-llama/Llama-3.2-3B-Instruct": 0.014601090150633966,
            "meta-llama/Meta-Llama-3-8B": 0.014131176760131169,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.01432225579071987,
            "openai-community/gpt2": 0.012368225378507154,
            "openai-community/gpt2-large": 0.01266819862131543,
            "openai-community/gpt2-medium": 0.012710896778378606,
            "openai-community/gpt2-xl": 0.013640943091946526
        },
        "arxiv_2025": {
            "meta-llama/Llama-3.2-1B": "N/A",
            "meta-llama/Llama-3.2-3B": "N/A",
            "meta-llama/Llama-3.2-3B-Instruct": "N/A",
            "meta-llama/Llama-3.2-1B-Instruct": "N/A",
            "openai-community/gpt2-xl": "N/A",
            "openai-community/gpt2": "N/A",
            "openai-community/gpt2-medium": "N/A",
            "openai-community/gpt2-large": "N/A",
            "EleutherAI/pythia-2.8b-deduped": "N/A",
            "EleutherAI/pythia-1.4b-deduped": "N/A",
            "EleutherAI/pythia-1b-deduped": "N/A",
            "EleutherAI/pythia-70m-deduped": "N/A",
            "EleutherAI/pythia-160m-deduped": "N/A",
            "EleutherAI/pythia-410m-deduped": "N/A",
            "google/gemma-2-2b": "N/A",
            "google/gemma-2b": "N/A",
            "google/gemma-2b-it": "N/A",
            "google/gemma-2-2b-it": "N/A",
            "Qwen/Qwen1.5-0.5B-Chat": "N/A",
            "Qwen/Qwen1.5-4B-Chat": "N/A",
            "Qwen/Qwen2.5-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-3B": "N/A",
            "Qwen/Qwen1.5-4B": "N/A",
            "Qwen/Qwen2.5-3B-Instruct": "N/A",
            "Qwen/Qwen1.5-0.5B": "N/A",
            "Qwen/Qwen2-1.5B": "N/A",
            "Qwen/Qwen1.5-1.8B": "N/A",
            "Qwen/Qwen2.5-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-0.5B": "N/A",
            "Qwen/Qwen1.5-1.8B-Chat": "N/A",
            "Qwen/Qwen2.5-1.5B": "N/A",
            "Qwen/Qwen2-0.5B": "N/A",
            "meta-llama/Meta-Llama-3-8B-Instruct": "N/A",
            "meta-llama/Meta-Llama-3-8B": "N/A",
            "meta-llama/Llama-3.1-8B-Instruct": "N/A",
            "meta-llama/Llama-3.1-8B": "N/A",
            "EleutherAI/pythia-12b": "N/A",
            "EleutherAI/pythia-6.9b-deduped": "N/A",
            "google/gemma-7b-it": "N/A",
            "google/gemma-2-9b": "N/A",
            "google/gemma-7b": "N/A",
            "google/gemma-2-9b-it": "N/A",
            "01-ai/Yi-1.5-6B-Chat": "N/A",
            "01-ai/Yi-1.5-6B": "N/A",
            "01-ai/Yi-9B": "N/A",
            "01-ai/Yi-6B-Chat": "N/A",
            "01-ai/Yi-6B": "N/A",
            "01-ai/Yi-1.5-9B": "N/A",
            "01-ai/Yi-1.5-9B-Chat": "N/A",
            "Qwen/Qwen2-7B": "N/A",
            "Qwen/Qwen1.5-14B": "N/A",
            "Qwen/Qwen1.5-7B-Chat": "N/A",
            "Qwen/Qwen2.5-7B-Instruct": "N/A",
            "Qwen/Qwen1.5-7B": "N/A",
            "Qwen/Qwen2.5-14B": "N/A",
            "Qwen/Qwen2.5-7B": "N/A",
            "Qwen/Qwen2.5-14B-Instruct": "N/A",
            "Qwen/Qwen1.5-14B-Chat": "N/A",
            "Qwen/Qwen2-7B-Instruct": "N/A"
        },
        "wiki_2025": {
            "meta-llama/Llama-3.2-1B": "N/A",
            "meta-llama/Llama-3.2-3B": "N/A",
            "meta-llama/Llama-3.2-3B-Instruct": "N/A",
            "meta-llama/Llama-3.2-1B-Instruct": "N/A",
            "openai-community/gpt2-xl": "N/A",
            "openai-community/gpt2": "N/A",
            "openai-community/gpt2-medium": "N/A",
            "openai-community/gpt2-large": "N/A",
            "EleutherAI/pythia-2.8b-deduped": "N/A",
            "EleutherAI/pythia-1.4b-deduped": "N/A",
            "EleutherAI/pythia-1b-deduped": "N/A",
            "EleutherAI/pythia-70m-deduped": "N/A",
            "EleutherAI/pythia-160m-deduped": "N/A",
            "EleutherAI/pythia-410m-deduped": "N/A",
            "google/gemma-2-2b": "N/A",
            "google/gemma-2b": "N/A",
            "google/gemma-2b-it": "N/A",
            "google/gemma-2-2b-it": "N/A",
            "Qwen/Qwen1.5-0.5B-Chat": "N/A",
            "Qwen/Qwen1.5-4B-Chat": "N/A",
            "Qwen/Qwen2.5-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-3B": "N/A",
            "Qwen/Qwen1.5-4B": "N/A",
            "Qwen/Qwen2.5-3B-Instruct": "N/A",
            "Qwen/Qwen1.5-0.5B": "N/A",
            "Qwen/Qwen2-1.5B": "N/A",
            "Qwen/Qwen1.5-1.8B": "N/A",
            "Qwen/Qwen2.5-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-0.5B": "N/A",
            "Qwen/Qwen1.5-1.8B-Chat": "N/A",
            "Qwen/Qwen2.5-1.5B": "N/A",
            "Qwen/Qwen2-0.5B": "N/A",
            "meta-llama/Meta-Llama-3-8B-Instruct": "N/A",
            "meta-llama/Meta-Llama-3-8B": "N/A",
            "meta-llama/Llama-3.1-8B-Instruct": "N/A",
            "meta-llama/Llama-3.1-8B": "N/A",
            "EleutherAI/pythia-12b": "N/A",
            "EleutherAI/pythia-6.9b-deduped": "N/A",
            "google/gemma-7b-it": "N/A",
            "google/gemma-2-9b": "N/A",
            "google/gemma-7b": "N/A",
            "google/gemma-2-9b-it": "N/A",
            "01-ai/Yi-1.5-6B-Chat": "N/A",
            "01-ai/Yi-1.5-9B-Chat": "N/A",
            "01-ai/Yi-6B": "N/A",
            "01-ai/Yi-9B": "N/A",
            "01-ai/Yi-1.5-6B": "N/A",
            "01-ai/Yi-6B-Chat": "N/A",
            "01-ai/Yi-1.5-9B": "N/A",
            "Qwen/Qwen2-7B": "N/A",
            "Qwen/Qwen1.5-14B": "N/A",
            "Qwen/Qwen1.5-7B-Chat": "N/A",
            "Qwen/Qwen2.5-7B-Instruct": "N/A",
            "Qwen/Qwen1.5-7B": "N/A",
            "Qwen/Qwen2.5-14B": "N/A",
            "Qwen/Qwen2.5-7B": "N/A",
            "Qwen/Qwen2.5-14B-Instruct": "N/A",
            "Qwen/Qwen1.5-14B-Chat": "N/A",
            "Qwen/Qwen2-7B-Instruct": "N/A"
        },
        "stackexchange_2025": {
            "meta-llama/Llama-3.2-1B": "N/A",
            "meta-llama/Llama-3.2-3B": "N/A",
            "meta-llama/Llama-3.2-3B-Instruct": "N/A",
            "meta-llama/Llama-3.2-1B-Instruct": "N/A",
            "openai-community/gpt2-xl": "N/A",
            "openai-community/gpt2": "N/A",
            "openai-community/gpt2-medium": "N/A",
            "openai-community/gpt2-large": "N/A",
            "EleutherAI/pythia-2.8b-deduped": "N/A",
            "EleutherAI/pythia-1.4b-deduped": "N/A",
            "EleutherAI/pythia-1b-deduped": "N/A",
            "EleutherAI/pythia-70m-deduped": "N/A",
            "EleutherAI/pythia-160m-deduped": "N/A",
            "EleutherAI/pythia-410m-deduped": "N/A",
            "google/gemma-2-2b": "N/A",
            "google/gemma-2b": "N/A",
            "google/gemma-2b-it": "N/A",
            "google/gemma-2-2b-it": "N/A",
            "Qwen/Qwen1.5-0.5B-Chat": "N/A",
            "Qwen/Qwen1.5-4B-Chat": "N/A",
            "Qwen/Qwen2.5-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-3B": "N/A",
            "Qwen/Qwen1.5-4B": "N/A",
            "Qwen/Qwen2.5-3B-Instruct": "N/A",
            "Qwen/Qwen1.5-0.5B": "N/A",
            "Qwen/Qwen2-1.5B": "N/A",
            "Qwen/Qwen1.5-1.8B": "N/A",
            "Qwen/Qwen2.5-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-0.5B": "N/A",
            "Qwen/Qwen1.5-1.8B-Chat": "N/A",
            "Qwen/Qwen2.5-1.5B": "N/A",
            "Qwen/Qwen2-0.5B": "N/A",
            "meta-llama/Meta-Llama-3-8B-Instruct": "N/A",
            "meta-llama/Meta-Llama-3-8B": "N/A",
            "meta-llama/Llama-3.1-8B-Instruct": "N/A",
            "meta-llama/Llama-3.1-8B": "N/A",
            "EleutherAI/pythia-12b": "N/A",
            "EleutherAI/pythia-6.9b-deduped": "N/A",
            "google/gemma-7b-it": "N/A",
            "google/gemma-2-9b": "N/A",
            "google/gemma-7b": "N/A",
            "google/gemma-2-9b-it": "N/A",
            "01-ai/Yi-1.5-6B-Chat": "N/A",
            "01-ai/Yi-1.5-6B": "N/A",
            "01-ai/Yi-9B": "N/A",
            "01-ai/Yi-6B-Chat": "N/A",
            "01-ai/Yi-6B": "N/A",
            "01-ai/Yi-1.5-9B": "N/A",
            "01-ai/Yi-1.5-9B-Chat": "N/A",
            "Qwen/Qwen2-7B": "N/A",
            "Qwen/Qwen1.5-14B": "N/A",
            "Qwen/Qwen1.5-7B-Chat": "N/A",
            "Qwen/Qwen2.5-7B-Instruct": "N/A",
            "Qwen/Qwen1.5-7B": "N/A",
            "Qwen/Qwen2.5-14B": "N/A",
            "Qwen/Qwen2.5-7B": "N/A",
            "Qwen/Qwen2.5-14B-Instruct": "N/A",
            "Qwen/Qwen1.5-14B-Chat": "N/A",
            "Qwen/Qwen2-7B-Instruct": "N/A"
        }
    },
    "direct_eval_stderr": {
        "mnli": {
            "01-ai/Yi-1.5-6B": 0.005027520123179933,
            "01-ai/Yi-1.5-6B-Chat": 0.004861585819619505,
            "01-ai/Yi-1.5-9B": 0.005044458903012264,
            "01-ai/Yi-1.5-9B-Chat": 0.004890421640162474,
            "01-ai/Yi-6B": 0.005036783987726844,
            "01-ai/Yi-6B-Chat": 0.005045992485250499,
            "01-ai/Yi-9B": 0.005040043188636208,
            "EleutherAI/pythia-1.4b-deduped": 0.004703257341537876,
            "EleutherAI/pythia-12b": 0.004884323999972405,
            "EleutherAI/pythia-160m-deduped": 0.0047683526288521665,
            "EleutherAI/pythia-1b-deduped": 0.0047858831751667235,
            "EleutherAI/pythia-2.8b-deduped": 0.0048505153122490674,
            "EleutherAI/pythia-410m-deduped": 0.004813305946238664,
            "EleutherAI/pythia-6.9b-deduped": 0.004919326669097455,
            "EleutherAI/pythia-70m-deduped": 0.004737876690659697,
            "Qwen/Qwen1.5-0.5B": 0.0049333014657424595,
            "Qwen/Qwen1.5-0.5B-Chat": 0.00503711157761548,
            "Qwen/Qwen1.5-1.8B": 0.004899212442097966,
            "Qwen/Qwen1.5-1.8B-Chat": 0.00504715132521182,
            "Qwen/Qwen1.5-14B": 0.004942437609934824,
            "Qwen/Qwen1.5-14B-Chat": 0.004604168356257913,
            "Qwen/Qwen1.5-4B": 0.005042731885654447,
            "Qwen/Qwen1.5-4B-Chat": 0.004999544934426265,
            "Qwen/Qwen1.5-7B": 0.00497750421754175,
            "Qwen/Qwen1.5-7B-Chat": 0.004772616363160118,
            "Qwen/Qwen2-0.5B": 0.00498952747304807,
            "Qwen/Qwen2-0.5B-Instruct": 0.005038185964926756,
            "Qwen/Qwen2-1.5B": 0.004959724988993357,
            "Qwen/Qwen2-1.5B-Instruct": 0.005044458903012281,
            "Qwen/Qwen2-7B": 0.004980238783806811,
            "Qwen/Qwen2-7B-Instruct": 0.004842442379244903,
            "Qwen/Qwen2.5-0.5B": 0.004914321165958116,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.004969330441743629,
            "Qwen/Qwen2.5-1.5B": 0.005040890970108216,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.004939436077607403,
            "Qwen/Qwen2.5-14B": 0.004743138650579768,
            "Qwen/Qwen2.5-14B-Instruct": 0.004308229192497885,
            "Qwen/Qwen2.5-3B": 0.005020311925807832,
            "Qwen/Qwen2.5-3B-Instruct": 0.004881904694347494,
            "Qwen/Qwen2.5-7B": 0.004879194575723342,
            "Qwen/Qwen2.5-7B-Instruct": 0.004510812990674768,
            "google/gemma-2-2b": 0.0050026228856015235,
            "google/gemma-2-2b-it": 0.005015881280007374,
            "google/gemma-2-9b": 0.005045234662474607,
            "google/gemma-2-9b-it": 0.004889106448597104,
            "google/gemma-2b": 0.004949545090307639,
            "google/gemma-2b-it": 0.00503090769014748,
            "google/gemma-7b": 0.004999970795692377,
            "google/gemma-7b-it": 0.004946441167823,
            "meta-llama/Llama-3.1-8B": 0.005037046481321229,
            "meta-llama/Llama-3.1-8B-Instruct": 0.00498374317227517,
            "meta-llama/Llama-3.2-1B": 0.004839408552143834,
            "meta-llama/Llama-3.2-1B-Instruct": 0.005043819126194727,
            "meta-llama/Llama-3.2-3B": 0.004796779806828283,
            "meta-llama/Llama-3.2-3B-Instruct": 0.005031318703576095,
            "meta-llama/Meta-Llama-3-8B": 0.005044458903012255,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.004978536229632079,
            "openai-community/gpt2": 0.004772262416487608,
            "openai-community/gpt2-large": 0.004842442379244894,
            "openai-community/gpt2-medium": 0.004820385715369125,
            "openai-community/gpt2-xl": 0.004860724173263057
        },
        "qqp": {
            "01-ai/Yi-1.5-6B": 0.0049315470205201,
            "01-ai/Yi-1.5-6B-Chat": 0.0041581245772585465,
            "01-ai/Yi-1.5-9B": 0.004985558803149168,
            "01-ai/Yi-1.5-9B-Chat": 0.003873403713226214,
            "01-ai/Yi-6B": 0.0048513742984083045,
            "01-ai/Yi-6B-Chat": 0.004481348485492386,
            "01-ai/Yi-9B": 0.004361076231687109,
            "EleutherAI/pythia-1.4b-deduped": 0.004957027457269262,
            "EleutherAI/pythia-12b": 0.004918029046373105,
            "EleutherAI/pythia-160m-deduped": 0.004824765158625208,
            "EleutherAI/pythia-1b-deduped": 0.004826123200511286,
            "EleutherAI/pythia-2.8b-deduped": 0.004956095972509748,
            "EleutherAI/pythia-410m-deduped": 0.004995753372132803,
            "EleutherAI/pythia-6.9b-deduped": 0.004823128160905999,
            "EleutherAI/pythia-70m-deduped": 0.004821757867717099,
            "Qwen/Qwen1.5-0.5B": 0.00482230665388948,
            "Qwen/Qwen1.5-0.5B-Chat": 0.004823674717866027,
            "Qwen/Qwen1.5-1.8B": 0.004803145533991543,
            "Qwen/Qwen1.5-1.8B-Chat": 0.00457798807310338,
            "Qwen/Qwen1.5-14B": 0.004166114574884442,
            "Qwen/Qwen1.5-14B-Chat": 0.0040503106673005955,
            "Qwen/Qwen1.5-4B": 0.004166114574884427,
            "Qwen/Qwen1.5-4B-Chat": 0.004339542275714815,
            "Qwen/Qwen1.5-7B": 0.003801570885057514,
            "Qwen/Qwen1.5-7B-Chat": 0.003782661874009818,
            "Qwen/Qwen2-0.5B": 0.00482230665388948,
            "Qwen/Qwen2-0.5B-Instruct": 0.004731548346468974,
            "Qwen/Qwen2-1.5B": 0.00481955379779893,
            "Qwen/Qwen2-1.5B-Instruct": 0.0043028644487416645,
            "Qwen/Qwen2-7B": 0.004205323230661876,
            "Qwen/Qwen2-7B-Instruct": 0.004194338475555281,
            "Qwen/Qwen2.5-0.5B": 0.004659178660942385,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.0045718120200325145,
            "Qwen/Qwen2.5-1.5B": 0.004306410746474373,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.0037705126543438367,
            "Qwen/Qwen2.5-14B": 0.003406693493118543,
            "Qwen/Qwen2.5-14B-Instruct": 0.003531238729496542,
            "Qwen/Qwen2.5-3B": 0.003536244547899799,
            "Qwen/Qwen2.5-3B-Instruct": 0.0038151843419626436,
            "Qwen/Qwen2.5-7B": 0.0034762583962129764,
            "Qwen/Qwen2.5-7B-Instruct": 0.0036597391121552165,
            "google/gemma-2-2b": 0.004982324091760456,
            "google/gemma-2-2b-it": 0.004380524842960428,
            "google/gemma-2-9b": 0.004909359345262853,
            "google/gemma-2-9b-it": 0.004267996787681681,
            "google/gemma-2b": 0.004829896146883807,
            "google/gemma-2b-it": 0.005000217617026376,
            "google/gemma-7b": 0.0049793202711853,
            "google/gemma-7b-it": 0.004910515483758201,
            "meta-llama/Llama-3.1-8B": 0.0048957234205766606,
            "meta-llama/Llama-3.1-8B-Instruct": 0.004352062734497875,
            "meta-llama/Llama-3.2-1B": 0.004999544333672449,
            "meta-llama/Llama-3.2-1B-Instruct": 0.004916553289615104,
            "meta-llama/Llama-3.2-3B": 0.004849370128074574,
            "meta-llama/Llama-3.2-3B-Instruct": 0.004782025279792859,
            "meta-llama/Meta-Llama-3-8B": 0.004984937708777557,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.004253871829586962,
            "openai-community/gpt2": 0.004838878121439586,
            "openai-community/gpt2-large": 0.0048404366520693005,
            "openai-community/gpt2-medium": 0.00482230665388948,
            "openai-community/gpt2-xl": 0.004833095476109564
        },
        "medmcqa": {
            "01-ai/Yi-1.5-6B": 0.007729674236551033,
            "01-ai/Yi-1.5-6B-Chat": 0.007705411199384129,
            "01-ai/Yi-1.5-9B": 0.007719954805640574,
            "01-ai/Yi-1.5-9B-Chat": 0.007729674236551032,
            "01-ai/Yi-6B": 0.007713533343225157,
            "01-ai/Yi-6B-Chat": 0.007717821404397129,
            "01-ai/Yi-9B": 0.007717598292699531,
            "EleutherAI/pythia-1.4b-deduped": 0.007150658110045896,
            "EleutherAI/pythia-12b": 0.006509703388329939,
            "EleutherAI/pythia-160m-deduped": 0.007179142455150485,
            "EleutherAI/pythia-1b-deduped": 0.007111948150772045,
            "EleutherAI/pythia-2.8b-deduped": 0.006779624437908082,
            "EleutherAI/pythia-410m-deduped": 0.0072239098734883786,
            "EleutherAI/pythia-6.9b-deduped": 0.006364657598654431,
            "EleutherAI/pythia-70m-deduped": 0.007215408940601057,
            "Qwen/Qwen1.5-0.5B": 0.007228131066836411,
            "Qwen/Qwen1.5-0.5B-Chat": 0.007206829715664748,
            "Qwen/Qwen1.5-1.8B": 0.0074489400047533455,
            "Qwen/Qwen1.5-1.8B-Chat": 0.007381352414568343,
            "Qwen/Qwen1.5-14B": 0.007714536052623427,
            "Qwen/Qwen1.5-14B-Chat": 0.007731541005334814,
            "Qwen/Qwen1.5-4B": 0.0076715470340267275,
            "Qwen/Qwen1.5-4B-Chat": 0.007641577292935665,
            "Qwen/Qwen1.5-7B": 0.00773173543449667,
            "Qwen/Qwen1.5-7B-Chat": 0.0076982480322389584,
            "Qwen/Qwen2-0.5B": 0.007343426826332973,
            "Qwen/Qwen2-0.5B-Instruct": 0.007382503906270716,
            "Qwen/Qwen2-1.5B": 0.007608806690600817,
            "Qwen/Qwen2-1.5B-Instruct": 0.007629211443287838,
            "Qwen/Qwen2-7B": 0.0076568097485801385,
            "Qwen/Qwen2-7B-Instruct": 0.007692494220034513,
            "Qwen/Qwen2.5-0.5B": 0.00744996732026624,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.007438558002210073,
            "Qwen/Qwen2.5-1.5B": 0.007715026730398339,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.007713533343225159,
            "Qwen/Qwen2.5-14B": 0.007448940004753349,
            "Qwen/Qwen2.5-14B-Instruct": 0.007436457810052948,
            "Qwen/Qwen2.5-3B": 0.007720758440437936,
            "Qwen/Qwen2.5-3B-Instruct": 0.007728188984831112,
            "Qwen/Qwen2.5-7B": 0.007574633322451373,
            "Qwen/Qwen2.5-7B-Instruct": 0.007669204157697391,
            "google/gemma-2-2b": 0.007585045276259062,
            "google/gemma-2-2b-it": 0.007650456753217209,
            "google/gemma-2-9b": 0.007638706420756213,
            "google/gemma-2-9b-it": 0.00766290067283318,
            "google/gemma-2b": 0.007071818658446871,
            "google/gemma-2b-it": 0.007350697793603454,
            "google/gemma-7b": 0.007730080862850249,
            "google/gemma-7b-it": 0.007636961906055532,
            "meta-llama/Llama-3.1-8B": 0.007621781227555943,
            "meta-llama/Llama-3.1-8B-Instruct": 0.007601354731712711,
            "meta-llama/Llama-3.2-1B": 0.007439605120577843,
            "meta-llama/Llama-3.2-1B-Instruct": 0.007680893600836814,
            "meta-llama/Llama-3.2-3B": 0.0077309311730650926,
            "meta-llama/Llama-3.2-3B-Instruct": 0.007689832514427779,
            "meta-llama/Meta-Llama-3-8B": 0.007624909395645081,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.007553511264398757,
            "openai-community/gpt2": 0.00720682971566475,
            "openai-community/gpt2-large": 0.0071952684770416955,
            "openai-community/gpt2-medium": 0.007187971470479771,
            "openai-community/gpt2-xl": 0.0071430285608817265
        },
        "qnli": {
            "01-ai/Yi-1.5-6B": 0.006611403684166577,
            "01-ai/Yi-1.5-6B-Chat": 0.006281480062914803,
            "01-ai/Yi-1.5-9B": 0.006760738110721012,
            "01-ai/Yi-1.5-9B-Chat": 0.004951089768273717,
            "01-ai/Yi-6B": 0.0067382529119608585,
            "01-ai/Yi-6B-Chat": 0.006765301626506883,
            "01-ai/Yi-9B": 0.00673504658386876,
            "EleutherAI/pythia-1.4b-deduped": 0.006764387537235331,
            "EleutherAI/pythia-12b": 0.00676169624181641,
            "EleutherAI/pythia-160m-deduped": 0.006764806510150313,
            "EleutherAI/pythia-1b-deduped": 0.006765042284363295,
            "EleutherAI/pythia-2.8b-deduped": 0.006763027056622816,
            "EleutherAI/pythia-410m-deduped": 0.006765377795038129,
            "EleutherAI/pythia-6.9b-deduped": 0.006759670033729408,
            "EleutherAI/pythia-70m-deduped": 0.006765015986877456,
            "Qwen/Qwen1.5-0.5B": 0.006739571971730923,
            "Qwen/Qwen1.5-0.5B-Chat": 0.006737580993441767,
            "Qwen/Qwen1.5-1.8B": 0.006737805884200535,
            "Qwen/Qwen1.5-1.8B-Chat": 0.006742111049425488,
            "Qwen/Qwen1.5-14B": 0.006381112426595348,
            "Qwen/Qwen1.5-14B-Chat": 0.005282609806324375,
            "Qwen/Qwen1.5-4B": 0.006383724889106441,
            "Qwen/Qwen1.5-4B-Chat": 0.005849333131148685,
            "Qwen/Qwen1.5-7B": 0.006651790679935519,
            "Qwen/Qwen1.5-7B-Chat": 0.0059942266310163425,
            "Qwen/Qwen2-0.5B": 0.006721274162612471,
            "Qwen/Qwen2-0.5B-Instruct": 0.006737805884200529,
            "Qwen/Qwen2-1.5B": 0.006702546580362512,
            "Qwen/Qwen2-1.5B-Instruct": 0.006731411324381113,
            "Qwen/Qwen2-7B": 0.006659911642392435,
            "Qwen/Qwen2-7B-Instruct": 0.006386327637698415,
            "Qwen/Qwen2.5-0.5B": 0.006733133534059208,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.006746049732719293,
            "Qwen/Qwen2.5-1.5B": 0.006731411324381105,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.0064282873268291215,
            "Qwen/Qwen2.5-14B": 0.006399196085175715,
            "Qwen/Qwen2.5-14B-Instruct": 0.004837652230598137,
            "Qwen/Qwen2.5-3B": 0.006350821863781664,
            "Qwen/Qwen2.5-3B-Instruct": 0.005444384320276755,
            "Qwen/Qwen2.5-7B": 0.00643796250066554,
            "Qwen/Qwen2.5-7B-Instruct": 0.005023729609521835,
            "google/gemma-2-2b": 0.006724345653161829,
            "google/gemma-2-2b-it": 0.005852209195496466,
            "google/gemma-2-9b": 0.006765042284363295,
            "google/gemma-2-9b-it": 0.004803507516609297,
            "google/gemma-2b": 0.00676016915613056,
            "google/gemma-2b-it": 0.006254314361925175,
            "google/gemma-7b": 0.006762544473748444,
            "google/gemma-7b-it": 0.005787626386065851,
            "meta-llama/Llama-3.1-8B": 0.0067652717029206486,
            "meta-llama/Llama-3.1-8B-Instruct": 0.00646912244547337,
            "meta-llama/Llama-3.2-1B": 0.00676375086637464,
            "meta-llama/Llama-3.2-1B-Instruct": 0.006694117196120041,
            "meta-llama/Llama-3.2-3B": 0.006765339710879607,
            "meta-llama/Llama-3.2-3B-Instruct": 0.006580944493534078,
            "meta-llama/Meta-Llama-3-8B": 0.006765377795038133,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.005821729440900679,
            "openai-community/gpt2": 0.006765369634164938,
            "openai-community/gpt2-large": 0.006764839156300612,
            "openai-community/gpt2-medium": 0.0067649887824742,
            "openai-community/gpt2-xl": 0.006762616137668644
        },
        "nq_open": {
            "01-ai/Yi-1.5-6B": 0.006361118274221954,
            "01-ai/Yi-1.5-6B-Chat": 0.0026371025306002245,
            "01-ai/Yi-1.5-9B": 0.005914238146623018,
            "01-ai/Yi-1.5-9B-Chat": 0.001631065502281289,
            "01-ai/Yi-6B": 0.006685856192186142,
            "01-ai/Yi-6B-Chat": 0.0017849926209927852,
            "01-ai/Yi-9B": 0.006644475792189071,
            "EleutherAI/pythia-1.4b-deduped": 0.0027582221088927757,
            "EleutherAI/pythia-12b": 0.003922264996900104,
            "EleutherAI/pythia-160m-deduped": 0.0007322856237378371,
            "EleutherAI/pythia-1b-deduped": 0.002494831007264402,
            "EleutherAI/pythia-2.8b-deduped": 0.0031917492023314175,
            "EleutherAI/pythia-410m-deduped": 0.0013527268817671333,
            "EleutherAI/pythia-6.9b-deduped": 0.0034964401930525977,
            "EleutherAI/pythia-70m-deduped": 0.0,
            "Qwen/Qwen1.5-0.5B": 0.0003916946315984659,
            "Qwen/Qwen1.5-0.5B-Chat": 0.0008301033613701402,
            "Qwen/Qwen1.5-1.8B": 0.00039169463159846824,
            "Qwen/Qwen1.5-1.8B-Chat": 0.001535893325791709,
            "Qwen/Qwen1.5-14B": 0.0005537863080294984,
            "Qwen/Qwen1.5-14B-Chat": 0.00039169463159847393,
            "Qwen/Qwen1.5-4B": 0.000479659505720111,
            "Qwen/Qwen1.5-4B-Chat": 0.0019833711912597843,
            "Qwen/Qwen1.5-7B": 0.0007322856237378222,
            "Qwen/Qwen1.5-7B-Chat": 0.0002770083102492981,
            "Qwen/Qwen2-0.5B": 0.0012658893134548793,
            "Qwen/Qwen2-0.5B-Instruct": 0.002637102530600205,
            "Qwen/Qwen2-1.5B": 0.00039169463159847143,
            "Qwen/Qwen2-1.5B-Instruct": 0.0015842211138014813,
            "Qwen/Qwen2-7B": 0.0018264860716231059,
            "Qwen/Qwen2-7B-Instruct": 0.0018869317722298065,
            "Qwen/Qwen2.5-0.5B": 0.0035458186234053855,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.0023430325233738786,
            "Qwen/Qwen2.5-1.5B": 0.004459738708546969,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.0033743430444957883,
            "Qwen/Qwen2.5-14B": 0.007302458494264471,
            "Qwen/Qwen2.5-14B-Instruct": 0.0035555940821433195,
            "Qwen/Qwen2.5-3B": 0.006180080198319078,
            "Qwen/Qwen2.5-3B-Instruct": 0.0015842211138014865,
            "Qwen/Qwen2.5-7B": 0.007024849442984049,
            "Qwen/Qwen2.5-7B-Instruct": 0.0034864622923360808,
            "google/gemma-2-2b": 0.006061123452522547,
            "google/gemma-2-2b-it": 0.005161423800745139,
            "google/gemma-2-9b": 0.0073049780372605125,
            "google/gemma-2-9b-it": 0.005565936201790636,
            "google/gemma-2b": 0.005114413848821538,
            "google/gemma-2b-it": 0.0030197979535715523,
            "google/gemma-7b": 0.006847594281617297,
            "google/gemma-7b-it": 0.004803790536844744,
            "meta-llama/Llama-3.1-8B": 0.006612966749708312,
            "meta-llama/Llama-3.1-8B-Instruct": 0.006337671208941927,
            "meta-llama/Llama-3.2-1B": 0.003913622883962475,
            "meta-llama/Llama-3.2-1B-Instruct": 0.0035162929156436185,
            "meta-llama/Llama-3.2-3B": 0.006184236482599438,
            "meta-llama/Llama-3.2-3B-Instruct": 0.006253950610420027,
            "meta-llama/Meta-Llama-3-8B": 0.0068666262831490014,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.00582147850549044,
            "openai-community/gpt2": 0.0007827376152844582,
            "openai-community/gpt2-large": 0.0019261201912579608,
            "openai-community/gpt2-medium": 0.0015358933257917083,
            "openai-community/gpt2-xl": 0.0025239943627109384
        },
        "sst2": {
            "01-ai/Yi-1.5-6B": 0.011507058737039125,
            "01-ai/Yi-1.5-6B-Chat": 0.0089621854485471,
            "01-ai/Yi-1.5-9B": 0.009442603267232971,
            "01-ai/Yi-1.5-9B-Chat": 0.009557356094989476,
            "01-ai/Yi-6B": 0.008642706843234248,
            "01-ai/Yi-6B-Chat": 0.009024222176285861,
            "01-ai/Yi-9B": 0.008443074798844208,
            "EleutherAI/pythia-1.4b-deduped": 0.0169343211533256,
            "EleutherAI/pythia-12b": 0.016462316115268008,
            "EleutherAI/pythia-160m-deduped": 0.016939001525351532,
            "EleutherAI/pythia-1b-deduped": 0.016121867105083603,
            "EleutherAI/pythia-2.8b-deduped": 0.015094111195471065,
            "EleutherAI/pythia-410m-deduped": 0.015600968787224336,
            "EleutherAI/pythia-6.9b-deduped": 0.016925759411718245,
            "EleutherAI/pythia-70m-deduped": 0.016941452632752724,
            "Qwen/Qwen1.5-0.5B": 0.016939001525351532,
            "Qwen/Qwen1.5-0.5B-Chat": 0.013209651416241001,
            "Qwen/Qwen1.5-1.8B": 0.01645282049019052,
            "Qwen/Qwen1.5-1.8B-Chat": 0.011713511040431675,
            "Qwen/Qwen1.5-14B": 0.008023854328869198,
            "Qwen/Qwen1.5-14B-Chat": 0.008023854328869177,
            "Qwen/Qwen1.5-4B": 0.010154741963033094,
            "Qwen/Qwen1.5-4B-Chat": 0.009325791021628792,
            "Qwen/Qwen1.5-7B": 0.009835698073987964,
            "Qwen/Qwen1.5-7B-Chat": 0.008510316584597707,
            "Qwen/Qwen2-0.5B": 0.014511636623169847,
            "Qwen/Qwen2-0.5B-Instruct": 0.014368594382173113,
            "Qwen/Qwen2-1.5B": 0.010257707759295584,
            "Qwen/Qwen2-1.5B-Instruct": 0.011161768083128763,
            "Qwen/Qwen2-7B": 0.008836292936187594,
            "Qwen/Qwen2-7B-Instruct": 0.009085669152846613,
            "Qwen/Qwen2.5-0.5B": 0.016884003462459954,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.014416851761963978,
            "Qwen/Qwen2.5-1.5B": 0.010843320972287825,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.010409159243095439,
            "Qwen/Qwen2.5-14B": 0.010359067206812074,
            "Qwen/Qwen2.5-14B-Instruct": 0.009085669152846613,
            "Qwen/Qwen2.5-3B": 0.010102641365451158,
            "Qwen/Qwen2.5-3B-Instruct": 0.010701827730093302,
            "Qwen/Qwen2.5-7B": 0.009266588332836693,
            "Qwen/Qwen2.5-7B-Instruct": 0.008306413186332583,
            "google/gemma-2-2b": 0.01561736482295246,
            "google/gemma-2-2b-it": 0.009085669152846613,
            "google/gemma-2-9b": 0.011834123005390905,
            "google/gemma-2-9b-it": 0.009146538264185705,
            "google/gemma-2b": 0.016816215108958362,
            "google/gemma-2b-it": 0.014626931678262884,
            "google/gemma-7b": 0.014464530608155838,
            "google/gemma-7b-it": 0.009325791021628798,
            "meta-llama/Llama-3.1-8B": 0.015744466531019657,
            "meta-llama/Llama-3.1-8B-Instruct": 0.011631759293505479,
            "meta-llama/Llama-3.2-1B": 0.016481016111204408,
            "meta-llama/Llama-3.2-1B-Instruct": 0.015395207025786267,
            "meta-llama/Llama-3.2-3B": 0.01535926921473779,
            "meta-llama/Llama-3.2-3B-Instruct": 0.011464927097018506,
            "meta-llama/Meta-Llama-3-8B": 0.01620719564381345,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.008707887141832765,
            "openai-community/gpt2": 0.016855362214590282,
            "openai-community/gpt2-large": 0.01694185368929243,
            "openai-community/gpt2-medium": 0.016499328865664707,
            "openai-community/gpt2-xl": 0.016939001525351532
        },
        "winogrande": {
            "01-ai/Yi-1.5-6B": 0.012621707979798502,
            "01-ai/Yi-1.5-6B-Chat": 0.01271748105247804,
            "01-ai/Yi-1.5-9B": 0.012430046102144337,
            "01-ai/Yi-1.5-9B-Chat": 0.012173009642449153,
            "01-ai/Yi-6B": 0.012758813448064605,
            "01-ai/Yi-6B-Chat": 0.012696531870038611,
            "01-ai/Yi-9B": 0.012510697991453934,
            "EleutherAI/pythia-1.4b-deduped": 0.013932814110418025,
            "EleutherAI/pythia-12b": 0.013502479670791278,
            "EleutherAI/pythia-160m-deduped": 0.014051956064076896,
            "EleutherAI/pythia-1b-deduped": 0.014030404213405791,
            "EleutherAI/pythia-2.8b-deduped": 0.013848684086658585,
            "EleutherAI/pythia-410m-deduped": 0.014019317531542563,
            "EleutherAI/pythia-6.9b-deduped": 0.013594002763035507,
            "EleutherAI/pythia-70m-deduped": 0.014047122916440415,
            "Qwen/Qwen1.5-0.5B": 0.013974847640536194,
            "Qwen/Qwen1.5-0.5B-Chat": 0.013981711904049733,
            "Qwen/Qwen1.5-1.8B": 0.013702520871485949,
            "Qwen/Qwen1.5-1.8B-Chat": 0.013795927003124946,
            "Qwen/Qwen1.5-14B": 0.012758813448064607,
            "Qwen/Qwen1.5-14B-Chat": 0.013000454144859902,
            "Qwen/Qwen1.5-4B": 0.01347000744392069,
            "Qwen/Qwen1.5-4B-Chat": 0.013254029695143351,
            "Qwen/Qwen1.5-7B": 0.01330771492894175,
            "Qwen/Qwen1.5-7B-Chat": 0.013380909249751242,
            "Qwen/Qwen2-0.5B": 0.013898585965412342,
            "Qwen/Qwen2-0.5B-Instruct": 0.01395233031191561,
            "Qwen/Qwen2-1.5B": 0.013315218762417397,
            "Qwen/Qwen2-1.5B-Instruct": 0.013395059320137332,
            "Qwen/Qwen2-7B": 0.012566815015698162,
            "Qwen/Qwen2-7B-Instruct": 0.012868639066091536,
            "Qwen/Qwen2.5-0.5B": 0.013935709739615713,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.013952330311915603,
            "Qwen/Qwen2.5-1.5B": 0.013540144376588903,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.01358230628499287,
            "Qwen/Qwen2.5-14B": 0.012134386019865346,
            "Qwen/Qwen2.5-14B-Instruct": 0.01200207862948574,
            "Qwen/Qwen2.5-3B": 0.013054277568469238,
            "Qwen/Qwen2.5-3B-Instruct": 0.012982160200926582,
            "Qwen/Qwen2.5-7B": 0.01248790476062631,
            "Qwen/Qwen2.5-7B-Instruct": 0.012799397296204171,
            "google/gemma-2-2b": 0.01304541671607257,
            "google/gemma-2-2b-it": 0.012926209475483568,
            "google/gemma-2-9b": 0.012298278833972385,
            "google/gemma-2-9b-it": 0.011988541844843915,
            "google/gemma-2b": 0.01341598137054513,
            "google/gemma-2b-it": 0.013594002763035516,
            "google/gemma-7b": 0.01214731471340311,
            "google/gemma-7b-it": 0.013036512096747976,
            "meta-llama/Llama-3.1-8B": 0.012236307219708264,
            "meta-llama/Llama-3.1-8B-Instruct": 0.012394724896983794,
            "meta-llama/Llama-3.2-1B": 0.013712536036556673,
            "meta-llama/Llama-3.2-1B-Instruct": 0.013682036993397413,
            "meta-llama/Llama-3.2-3B": 0.01293564649932531,
            "meta-llama/Llama-3.2-3B-Instruct": 0.013036512096747986,
            "meta-llama/Meta-Llama-3-8B": 0.012322700705552667,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.012675392786772724,
            "openai-community/gpt2": 0.014045126130978598,
            "openai-community/gpt2-large": 0.013972488371616692,
            "openai-community/gpt2-medium": 0.014025142640639513,
            "openai-community/gpt2-xl": 0.013856250072796315
        },
        "hellaswag": {
            "01-ai/Yi-1.5-6B": 0.004309945772658184,
            "01-ai/Yi-1.5-6B-Chat": 0.0042282652261513625,
            "01-ai/Yi-1.5-9B": 0.004149412218878544,
            "01-ai/Yi-1.5-9B-Chat": 0.004094481222041068,
            "01-ai/Yi-6B": 0.004332074293773088,
            "01-ai/Yi-6B-Chat": 0.004293949207894309,
            "01-ai/Yi-9B": 0.00428195160072518,
            "EleutherAI/pythia-1.4b-deduped": 0.004981811000438133,
            "EleutherAI/pythia-12b": 0.004686592303021876,
            "EleutherAI/pythia-160m-deduped": 0.00463818146181519,
            "EleutherAI/pythia-1b-deduped": 0.004999385000681311,
            "EleutherAI/pythia-2.8b-deduped": 0.004910707434245147,
            "EleutherAI/pythia-410m-deduped": 0.0049234434118310575,
            "EleutherAI/pythia-6.9b-deduped": 0.004741025915629574,
            "EleutherAI/pythia-70m-deduped": 0.004468886672853918,
            "Qwen/Qwen1.5-0.5B": 0.00499962584858719,
            "Qwen/Qwen1.5-0.5B-Chat": 0.004969014500935631,
            "Qwen/Qwen1.5-1.8B": 0.0048790925953965045,
            "Qwen/Qwen1.5-1.8B-Chat": 0.004900648185216472,
            "Qwen/Qwen1.5-14B": 0.004045233663404438,
            "Qwen/Qwen1.5-14B-Chat": 0.003985120841180391,
            "Qwen/Qwen1.5-4B": 0.004519119631545974,
            "Qwen/Qwen1.5-4B-Chat": 0.004603456872994313,
            "Qwen/Qwen1.5-7B": 0.004211739412035208,
            "Qwen/Qwen1.5-7B-Chat": 0.004208535514536642,
            "Qwen/Qwen2-0.5B": 0.004999269773659341,
            "Qwen/Qwen2-0.5B-Instruct": 0.005000248418671623,
            "Qwen/Qwen2-1.5B": 0.004757493286830131,
            "Qwen/Qwen2-1.5B-Instruct": 0.004743366521005505,
            "Qwen/Qwen2-7B": 0.004090268576720382,
            "Qwen/Qwen2-7B-Instruct": 0.003950612070752011,
            "Qwen/Qwen2.5-0.5B": 0.004995837851610326,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.00499438989197257,
            "Qwen/Qwen2.5-1.5B": 0.0046745652371122815,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.004652125882596241,
            "Qwen/Qwen2.5-14B": 0.003767024694304935,
            "Qwen/Qwen2.5-14B-Instruct": 0.0036372464799891875,
            "Qwen/Qwen2.5-3B": 0.004411420413313965,
            "Qwen/Qwen2.5-3B-Instruct": 0.0043286100178315376,
            "Qwen/Qwen2.5-7B": 0.004077551549969762,
            "Qwen/Qwen2.5-7B-Instruct": 0.0039645129254769354,
            "google/gemma-2-2b": 0.0044424034592603825,
            "google/gemma-2-2b-it": 0.004462842894015742,
            "google/gemma-2-9b": 0.004012894383376253,
            "google/gemma-2-9b-it": 0.003994940169101136,
            "google/gemma-2b": 0.004518171907722933,
            "google/gemma-2b-it": 0.004797017837992119,
            "google/gemma-7b": 0.0039295139785997715,
            "google/gemma-7b-it": 0.004448582919199867,
            "meta-llama/Llama-3.1-8B": 0.004052480877206502,
            "meta-llama/Llama-3.1-8B-Instruct": 0.004038678879622764,
            "meta-llama/Llama-3.2-1B": 0.00479406479990929,
            "meta-llama/Llama-3.2-1B-Instruct": 0.004861185257960668,
            "meta-llama/Llama-3.2-3B": 0.004377768893631274,
            "meta-llama/Llama-3.2-3B-Instruct": 0.004505752565401075,
            "meta-llama/Meta-Llama-3-8B": 0.004058971239704706,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.004298118470009445,
            "openai-community/gpt2": 0.004629667631940664,
            "openai-community/gpt2-large": 0.004978298338331386,
            "openai-community/gpt2-medium": 0.004885287156663291,
            "openai-community/gpt2-xl": 0.004999510327056756
        },
        "social_iqa": {
            "01-ai/Yi-1.5-6B": 0.011304584145927783,
            "01-ai/Yi-1.5-6B-Chat": 0.01131347788750555,
            "01-ai/Yi-1.5-9B": 0.011303611339153356,
            "01-ai/Yi-1.5-9B-Chat": 0.011267028794184973,
            "01-ai/Yi-6B": 0.011308373735025405,
            "01-ai/Yi-6B-Chat": 0.011313691251392989,
            "01-ai/Yi-9B": 0.011294116144908542,
            "EleutherAI/pythia-1.4b-deduped": 0.011081681624606212,
            "EleutherAI/pythia-12b": 0.01120063727372182,
            "EleutherAI/pythia-160m-deduped": 0.010955548814246934,
            "EleutherAI/pythia-1b-deduped": 0.011098061143371356,
            "EleutherAI/pythia-2.8b-deduped": 0.011122558066098069,
            "EleutherAI/pythia-410m-deduped": 0.011086424438789676,
            "EleutherAI/pythia-6.9b-deduped": 0.01118172179394835,
            "EleutherAI/pythia-70m-deduped": 0.010860020281873285,
            "Qwen/Qwen1.5-0.5B": 0.011178123214465785,
            "Qwen/Qwen1.5-0.5B-Chat": 0.011174475471772085,
            "Qwen/Qwen1.5-1.8B": 0.011261582070818423,
            "Qwen/Qwen1.5-1.8B-Chat": 0.01124473114819318,
            "Qwen/Qwen1.5-14B": 0.011290523693989227,
            "Qwen/Qwen1.5-14B-Chat": 0.011307217422300715,
            "Qwen/Qwen1.5-4B": 0.011313068928806718,
            "Qwen/Qwen1.5-4B-Chat": 0.011291996440195285,
            "Qwen/Qwen1.5-7B": 0.011307614732827402,
            "Qwen/Qwen1.5-7B-Chat": 0.01130837373502542,
            "Qwen/Qwen2-0.5B": 0.011192223024107365,
            "Qwen/Qwen2-0.5B-Instruct": 0.011205539177566705,
            "Qwen/Qwen2-1.5B": 0.011274150206980896,
            "Qwen/Qwen2-1.5B-Instruct": 0.011313353423379498,
            "Qwen/Qwen2-7B": 0.011309749296679794,
            "Qwen/Qwen2-7B-Instruct": 0.011301523080895128,
            "Qwen/Qwen2.5-0.5B": 0.011238140029326911,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.01129126602959519,
            "Qwen/Qwen2.5-1.5B": 0.011311456657738512,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.011313922391063588,
            "Qwen/Qwen2.5-14B": 0.011253451731222587,
            "Qwen/Qwen2.5-14B-Instruct": 0.011274150206980896,
            "Qwen/Qwen2.5-3B": 0.011314070555035511,
            "Qwen/Qwen2.5-3B-Instruct": 0.011304584145927811,
            "Qwen/Qwen2.5-7B": 0.011261582070818421,
            "Qwen/Qwen2.5-7B-Instruct": 0.011307217422300711,
            "google/gemma-2-2b": 0.011310063517892637,
            "google/gemma-2-2b-it": 0.011314064628513767,
            "google/gemma-2-9b": 0.01124343708855983,
            "google/gemma-2-9b-it": 0.011181721793948343,
            "google/gemma-2b": 0.011307614732827419,
            "google/gemma-2b-it": 0.011296128605570367,
            "google/gemma-7b": 0.011310656364332601,
            "google/gemma-7b-it": 0.011288225113420704,
            "meta-llama/Llama-3.1-8B": 0.011308000169997612,
            "meta-llama/Llama-3.1-8B-Instruct": 0.011313857198301226,
            "meta-llama/Llama-3.2-1B": 0.011193930340551272,
            "meta-llama/Llama-3.2-1B-Instruct": 0.011210331273967561,
            "meta-llama/Llama-3.2-3B": 0.011289769431024861,
            "meta-llama/Llama-3.2-3B-Instruct": 0.011293421495595713,
            "meta-llama/Meta-Llama-3-8B": 0.011287435053883957,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.011312737009429417,
            "openai-community/gpt2": 0.010902877999595323,
            "openai-community/gpt2-large": 0.011064683986236569,
            "openai-community/gpt2-medium": 0.011041917016537851,
            "openai-community/gpt2-xl": 0.011098061143371356
        },
        "mathqa": {
            "01-ai/Yi-1.5-6B": 0.009026420365433753,
            "01-ai/Yi-1.5-6B-Chat": 0.009000432464854992,
            "01-ai/Yi-1.5-9B": 0.009092521254346507,
            "01-ai/Yi-1.5-9B-Chat": 0.009094630601149642,
            "01-ai/Yi-6B": 0.008678253339399545,
            "01-ai/Yi-6B-Chat": 0.008672062303343076,
            "01-ai/Yi-9B": 0.00893282081730383,
            "EleutherAI/pythia-1.4b-deduped": 0.007911755262023774,
            "EleutherAI/pythia-12b": 0.00796108364801871,
            "EleutherAI/pythia-160m-deduped": 0.007555381108481063,
            "EleutherAI/pythia-1b-deduped": 0.007857518810292742,
            "EleutherAI/pythia-2.8b-deduped": 0.007890234123285118,
            "EleutherAI/pythia-410m-deduped": 0.00770172129542906,
            "EleutherAI/pythia-6.9b-deduped": 0.007978403103631442,
            "EleutherAI/pythia-70m-deduped": 0.007377141600569718,
            "Qwen/Qwen1.5-0.5B": 0.00809535074004893,
            "Qwen/Qwen1.5-0.5B-Chat": 0.008098583692885271,
            "Qwen/Qwen1.5-1.8B": 0.008374198905276724,
            "Qwen/Qwen1.5-1.8B-Chat": 0.008414188017330376,
            "Qwen/Qwen1.5-14B": 0.009008268438286164,
            "Qwen/Qwen1.5-14B-Chat": 0.008942306034613426,
            "Qwen/Qwen1.5-4B": 0.008550753472418224,
            "Qwen/Qwen1.5-4B-Chat": 0.008587586653113786,
            "Qwen/Qwen1.5-7B": 0.00886348847927826,
            "Qwen/Qwen1.5-7B-Chat": 0.00892591308199658,
            "Qwen/Qwen2-0.5B": 0.008085616216226046,
            "Qwen/Qwen2-0.5B-Instruct": 0.00809211184775404,
            "Qwen/Qwen2-1.5B": 0.008515050796766762,
            "Qwen/Qwen2-1.5B-Instruct": 0.008618770220993815,
            "Qwen/Qwen2-7B": 0.009044290513745381,
            "Qwen/Qwen2-7B-Instruct": 0.009035528442190946,
            "Qwen/Qwen2.5-0.5B": 0.00829916392351649,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.008371490230938661,
            "Qwen/Qwen2.5-1.5B": 0.00874160924448244,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.008690505330494359,
            "Qwen/Qwen2.5-14B": 0.009147267863176694,
            "Qwen/Qwen2.5-14B-Instruct": 0.009148706843976114,
            "Qwen/Qwen2.5-3B": 0.008852312963224014,
            "Qwen/Qwen2.5-3B-Instruct": 0.008669988966158285,
            "Qwen/Qwen2.5-7B": 0.009076697959382814,
            "Qwen/Qwen2.5-7B-Instruct": 0.008982927262455581,
            "google/gemma-2-2b": 0.00861437472958525,
            "google/gemma-2-2b-it": 0.008569330302087065,
            "google/gemma-2-9b": 0.009128029560185102,
            "google/gemma-2-9b-it": 0.00904429051374539,
            "google/gemma-2b": 0.008483180074965633,
            "google/gemma-2b-it": 0.008560082076644165,
            "google/gemma-7b": 0.00892311898573328,
            "google/gemma-7b-it": 0.008735876431478832,
            "meta-llama/Llama-3.1-8B": 0.008958064421353744,
            "meta-llama/Llama-3.1-8B-Instruct": 0.008930070999502231,
            "meta-llama/Llama-3.2-1B": 0.008284830813404332,
            "meta-llama/Llama-3.2-1B-Instruct": 0.008609959521088478,
            "meta-llama/Llama-3.2-3B": 0.008674130808976012,
            "meta-llama/Llama-3.2-3B-Instruct": 0.008855528642722368,
            "meta-llama/Meta-Llama-3-8B": 0.00895288192347811,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.009027449492858391,
            "openai-community/gpt2": 0.007443831666570558,
            "openai-community/gpt2-large": 0.0076215577382015304,
            "openai-community/gpt2-medium": 0.0076977793609442485,
            "openai-community/gpt2-xl": 0.007798054851247488
        },
        "anli_r1": {
            "01-ai/Yi-1.5-6B": 0.015743152379585547,
            "01-ai/Yi-1.5-6B-Chat": 0.01581395210189663,
            "01-ai/Yi-1.5-9B": 0.015736792768752,
            "01-ai/Yi-1.5-9B-Chat": 0.015752210388771833,
            "01-ai/Yi-6B": 0.015635487471405193,
            "01-ai/Yi-6B-Chat": 0.015730176046009046,
            "01-ai/Yi-9B": 0.015790799515836763,
            "EleutherAI/pythia-1.4b-deduped": 0.015080663991563098,
            "EleutherAI/pythia-12b": 0.014632638658632902,
            "EleutherAI/pythia-160m-deduped": 0.014899597242811468,
            "EleutherAI/pythia-1b-deduped": 0.014899597242811468,
            "EleutherAI/pythia-2.8b-deduped": 0.014842213153411254,
            "EleutherAI/pythia-410m-deduped": 0.01480686473373886,
            "EleutherAI/pythia-6.9b-deduped": 0.014721675438880233,
            "EleutherAI/pythia-70m-deduped": 0.014865395385928369,
            "Qwen/Qwen1.5-0.5B": 0.014512395033543138,
            "Qwen/Qwen1.5-0.5B-Chat": 0.015158521721486776,
            "Qwen/Qwen1.5-1.8B": 0.014910846164229852,
            "Qwen/Qwen1.5-1.8B-Chat": 0.014965960710224501,
            "Qwen/Qwen1.5-14B": 0.015813952101896633,
            "Qwen/Qwen1.5-14B-Chat": 0.015663503610155283,
            "Qwen/Qwen1.5-4B": 0.01554324910025554,
            "Qwen/Qwen1.5-4B-Chat": 0.015693223928730373,
            "Qwen/Qwen1.5-7B": 0.01581727492920901,
            "Qwen/Qwen1.5-7B-Chat": 0.015635487471405182,
            "Qwen/Qwen2-0.5B": 0.014399942998441273,
            "Qwen/Qwen2-0.5B-Instruct": 0.014709193056057114,
            "Qwen/Qwen2-1.5B": 0.015213890444671287,
            "Qwen/Qwen2-1.5B-Instruct": 0.015763390640483706,
            "Qwen/Qwen2-7B": 0.015784807891138772,
            "Qwen/Qwen2-7B-Instruct": 0.015445859463771304,
            "Qwen/Qwen2.5-0.5B": 0.014658474370508993,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.014794927843348635,
            "Qwen/Qwen2.5-1.5B": 0.015512467135715087,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.015730176046009046,
            "Qwen/Qwen2.5-14B": 0.015424555647308498,
            "Qwen/Qwen2.5-14B-Instruct": 0.014442734941575025,
            "Qwen/Qwen2.5-3B": 0.015784807891138772,
            "Qwen/Qwen2.5-3B-Instruct": 0.015663503610155286,
            "Qwen/Qwen2.5-7B": 0.015790799515836763,
            "Qwen/Qwen2.5-7B-Instruct": 0.0144568322948011,
            "google/gemma-2-2b": 0.015019206922356953,
            "google/gemma-2-2b-it": 0.015814743314581818,
            "google/gemma-2-9b": 0.015645087688113814,
            "google/gemma-2-9b-it": 0.014456832294801101,
            "google/gemma-2b": 0.014987482264363937,
            "google/gemma-2b-it": 0.015070604603768408,
            "google/gemma-7b": 0.015640320317040095,
            "google/gemma-7b-it": 0.01577824302490459,
            "meta-llama/Llama-3.1-8B": 0.015139491543780534,
            "meta-llama/Llama-3.1-8B-Instruct": 0.01579621855130262,
            "meta-llama/Llama-3.2-1B": 0.015149042659306623,
            "meta-llama/Llama-3.2-1B-Instruct": 0.014794927843348632,
            "meta-llama/Llama-3.2-3B": 0.015008706182121731,
            "meta-llama/Llama-3.2-3B-Instruct": 0.015704987954361798,
            "meta-llama/Meta-Llama-3-8B": 0.014944140233795021,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.015812179641814892,
            "openai-community/gpt2": 0.01499813134840269,
            "openai-community/gpt2-large": 0.014794927843348642,
            "openai-community/gpt2-medium": 0.014944140233795018,
            "openai-community/gpt2-xl": 0.014955087918653603
        },
        "piqa": {
            "01-ai/Yi-1.5-6B": 0.009345961674823409,
            "01-ai/Yi-1.5-6B-Chat": 0.009530351270479397,
            "01-ai/Yi-1.5-9B": 0.009190740295126473,
            "01-ai/Yi-1.5-9B-Chat": 0.009298209954776728,
            "01-ai/Yi-6B": 0.00953929982817407,
            "01-ai/Yi-6B-Chat": 0.009916841655042807,
            "01-ai/Yi-9B": 0.009457844699952377,
            "EleutherAI/pythia-1.4b-deduped": 0.01038925680329602,
            "EleutherAI/pythia-12b": 0.009837063180625326,
            "EleutherAI/pythia-160m-deduped": 0.011320331012905074,
            "EleutherAI/pythia-1b-deduped": 0.01066735379238821,
            "EleutherAI/pythia-2.8b-deduped": 0.010241826155811627,
            "EleutherAI/pythia-410m-deduped": 0.010959127105167044,
            "EleutherAI/pythia-6.9b-deduped": 0.009861236071080751,
            "EleutherAI/pythia-70m-deduped": 0.011500864675166568,
            "Qwen/Qwen1.5-0.5B": 0.010765602506939068,
            "Qwen/Qwen1.5-0.5B-Chat": 0.011009071725162498,
            "Qwen/Qwen1.5-1.8B": 0.010192864802278045,
            "Qwen/Qwen1.5-1.8B-Chat": 0.010343392940090013,
            "Qwen/Qwen1.5-14B": 0.009364873741341448,
            "Qwen/Qwen1.5-14B-Chat": 0.009908965890558213,
            "Qwen/Qwen1.5-4B": 0.0098126829508152,
            "Qwen/Qwen1.5-4B-Chat": 0.010032309105568783,
            "Qwen/Qwen1.5-7B": 0.009466997964536391,
            "Qwen/Qwen1.5-7B-Chat": 0.009979042717267312,
            "Qwen/Qwen2-0.5B": 0.01076029507058038,
            "Qwen/Qwen2-0.5B-Instruct": 0.01071173289158835,
            "Qwen/Qwen2-1.5B": 0.010054810789671818,
            "Qwen/Qwen2-1.5B-Instruct": 0.009971345364651068,
            "Qwen/Qwen2-7B": 0.009150819250948718,
            "Qwen/Qwen2-7B-Instruct": 0.009210530962579795,
            "Qwen/Qwen2.5-0.5B": 0.010695225308183138,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.01067855639814923,
            "Qwen/Qwen2.5-1.5B": 0.00995588425029171,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.009963625892809545,
            "Qwen/Qwen2.5-14B": 0.00894422022020494,
            "Qwen/Qwen2.5-14B-Instruct": 0.008996986448433702,
            "Qwen/Qwen2.5-3B": 0.009530351270479397,
            "Qwen/Qwen2.5-3B-Instruct": 0.009609984714384607,
            "Qwen/Qwen2.5-7B": 0.009383679003767333,
            "Qwen/Qwen2.5-7B-Instruct": 0.009269232237679923,
            "google/gemma-2-2b": 0.00947612538304945,
            "google/gemma-2-2b-it": 0.009420971671017915,
            "google/gemma-2-9b": 0.008770149677689312,
            "google/gemma-2-9b-it": 0.009317391893706853,
            "google/gemma-2b": 0.009609984714384612,
            "google/gemma-2b-it": 0.01006226814077261,
            "google/gemma-7b": 0.00892289994808559,
            "google/gemma-7b-it": 0.009729897956410025,
            "meta-llama/Llama-3.1-8B": 0.00912057829275865,
            "meta-llama/Llama-3.1-8B-Instruct": 0.009069597302604,
            "meta-llama/Llama-3.2-1B": 0.010121156016819262,
            "meta-llama/Llama-3.2-1B-Instruct": 0.010128421335088678,
            "meta-llama/Llama-3.2-3B": 0.009653357463605336,
            "meta-llama/Llama-3.2-3B-Instruct": 0.009812682950815202,
            "meta-llama/Meta-Llama-3-8B": 0.009220384152336641,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.009530351270479397,
            "openai-community/gpt2": 0.011294565805619015,
            "openai-community/gpt2-large": 0.01077089236746368,
            "openai-community/gpt2-medium": 0.011022346708970234,
            "openai-community/gpt2-xl": 0.010639030620156989
        },
        "sciq": {
            "01-ai/Yi-1.5-6B": 0.007454835650406727,
            "01-ai/Yi-1.5-6B-Chat": 0.007855297938697582,
            "01-ai/Yi-1.5-9B": 0.0066278147173806975,
            "01-ai/Yi-1.5-9B-Chat": 0.006627814717380703,
            "01-ai/Yi-6B": 0.007088105617246442,
            "01-ai/Yi-6B-Chat": 0.011171786285496497,
            "01-ai/Yi-9B": 0.005733836139695438,
            "EleutherAI/pythia-1.4b-deduped": 0.01319083007236448,
            "EleutherAI/pythia-12b": 0.011297239823409312,
            "EleutherAI/pythia-160m-deduped": 0.015195720118175113,
            "EleutherAI/pythia-1b-deduped": 0.011569479368271287,
            "EleutherAI/pythia-2.8b-deduped": 0.011884495834541674,
            "EleutherAI/pythia-410m-deduped": 0.013842963108656603,
            "EleutherAI/pythia-6.9b-deduped": 0.010945263761042955,
            "EleutherAI/pythia-70m-deduped": 0.015743152379585536,
            "Qwen/Qwen1.5-0.5B": 0.011994493230973428,
            "Qwen/Qwen1.5-0.5B-Chat": 0.013063179040595304,
            "Qwen/Qwen1.5-1.8B": 0.00973955126578514,
            "Qwen/Qwen1.5-1.8B-Chat": 0.010640169792499356,
            "Qwen/Qwen1.5-14B": 0.008963053962592076,
            "Qwen/Qwen1.5-14B-Chat": 0.010534798620855755,
            "Qwen/Qwen1.5-4B": 0.009575368801653886,
            "Qwen/Qwen1.5-4B-Chat": 0.01339490288966001,
            "Qwen/Qwen1.5-7B": 0.010570133761108654,
            "Qwen/Qwen1.5-7B-Chat": 0.0117721103708122,
            "Qwen/Qwen2-0.5B": 0.010391293421849877,
            "Qwen/Qwen2-0.5B-Instruct": 0.010131468138757004,
            "Qwen/Qwen2-1.5B": 0.008484573530118585,
            "Qwen/Qwen2-1.5B-Instruct": 0.008384169266796401,
            "Qwen/Qwen2-7B": 0.007799733061832019,
            "Qwen/Qwen2-7B-Instruct": 0.008823426366942336,
            "Qwen/Qwen2.5-0.5B": 0.009320454434783191,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.010281328012747394,
            "Qwen/Qwen2.5-1.5B": 0.007964887911291605,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.007454835650406727,
            "Qwen/Qwen2.5-14B": 0.006488921798427414,
            "Qwen/Qwen2.5-14B-Instruct": 0.00774364022691931,
            "Qwen/Qwen2.5-3B": 0.006627814717380701,
            "Qwen/Qwen2.5-3B-Instruct": 0.008916866630745939,
            "Qwen/Qwen2.5-7B": 0.006895472974897888,
            "Qwen/Qwen2.5-7B-Instruct": 0.0076870078762864245,
            "google/gemma-2-2b": 0.006418114379799741,
            "google/gemma-2-2b-it": 0.00843458014024063,
            "google/gemma-2-9b": 0.00530916068575698,
            "google/gemma-2-9b-it": 0.006418114379799741,
            "google/gemma-2b": 0.008870325962594766,
            "google/gemma-2b-it": 0.010605256784796574,
            "google/gemma-7b": 0.007335175853706834,
            "google/gemma-7b-it": 0.008434580140240639,
            "meta-llama/Llama-3.1-8B": 0.006488921798427416,
            "meta-llama/Llama-3.1-8B-Instruct": 0.006418114379799741,
            "meta-llama/Llama-3.2-1B": 0.00896305396259207,
            "meta-llama/Llama-3.2-1B-Instruct": 0.008534156773333431,
            "meta-llama/Llama-3.2-3B": 0.007799733061832025,
            "meta-llama/Llama-3.2-3B-Instruct": 0.007855297938697582,
            "meta-llama/Meta-Llama-3-8B": 0.0071508835212954446,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.007513751157474926,
            "openai-community/gpt2": 0.01514904265930663,
            "openai-community/gpt2-large": 0.014593284892852621,
            "openai-community/gpt2-medium": 0.014853842487270334,
            "openai-community/gpt2-xl": 0.013512312258920852
        },
        "commonsense_qa": {
            "01-ai/Yi-1.5-6B": 0.012726630083024071,
            "01-ai/Yi-1.5-6B-Chat": 0.012325225198723451,
            "01-ai/Yi-1.5-9B": 0.011802018846530007,
            "01-ai/Yi-1.5-9B-Chat": 0.011268624978801633,
            "01-ai/Yi-6B": 0.012726630083024068,
            "01-ai/Yi-6B-Chat": 0.01225521464233077,
            "01-ai/Yi-9B": 0.011603856781422558,
            "EleutherAI/pythia-1.4b-deduped": 0.01117578396411473,
            "EleutherAI/pythia-12b": 0.010884940080324158,
            "EleutherAI/pythia-160m-deduped": 0.01132338158892044,
            "EleutherAI/pythia-1b-deduped": 0.011305207486827687,
            "EleutherAI/pythia-2.8b-deduped": 0.011654350093704639,
            "EleutherAI/pythia-410m-deduped": 0.011250215810979042,
            "EleutherAI/pythia-6.9b-deduped": 0.011586881879177845,
            "EleutherAI/pythia-70m-deduped": 0.011377439773963998,
            "Qwen/Qwen1.5-0.5B": 0.0142834244777264,
            "Qwen/Qwen1.5-0.5B-Chat": 0.014227191671360575,
            "Qwen/Qwen1.5-1.8B": 0.013607879727439876,
            "Qwen/Qwen1.5-1.8B-Chat": 0.013054409950776526,
            "Qwen/Qwen1.5-14B": 0.010824462376464367,
            "Qwen/Qwen1.5-14B-Chat": 0.010763185143496067,
            "Qwen/Qwen1.5-4B": 0.012577752106542448,
            "Qwen/Qwen1.5-4B-Chat": 0.012487159508311585,
            "Qwen/Qwen1.5-7B": 0.01146601146601154,
            "Qwen/Qwen1.5-7B-Chat": 0.011341478090883527,
            "Qwen/Qwen2-0.5B": 0.014314146971345162,
            "Qwen/Qwen2-0.5B-Instruct": 0.014293390567093077,
            "Qwen/Qwen2-1.5B": 0.013419794775481147,
            "Qwen/Qwen2-1.5B-Instruct": 0.013022531002213353,
            "Qwen/Qwen2-7B": 0.011080924837411212,
            "Qwen/Qwen2-7B-Instruct": 0.01123172751912785,
            "Qwen/Qwen2.5-0.5B": 0.014253522973064033,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.014167165797714333,
            "Qwen/Qwen2.5-1.5B": 0.012434123245733735,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.01238014924901323,
            "Qwen/Qwen2.5-14B": 0.010333168375027148,
            "Qwen/Qwen2.5-14B-Instruct": 0.010444307085591489,
            "Qwen/Qwen2.5-3B": 0.01194413467602355,
            "Qwen/Qwen2.5-3B-Instruct": 0.011671038436522905,
            "Qwen/Qwen2.5-7B": 0.01010314476903187,
            "Qwen/Qwen2.5-7B-Instruct": 0.010864868854480418,
            "google/gemma-2-2b": 0.014308384323811102,
            "google/gemma-2-2b-it": 0.0131168037494241,
            "google/gemma-2-9b": 0.013245857283164164,
            "google/gemma-2-9b-it": 0.011430809442838384,
            "google/gemma-2b": 0.012856179020358158,
            "google/gemma-2b-it": 0.01431495355687843,
            "google/gemma-7b": 0.01409128618926753,
            "google/gemma-7b-it": 0.013116803749424104,
            "meta-llama/Llama-3.1-8B": 0.0130332081673615,
            "meta-llama/Llama-3.1-8B-Instruct": 0.012226783409751472,
            "meta-llama/Llama-3.2-1B": 0.014305233095109324,
            "meta-llama/Llama-3.2-1B-Instruct": 0.014099594443889921,
            "meta-llama/Llama-3.2-3B": 0.013529066799168448,
            "meta-llama/Llama-3.2-3B-Instruct": 0.012564981568550694,
            "meta-llama/Meta-Llama-3-8B": 0.013167424546204662,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.012500273456369256,
            "openai-community/gpt2": 0.011359497363584395,
            "openai-community/gpt2-large": 0.011430809442838398,
            "openai-community/gpt2-medium": 0.011341478090883527,
            "openai-community/gpt2-xl": 0.011359497363584395
        },
        "boolq": {
            "01-ai/Yi-1.5-6B": 0.006939251824863105,
            "01-ai/Yi-1.5-6B-Chat": 0.006304921569607263,
            "01-ai/Yi-1.5-9B": 0.006184327240690367,
            "01-ai/Yi-1.5-9B-Chat": 0.005649663619774143,
            "01-ai/Yi-6B": 0.007521796682240532,
            "01-ai/Yi-6B-Chat": 0.006584388531202196,
            "01-ai/Yi-9B": 0.006184327240690374,
            "EleutherAI/pythia-1.4b-deduped": 0.008625883905552705,
            "EleutherAI/pythia-12b": 0.008212203003803802,
            "EleutherAI/pythia-160m-deduped": 0.008742437504570403,
            "EleutherAI/pythia-1b-deduped": 0.008536430524403959,
            "EleutherAI/pythia-2.8b-deduped": 0.008374337517726586,
            "EleutherAI/pythia-410m-deduped": 0.008626774352070746,
            "EleutherAI/pythia-6.9b-deduped": 0.00837111203475938,
            "EleutherAI/pythia-70m-deduped": 0.008488668235778606,
            "Qwen/Qwen1.5-0.5B": 0.008744686941762909,
            "Qwen/Qwen1.5-0.5B-Chat": 0.008744582253526263,
            "Qwen/Qwen1.5-1.8B": 0.008261778456573672,
            "Qwen/Qwen1.5-1.8B-Chat": 0.0076770210725111586,
            "Qwen/Qwen1.5-14B": 0.006152074564982397,
            "Qwen/Qwen1.5-14B-Chat": 0.005951258198835659,
            "Qwen/Qwen1.5-4B": 0.0072689494869396,
            "Qwen/Qwen1.5-4B-Chat": 0.007059417421689209,
            "Qwen/Qwen1.5-7B": 0.006649095508488924,
            "Qwen/Qwen1.5-7B-Chat": 0.006210949869232178,
            "Qwen/Qwen2-0.5B": 0.008513189460768055,
            "Qwen/Qwen2-0.5B-Instruct": 0.008339723407282288,
            "Qwen/Qwen2-1.5B": 0.007795370560089196,
            "Qwen/Qwen2-1.5B-Instruct": 0.007430940864240422,
            "Qwen/Qwen2-7B": 0.006263513133533241,
            "Qwen/Qwen2-7B-Instruct": 0.005979923446403403,
            "Qwen/Qwen2.5-0.5B": 0.00847388227919459,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.008261778456573674,
            "Qwen/Qwen2.5-1.5B": 0.007765176800187589,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.007243766816777982,
            "Qwen/Qwen2.5-14B": 0.00619500387506207,
            "Qwen/Qwen2.5-14B-Instruct": 0.005681110222539688,
            "Qwen/Qwen2.5-3B": 0.007325466295353579,
            "Qwen/Qwen2.5-3B-Instruct": 0.0069799467761453605,
            "Qwen/Qwen2.5-7B": 0.006294622267483764,
            "Qwen/Qwen2.5-7B-Instruct": 0.005985625684183212,
            "google/gemma-2-2b": 0.007705958419083052,
            "google/gemma-2-2b-it": 0.006430770316534756,
            "google/gemma-2-9b": 0.006415945954980932,
            "google/gemma-2-9b-it": 0.005494404326399935,
            "google/gemma-2b": 0.008063065224064633,
            "google/gemma-2b-it": 0.008413404209789987,
            "google/gemma-7b": 0.006518179131399637,
            "google/gemma-7b-it": 0.006743433267054196,
            "meta-llama/Llama-3.1-8B": 0.006542000663168085,
            "meta-llama/Llama-3.1-8B-Instruct": 0.006178975060597769,
            "meta-llama/Llama-3.2-1B": 0.008394940698368875,
            "meta-llama/Llama-3.2-1B-Instruct": 0.00791061920469764,
            "meta-llama/Llama-3.2-3B": 0.007662371410541708,
            "meta-llama/Llama-3.2-3B-Instruct": 0.007132608721450022,
            "meta-llama/Meta-Llama-3-8B": 0.006685413197479399,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.006340695266796407,
            "openai-community/gpt2": 0.008742169169427043,
            "openai-community/gpt2-large": 0.0085504542482809,
            "openai-community/gpt2-medium": 0.008614932353134942,
            "openai-community/gpt2-xl": 0.00849914969044927
        },
        "cola": {
            "01-ai/Yi-1.5-6B": 0.03057764386438787,
            "01-ai/Yi-1.5-6B-Chat": 0.031959416760597145,
            "01-ai/Yi-1.5-9B": 0.03109336541844063,
            "01-ai/Yi-1.5-9B-Chat": 0.029663980159563584,
            "01-ai/Yi-6B": 0.031331548234440475,
            "01-ai/Yi-6B-Chat": 0.031855819156683514,
            "01-ai/Yi-9B": 0.0319686923260229,
            "EleutherAI/pythia-1.4b-deduped": 0.029271027460858304,
            "EleutherAI/pythia-12b": 0.031131858043814457,
            "EleutherAI/pythia-160m-deduped": 0.0,
            "EleutherAI/pythia-1b-deduped": 0.0,
            "EleutherAI/pythia-2.8b-deduped": 0.03086000779738776,
            "EleutherAI/pythia-410m-deduped": 0.030997991107252907,
            "EleutherAI/pythia-6.9b-deduped": 0.031972062154903114,
            "EleutherAI/pythia-70m-deduped": 0.0,
            "Qwen/Qwen1.5-0.5B": 0.03164052762146506,
            "Qwen/Qwen1.5-0.5B-Chat": 0.03122922093665157,
            "Qwen/Qwen1.5-1.8B": 0.03081819267496062,
            "Qwen/Qwen1.5-1.8B-Chat": 0.0341722103779974,
            "Qwen/Qwen1.5-14B": 0.02570478831553826,
            "Qwen/Qwen1.5-14B-Chat": 0.03172623463960685,
            "Qwen/Qwen1.5-4B": 0.030137825169611193,
            "Qwen/Qwen1.5-4B-Chat": 0.03358477304296597,
            "Qwen/Qwen1.5-7B": 0.02557472289032862,
            "Qwen/Qwen1.5-7B-Chat": 0.03185504182179291,
            "Qwen/Qwen2-0.5B": 0.030982202871807175,
            "Qwen/Qwen2-0.5B-Instruct": 0.03155953327600522,
            "Qwen/Qwen2-1.5B": 0.034410120992966364,
            "Qwen/Qwen2-1.5B-Instruct": 0.03322356886614555,
            "Qwen/Qwen2-7B": 0.033085310213984274,
            "Qwen/Qwen2-7B-Instruct": 0.03309092257993245,
            "Qwen/Qwen2.5-0.5B": 0.032140220720729216,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.030608517294849903,
            "Qwen/Qwen2.5-1.5B": 0.03085537464749485,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.031282661879317074,
            "Qwen/Qwen2.5-14B": 0.031519047975359336,
            "Qwen/Qwen2.5-14B-Instruct": 0.026108540909066207,
            "Qwen/Qwen2.5-3B": 0.03307419245072045,
            "Qwen/Qwen2.5-3B-Instruct": 0.026474766280384462,
            "Qwen/Qwen2.5-7B": 0.03156184184676825,
            "Qwen/Qwen2.5-7B-Instruct": 0.031236184343032877,
            "google/gemma-2-2b": 0.031206698263874465,
            "google/gemma-2-2b-it": 0.03134360575563244,
            "google/gemma-2-9b": 0.031720311072926596,
            "google/gemma-2-9b-it": 0.027425443509922164,
            "google/gemma-2b": 0.012054107370462076,
            "google/gemma-2b-it": 0.02919097837868547,
            "google/gemma-7b": 0.03146975982906753,
            "google/gemma-7b-it": 0.03200043388942737,
            "meta-llama/Llama-3.1-8B": 0.03270314179680552,
            "meta-llama/Llama-3.1-8B-Instruct": 0.033581096487460285,
            "meta-llama/Llama-3.2-1B": 0.03148307741429932,
            "meta-llama/Llama-3.2-1B-Instruct": 0.03293703006416666,
            "meta-llama/Llama-3.2-3B": 0.02866992099414509,
            "meta-llama/Llama-3.2-3B-Instruct": 0.022654694150170525,
            "meta-llama/Meta-Llama-3-8B": 0.031163552657401488,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.03211601001681498,
            "openai-community/gpt2": 0.03146784749144799,
            "openai-community/gpt2-large": 0.012934176156490184,
            "openai-community/gpt2-medium": 0.0,
            "openai-community/gpt2-xl": 0.0
        },
        "gsm8k": {
            "01-ai/Yi-1.5-6B": 0.013483026939074823,
            "01-ai/Yi-1.5-6B-Chat": 0.01377134076569978,
            "01-ai/Yi-1.5-9B": 0.013689011567414212,
            "01-ai/Yi-1.5-9B-Chat": 0.013697992668274523,
            "01-ai/Yi-6B": 0.012888247397371141,
            "01-ai/Yi-6B-Chat": 0.012911675645682838,
            "01-ai/Yi-9B": 0.011449986902435323,
            "EleutherAI/pythia-1.4b-deduped": 0.003447819272389008,
            "EleutherAI/pythia-12b": 0.003756078341031476,
            "EleutherAI/pythia-160m-deduped": 0.0030152942428909443,
            "EleutherAI/pythia-1b-deduped": 0.003970449129848635,
            "EleutherAI/pythia-2.8b-deduped": 0.004106620637749698,
            "EleutherAI/pythia-410m-deduped": 0.0033660229497263303,
            "EleutherAI/pythia-6.9b-deduped": 0.003900413385915722,
            "EleutherAI/pythia-70m-deduped": 0.0031957470754808174,
            "Qwen/Qwen1.5-0.5B": 0.01127844785690078,
            "Qwen/Qwen1.5-0.5B-Chat": 0.00758408922014812,
            "Qwen/Qwen1.5-1.8B": 0.012634504465211183,
            "Qwen/Qwen1.5-1.8B-Chat": 0.012714401009923649,
            "Qwen/Qwen1.5-14B": 0.01354063973334243,
            "Qwen/Qwen1.5-14B-Chat": 0.013735191956468641,
            "Qwen/Qwen1.5-4B": 0.013750202076584419,
            "Qwen/Qwen1.5-4B-Chat": 0.01340907747131918,
            "Qwen/Qwen1.5-7B": 0.013767064940239285,
            "Qwen/Qwen1.5-7B-Chat": 0.013771594106283036,
            "Qwen/Qwen2-0.5B": 0.00826627452868564,
            "Qwen/Qwen2-0.5B-Instruct": 0.011731278748420906,
            "Qwen/Qwen2-1.5B": 0.010249811990593508,
            "Qwen/Qwen2-1.5B-Instruct": 0.012979892496598266,
            "Qwen/Qwen2-7B": 0.013495926436566438,
            "Qwen/Qwen2-7B-Instruct": 0.013566991960151781,
            "Qwen/Qwen2.5-0.5B": 0.006005442354577734,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.01207140536990551,
            "Qwen/Qwen2.5-1.5B": 0.007950942148339349,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.013712471049515442,
            "Qwen/Qwen2.5-14B": 0.00999950936975744,
            "Qwen/Qwen2.5-14B-Instruct": 0.013146945941397226,
            "Qwen/Qwen2.5-3B": 0.007189835754365252,
            "Qwen/Qwen2.5-3B-Instruct": 0.013566991960151775,
            "Qwen/Qwen2.5-7B": 0.008845468136919114,
            "Qwen/Qwen2.5-7B-Instruct": 0.012522795894420865,
            "google/gemma-2-2b": 0.006536148151288703,
            "google/gemma-2-2b-it": 0.013681937191764628,
            "google/gemma-2-9b": 0.01133653148963886,
            "google/gemma-2-9b-it": 0.012071405369905487,
            "google/gemma-2b": 0.006133057708959225,
            "google/gemma-2b-it": 0.008096605771155745,
            "google/gemma-7b": 0.011021119022510203,
            "google/gemma-7b-it": 0.013120581030382132,
            "meta-llama/Llama-3.1-8B": 0.011857183603902225,
            "meta-llama/Llama-3.1-8B-Instruct": 0.01211691241992571,
            "meta-llama/Llama-3.2-1B": 0.0047234874655147745,
            "meta-llama/Llama-3.2-1B-Instruct": 0.013153446023536032,
            "meta-llama/Llama-3.2-3B": 0.008403622228924022,
            "meta-llama/Llama-3.2-3B-Instruct": 0.0132525392279662,
            "meta-llama/Meta-Llama-3-8B": 0.009388953419897731,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.011893980214826171,
            "openai-community/gpt2": 0.0036816118940738735,
            "openai-community/gpt2-large": 0.003828982978735705,
            "openai-community/gpt2-medium": 0.003527595888722438,
            "openai-community/gpt2-xl": 0.0036054868679982555
        },
        "wic": {
            "01-ai/Yi-1.5-6B": 0.01981072129375818,
            "01-ai/Yi-1.5-6B-Chat": 0.019042010472530846,
            "01-ai/Yi-1.5-9B": 0.01939510234307799,
            "01-ai/Yi-1.5-9B-Chat": 0.019161437163076115,
            "01-ai/Yi-6B": 0.0197717471729423,
            "01-ai/Yi-6B-Chat": 0.019612618397185942,
            "01-ai/Yi-9B": 0.019809163801196517,
            "EleutherAI/pythia-1.4b-deduped": 0.01980984521925977,
            "EleutherAI/pythia-12b": 0.019809163801196503,
            "EleutherAI/pythia-160m-deduped": 0.01981072129375818,
            "EleutherAI/pythia-1b-deduped": 0.01981072129375818,
            "EleutherAI/pythia-2.8b-deduped": 0.01981072129375818,
            "EleutherAI/pythia-410m-deduped": 0.019802835228005834,
            "EleutherAI/pythia-6.9b-deduped": 0.01981072129375818,
            "EleutherAI/pythia-70m-deduped": 0.01981072129375818,
            "Qwen/Qwen1.5-0.5B": 0.019810623954060382,
            "Qwen/Qwen1.5-0.5B-Chat": 0.01981072129375818,
            "Qwen/Qwen1.5-1.8B": 0.019802835228005838,
            "Qwen/Qwen1.5-1.8B-Chat": 0.01972292121835615,
            "Qwen/Qwen1.5-14B": 0.019193614242270354,
            "Qwen/Qwen1.5-14B-Chat": 0.01889235444865868,
            "Qwen/Qwen1.5-4B": 0.018987551157250267,
            "Qwen/Qwen1.5-4B-Chat": 0.0197755505291712,
            "Qwen/Qwen1.5-7B": 0.01835559232177827,
            "Qwen/Qwen1.5-7B-Chat": 0.018572719528282815,
            "Qwen/Qwen2-0.5B": 0.019810623954060382,
            "Qwen/Qwen2-0.5B-Instruct": 0.01980828765781382,
            "Qwen/Qwen2-1.5B": 0.01975457420019826,
            "Qwen/Qwen2-1.5B-Instruct": 0.019662110573333363,
            "Qwen/Qwen2-7B": 0.019754574200198268,
            "Qwen/Qwen2-7B-Instruct": 0.01904201047253086,
            "Qwen/Qwen2.5-0.5B": 0.019808287657813818,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.01980721676327149,
            "Qwen/Qwen2.5-1.5B": 0.019771747172942288,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.019077219524766206,
            "Qwen/Qwen2.5-14B": 0.01979893971597298,
            "Qwen/Qwen2.5-14B-Instruct": 0.01953538134394992,
            "Qwen/Qwen2.5-3B": 0.019145026173967926,
            "Qwen/Qwen2.5-3B-Instruct": 0.019355390973060382,
            "Qwen/Qwen2.5-7B": 0.019545743293091934,
            "Qwen/Qwen2.5-7B-Instruct": 0.01969787548351923,
            "google/gemma-2-2b": 0.01980984521925977,
            "google/gemma-2-2b-it": 0.019763552842796978,
            "google/gemma-2-9b": 0.019804490588592582,
            "google/gemma-2-9b-it": 0.019662110573333363,
            "google/gemma-2b": 0.019810623954060386,
            "google/gemma-2b-it": 0.019809163801196517,
            "google/gemma-7b": 0.019810623954060382,
            "google/gemma-7b-it": 0.01916143716307612,
            "meta-llama/Llama-3.1-8B": 0.019809163801196517,
            "meta-llama/Llama-3.1-8B-Instruct": 0.01909449673562727,
            "meta-llama/Llama-3.2-1B": 0.019704433497536925,
            "meta-llama/Llama-3.2-1B-Instruct": 0.019805951085979396,
            "meta-llama/Llama-3.2-3B": 0.019810331932097542,
            "meta-llama/Llama-3.2-3B-Instruct": 0.01980984521925977,
            "meta-llama/Meta-Llama-3-8B": 0.019810331932097542,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.019704433497536932,
            "openai-community/gpt2": 0.019808287657813818,
            "openai-community/gpt2-large": 0.019810331932097542,
            "openai-community/gpt2-medium": 0.01981072129375818,
            "openai-community/gpt2-xl": 0.019810623954060386
        },
        "openbookqa": {
            "01-ai/Yi-1.5-6B": 0.022080014812228134,
            "01-ai/Yi-1.5-6B-Chat": 0.0221989546414768,
            "01-ai/Yi-1.5-9B": 0.02227969410784342,
            "01-ai/Yi-1.5-9B-Chat": 0.0221989546414768,
            "01-ai/Yi-6B": 0.022017482578127676,
            "01-ai/Yi-6B-Chat": 0.02214979066386193,
            "01-ai/Yi-9B": 0.022109039310618552,
            "EleutherAI/pythia-1.4b-deduped": 0.02104961216613481,
            "EleutherAI/pythia-12b": 0.02172888143870172,
            "EleutherAI/pythia-160m-deduped": 0.019827714859587574,
            "EleutherAI/pythia-1b-deduped": 0.021049612166134817,
            "EleutherAI/pythia-2.8b-deduped": 0.02135209178622311,
            "EleutherAI/pythia-410m-deduped": 0.020514426225628046,
            "EleutherAI/pythia-6.9b-deduped": 0.021814300984787635,
            "EleutherAI/pythia-70m-deduped": 0.019279819056352555,
            "Qwen/Qwen1.5-0.5B": 0.020916668330019886,
            "Qwen/Qwen1.5-0.5B-Chat": 0.02126575803797874,
            "Qwen/Qwen1.5-1.8B": 0.021265758037978744,
            "Qwen/Qwen1.5-1.8B-Chat": 0.021814300984787635,
            "Qwen/Qwen1.5-14B": 0.022187215803029008,
            "Qwen/Qwen1.5-14B-Chat": 0.022318338119870523,
            "Qwen/Qwen1.5-4B": 0.021930844120728505,
            "Qwen/Qwen1.5-4B-Chat": 0.022175109265613155,
            "Qwen/Qwen1.5-7B": 0.022064943313928866,
            "Qwen/Qwen1.5-7B-Chat": 0.022210326363977417,
            "Qwen/Qwen2-0.5B": 0.021049612166134806,
            "Qwen/Qwen2-0.5B-Instruct": 0.0215391706373177,
            "Qwen/Qwen2-1.5B": 0.0215391706373177,
            "Qwen/Qwen2-1.5B-Instruct": 0.02201748257812767,
            "Qwen/Qwen2-7B": 0.02223197069632112,
            "Qwen/Qwen2-7B-Instruct": 0.022303966774269955,
            "Qwen/Qwen2.5-0.5B": 0.021380042385946044,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.021323728632807498,
            "Qwen/Qwen2.5-1.5B": 0.022000910893877193,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.02196663529383292,
            "Qwen/Qwen2.5-14B": 0.02227969410784342,
            "Qwen/Qwen2.5-14B-Instruct": 0.02236139673920787,
            "Qwen/Qwen2.5-3B": 0.02209471322976178,
            "Qwen/Qwen2.5-3B-Instruct": 0.022261697292270143,
            "Qwen/Qwen2.5-7B": 0.022347949832668093,
            "Qwen/Qwen2.5-7B-Instruct": 0.0223716109825804,
            "google/gemma-2-2b": 0.022080014812228137,
            "google/gemma-2-2b-it": 0.02224224437573102,
            "google/gemma-2-9b": 0.022347949832668093,
            "google/gemma-2-9b-it": 0.022383074051792257,
            "google/gemma-2b": 0.021930844120728505,
            "google/gemma-2b-it": 0.02196663529383292,
            "google/gemma-7b": 0.02223197069632112,
            "google/gemma-7b-it": 0.02226169729227014,
            "meta-llama/Llama-3.1-8B": 0.022288147591176945,
            "meta-llama/Llama-3.1-8B-Instruct": 0.022261697292270143,
            "meta-llama/Llama-3.2-1B": 0.0216371979857224,
            "meta-llama/Llama-3.2-1B-Instruct": 0.0216371979857224,
            "meta-llama/Llama-3.2-3B": 0.0220009108938772,
            "meta-llama/Llama-3.2-3B-Instruct": 0.02200091089387719,
            "meta-llama/Meta-Llama-3-8B": 0.02226169729227014,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.022242244375731024,
            "openai-community/gpt2": 0.019920483209566065,
            "openai-community/gpt2-large": 0.020740596536488083,
            "openai-community/gpt2-medium": 0.02055326917420919,
            "openai-community/gpt2-xl": 0.020882340488761808
        },
        "mrpc": {
            "01-ai/Yi-1.5-6B": 0.02340925331970717,
            "01-ai/Yi-1.5-6B-Chat": 0.020872351656743164,
            "01-ai/Yi-1.5-9B": 0.02235954967988353,
            "01-ai/Yi-1.5-9B-Chat": 0.021393040183721096,
            "01-ai/Yi-6B": 0.021463642763705344,
            "01-ai/Yi-6B-Chat": 0.02269371331450998,
            "01-ai/Yi-9B": 0.022950790715623722,
            "EleutherAI/pythia-1.4b-deduped": 0.023189113109403532,
            "EleutherAI/pythia-12b": 0.024350302418765173,
            "EleutherAI/pythia-160m-deduped": 0.023048336668420193,
            "EleutherAI/pythia-1b-deduped": 0.023048336668420193,
            "EleutherAI/pythia-2.8b-deduped": 0.022999936277943427,
            "EleutherAI/pythia-410m-deduped": 0.024437432295314872,
            "EleutherAI/pythia-6.9b-deduped": 0.023095996571841474,
            "EleutherAI/pythia-70m-deduped": 0.023048336668420193,
            "Qwen/Qwen1.5-0.5B": 0.023048336668420193,
            "Qwen/Qwen1.5-0.5B-Chat": 0.023492334306757016,
            "Qwen/Qwen1.5-1.8B": 0.02353282402069415,
            "Qwen/Qwen1.5-1.8B-Chat": 0.022181599622954355,
            "Qwen/Qwen1.5-14B": 0.01949157366492716,
            "Qwen/Qwen1.5-14B-Chat": 0.019679975237883455,
            "Qwen/Qwen1.5-4B": 0.020714768648824114,
            "Qwen/Qwen1.5-4B-Chat": 0.02295079071562373,
            "Qwen/Qwen1.5-7B": 0.020217143503271046,
            "Qwen/Qwen1.5-7B-Chat": 0.02004263328786896,
            "Qwen/Qwen2-0.5B": 0.02402812325398081,
            "Qwen/Qwen2-0.5B-Instruct": 0.023048336668420193,
            "Qwen/Qwen2-1.5B": 0.02456604569986734,
            "Qwen/Qwen2-1.5B-Instruct": 0.020949641895469096,
            "Qwen/Qwen2-7B": 0.02439511636348831,
            "Qwen/Qwen2-7B-Instruct": 0.020872351656743164,
            "Qwen/Qwen2.5-0.5B": 0.02390001176903565,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.023048336668420193,
            "Qwen/Qwen2.5-1.5B": 0.02139304018372112,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.021025946054537687,
            "Qwen/Qwen2.5-14B": 0.019953696350889245,
            "Qwen/Qwen2.5-14B-Instruct": 0.020714768648824124,
            "Qwen/Qwen2.5-3B": 0.02094964189546909,
            "Qwen/Qwen2.5-3B-Instruct": 0.02372490639698967,
            "Qwen/Qwen2.5-7B": 0.023189113109403532,
            "Qwen/Qwen2.5-7B-Instruct": 0.02274665905021724,
            "google/gemma-2-2b": 0.02390001176903565,
            "google/gemma-2-2b-it": 0.023796963985532167,
            "google/gemma-2-9b": 0.022999936277943427,
            "google/gemma-2-9b-it": 0.021736971522579644,
            "google/gemma-2b": 0.023048336668420193,
            "google/gemma-2b-it": 0.02353282402069416,
            "google/gemma-7b": 0.022530199346874002,
            "google/gemma-7b-it": 0.022746659050217236,
            "meta-llama/Llama-3.1-8B": 0.023142920563024697,
            "meta-llama/Llama-3.1-8B-Instruct": 0.022474116867217814,
            "meta-llama/Llama-3.2-1B": 0.0233666545744261,
            "meta-llama/Llama-3.2-1B-Instruct": 0.024227245879965414,
            "meta-llama/Llama-3.2-3B": 0.023409253319707175,
            "meta-llama/Llama-3.2-3B-Instruct": 0.022120630385010477,
            "meta-llama/Meta-Llama-3-8B": 0.02309599657184147,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.022058823529411735,
            "openai-community/gpt2": 0.024597268902564928,
            "openai-community/gpt2-large": 0.023366654574426098,
            "openai-community/gpt2-medium": 0.023048336668420193,
            "openai-community/gpt2-xl": 0.023611719908318594
        },
        "headqa_en": {
            "01-ai/Yi-1.5-6B": 0.009293125515463716,
            "01-ai/Yi-1.5-6B-Chat": 0.00937963969888124,
            "01-ai/Yi-1.5-9B": 0.009397801186248863,
            "01-ai/Yi-1.5-9B-Chat": 0.009448101970358417,
            "01-ai/Yi-6B": 0.009400310229276744,
            "01-ai/Yi-6B-Chat": 0.009370165139090619,
            "01-ai/Yi-9B": 0.00935186955834199,
            "EleutherAI/pythia-1.4b-deduped": 0.009088847929910097,
            "EleutherAI/pythia-12b": 0.009298050684004381,
            "EleutherAI/pythia-160m-deduped": 0.008538984536417878,
            "EleutherAI/pythia-1b-deduped": 0.008951013596145299,
            "EleutherAI/pythia-2.8b-deduped": 0.009176095652860124,
            "EleutherAI/pythia-410m-deduped": 0.008801940051553762,
            "EleutherAI/pythia-6.9b-deduped": 0.009284806572834363,
            "EleutherAI/pythia-70m-deduped": 0.008445838167389329,
            "Qwen/Qwen1.5-0.5B": 0.00878125074733185,
            "Qwen/Qwen1.5-0.5B-Chat": 0.008676161105957144,
            "Qwen/Qwen1.5-1.8B": 0.009042709989538772,
            "Qwen/Qwen1.5-1.8B-Chat": 0.009023586509638451,
            "Qwen/Qwen1.5-14B": 0.009372899018726125,
            "Qwen/Qwen1.5-14B-Chat": 0.009211341768861967,
            "Qwen/Qwen1.5-4B": 0.009174083317233421,
            "Qwen/Qwen1.5-4B-Chat": 0.009070677697729547,
            "Qwen/Qwen1.5-7B": 0.009266017786984361,
            "Qwen/Qwen1.5-7B-Chat": 0.009168011903764635,
            "Qwen/Qwen2-0.5B": 0.008732754527011647,
            "Qwen/Qwen2-0.5B-Instruct": 0.008810709413802912,
            "Qwen/Qwen2-1.5B": 0.009075255747504299,
            "Qwen/Qwen2-1.5B-Instruct": 0.009161888800497137,
            "Qwen/Qwen2-7B": 0.00943971655823226,
            "Qwen/Qwen2-7B-Instruct": 0.009462920088428825,
            "Qwen/Qwen2.5-0.5B": 0.008867691773170792,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.0089247914894946,
            "Qwen/Qwen2.5-1.5B": 0.009255485907665237,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.009302926301305895,
            "Qwen/Qwen2.5-14B": 0.00951361359972617,
            "Qwen/Qwen2.5-14B-Instruct": 0.009546787899419762,
            "Qwen/Qwen2.5-3B": 0.009382298412004426,
            "Qwen/Qwen2.5-3B-Instruct": 0.009378302298575909,
            "Qwen/Qwen2.5-7B": 0.009464806929904604,
            "Qwen/Qwen2.5-7B-Instruct": 0.009491390379960642,
            "google/gemma-2-2b": 0.00945115986827532,
            "google/gemma-2-2b-it": 0.009459083718028043,
            "google/gemma-2-9b": 0.009548129651256988,
            "google/gemma-2-9b-it": 0.009545994957415307,
            "google/gemma-2b": 0.009318821481601559,
            "google/gemma-2b-it": 0.00920366858743745,
            "google/gemma-7b": 0.009510489046179979,
            "google/gemma-7b-it": 0.009380971735929479,
            "meta-llama/Llama-3.1-8B": 0.00952873978220898,
            "meta-llama/Llama-3.1-8B-Instruct": 0.00954141900524702,
            "meta-llama/Llama-3.2-1B": 0.00910664089692559,
            "meta-llama/Llama-3.2-1B-Instruct": 0.009033196284204686,
            "meta-llama/Llama-3.2-3B": 0.009364632806279177,
            "meta-llama/Llama-3.2-3B-Instruct": 0.009371534767500805,
            "meta-llama/Meta-Llama-3-8B": 0.009468517987865806,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.009534797785793843,
            "openai-community/gpt2": 0.008434774075330819,
            "openai-community/gpt2-large": 0.008593906746745195,
            "openai-community/gpt2-medium": 0.008552884316239904,
            "openai-community/gpt2-xl": 0.008781250747331843
        },
        "rte": {
            "01-ai/Yi-1.5-6B": 0.026400300403644338,
            "01-ai/Yi-1.5-6B-Chat": 0.02590557816045717,
            "01-ai/Yi-1.5-9B": 0.024795403613230516,
            "01-ai/Yi-1.5-9B-Chat": 0.024943505204487317,
            "01-ai/Yi-6B": 0.027850410392630694,
            "01-ai/Yi-6B-Chat": 0.02738017597257561,
            "01-ai/Yi-9B": 0.026633581342891788,
            "EleutherAI/pythia-1.4b-deduped": 0.029953149241808946,
            "EleutherAI/pythia-12b": 0.029973636495415252,
            "EleutherAI/pythia-160m-deduped": 0.030009848912529117,
            "EleutherAI/pythia-1b-deduped": 0.030063300411902652,
            "EleutherAI/pythia-2.8b-deduped": 0.030063300411902652,
            "EleutherAI/pythia-410m-deduped": 0.030009848912529117,
            "EleutherAI/pythia-6.9b-deduped": 0.029796668829124674,
            "EleutherAI/pythia-70m-deduped": 0.030096267148976626,
            "Qwen/Qwen1.5-0.5B": 0.029256116567736464,
            "Qwen/Qwen1.5-0.5B-Chat": 0.029731622646495873,
            "Qwen/Qwen1.5-1.8B": 0.029992535385373314,
            "Qwen/Qwen1.5-1.8B-Chat": 0.028910281676964154,
            "Qwen/Qwen1.5-14B": 0.024490730771774636,
            "Qwen/Qwen1.5-14B-Chat": 0.02350491152389247,
            "Qwen/Qwen1.5-4B": 0.026633581342891788,
            "Qwen/Qwen1.5-4B-Chat": 0.023329476711663546,
            "Qwen/Qwen1.5-7B": 0.02577583473914463,
            "Qwen/Qwen1.5-7B-Chat": 0.02259324110170705,
            "Qwen/Qwen2-0.5B": 0.029452371378346814,
            "Qwen/Qwen2-0.5B-Instruct": 0.028573483267653785,
            "Qwen/Qwen2-1.5B": 0.027850410392630694,
            "Qwen/Qwen2-1.5B-Instruct": 0.024943505204487314,
            "Qwen/Qwen2-7B": 0.026746810842806404,
            "Qwen/Qwen2-7B-Instruct": 0.023845970444438903,
            "Qwen/Qwen2.5-0.5B": 0.02962183222241719,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.02897228246513241,
            "Qwen/Qwen2.5-1.5B": 0.027574370145292605,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.0260328611946859,
            "Qwen/Qwen2.5-14B": 0.02401173390286763,
            "Qwen/Qwen2.5-14B-Instruct": 0.02200239659756621,
            "Qwen/Qwen2.5-3B": 0.025905578160457177,
            "Qwen/Qwen2.5-3B-Instruct": 0.023329476711663553,
            "Qwen/Qwen2.5-7B": 0.02332947671166355,
            "Qwen/Qwen2.5-7B-Instruct": 0.021797558224296004,
            "google/gemma-2-2b": 0.029256116567736464,
            "google/gemma-2-2b-it": 0.025775834739144625,
            "google/gemma-2-9b": 0.02793843768120908,
            "google/gemma-2-9b-it": 0.024943505204487317,
            "google/gemma-2b": 0.028713610811000382,
            "google/gemma-2b-it": 0.026857804902852226,
            "google/gemma-7b": 0.027938437681209075,
            "google/gemma-7b-it": 0.024174407592194747,
            "meta-llama/Llama-3.1-8B": 0.027279964226856374,
            "meta-llama/Llama-3.1-8B-Instruct": 0.027279964226856374,
            "meta-llama/Llama-3.2-1B": 0.02985524739031494,
            "meta-llama/Llama-3.2-1B-Instruct": 0.028910281676964158,
            "meta-llama/Llama-3.2-3B": 0.030009848912529113,
            "meta-llama/Llama-3.2-3B-Instruct": 0.02564359358588824,
            "meta-llama/Meta-Llama-3-8B": 0.0275743701452926,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.026280188408178123,
            "openai-community/gpt2": 0.030039730592197812,
            "openai-community/gpt2-large": 0.030052303463143706,
            "openai-community/gpt2-medium": 0.030052303463143706,
            "openai-community/gpt2-xl": 0.030063300411902652
        },
        "arc_easy": {
            "01-ai/Yi-1.5-6B": 0.009020523527210174,
            "01-ai/Yi-1.5-6B-Chat": 0.008610355160815555,
            "01-ai/Yi-1.5-9B": 0.008364176253861636,
            "01-ai/Yi-1.5-9B-Chat": 0.008264279630493454,
            "01-ai/Yi-6B": 0.008570882513077218,
            "01-ai/Yi-6B-Chat": 0.00969716659575248,
            "01-ai/Yi-9B": 0.00823233772807356,
            "EleutherAI/pythia-1.4b-deduped": 0.010163945352271721,
            "EleutherAI/pythia-12b": 0.009863468202583785,
            "EleutherAI/pythia-160m-deduped": 0.010012992232540624,
            "EleutherAI/pythia-1b-deduped": 0.010251405621305368,
            "EleutherAI/pythia-2.8b-deduped": 0.010087174498762886,
            "EleutherAI/pythia-410m-deduped": 0.010221897564256045,
            "EleutherAI/pythia-6.9b-deduped": 0.009885391390947719,
            "EleutherAI/pythia-70m-deduped": 0.009856013425811239,
            "Qwen/Qwen1.5-0.5B": 0.010248378585554033,
            "Qwen/Qwen1.5-0.5B-Chat": 0.010186228624515655,
            "Qwen/Qwen1.5-1.8B": 0.010096663811817688,
            "Qwen/Qwen1.5-1.8B-Chat": 0.010060521220920566,
            "Qwen/Qwen1.5-14B": 0.009540440071928283,
            "Qwen/Qwen1.5-14B-Chat": 0.009691180932083501,
            "Qwen/Qwen1.5-4B": 0.009981120724601437,
            "Qwen/Qwen1.5-4B-Chat": 0.010156678075911084,
            "Qwen/Qwen1.5-7B": 0.009945041946366511,
            "Qwen/Qwen1.5-7B-Chat": 0.009887786585323955,
            "Qwen/Qwen2-0.5B": 0.010259420038764082,
            "Qwen/Qwen2-0.5B-Instruct": 0.010205540414612871,
            "Qwen/Qwen2-1.5B": 0.010037412763064526,
            "Qwen/Qwen2-1.5B-Instruct": 0.009673016668133387,
            "Qwen/Qwen2-7B": 0.008924765424529265,
            "Qwen/Qwen2-7B-Instruct": 0.008709108323214467,
            "Qwen/Qwen2.5-0.5B": 0.010104361780747521,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.010080695355466594,
            "Qwen/Qwen2.5-1.5B": 0.009266280584997755,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.008772796145221905,
            "Qwen/Qwen2.5-14B": 0.008339528929814004,
            "Qwen/Qwen2.5-14B-Instruct": 0.007963772171570793,
            "Qwen/Qwen2.5-3B": 0.009098548093009187,
            "Qwen/Qwen2.5-3B-Instruct": 0.009120919741760597,
            "Qwen/Qwen2.5-7B": 0.008582222390414077,
            "Qwen/Qwen2.5-7B-Instruct": 0.008033148299801934,
            "google/gemma-2-2b": 0.008167394336065758,
            "google/gemma-2-2b-it": 0.008424859451865156,
            "google/gemma-2-9b": 0.006656742640826048,
            "google/gemma-2-9b-it": 0.007464773716353824,
            "google/gemma-2b": 0.009186490105111899,
            "google/gemma-2b-it": 0.009697166595752474,
            "google/gemma-7b": 0.00804000196687019,
            "google/gemma-7b-it": 0.009089526578213693,
            "meta-llama/Llama-3.1-8B": 0.007790845678413373,
            "meta-llama/Llama-3.1-8B-Instruct": 0.008238754121344097,
            "meta-llama/Llama-3.2-1B": 0.009972837790531479,
            "meta-llama/Llama-3.2-1B-Instruct": 0.009858506543162057,
            "meta-llama/Llama-3.2-3B": 0.009203588704032635,
            "meta-llama/Llama-3.2-3B-Instruct": 0.009306838912173907,
            "meta-llama/Meta-Llama-3-8B": 0.008559492758241152,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.00841282875411993,
            "openai-community/gpt2": 0.010030038935883607,
            "openai-community/gpt2-large": 0.010236494647406476,
            "openai-community/gpt2-medium": 0.01017545958275974,
            "openai-community/gpt2-xl": 0.010257511546488228
        },
        "arc_challenge": {
            "01-ai/Yi-1.5-6B": 0.014610348300255793,
            "01-ai/Yi-1.5-6B-Chat": 0.014562291073601229,
            "01-ai/Yi-1.5-9B": 0.014555949760496435,
            "01-ai/Yi-1.5-9B-Chat": 0.014374922192642667,
            "01-ai/Yi-6B": 0.014610858923956945,
            "01-ai/Yi-6B-Chat": 0.014588204105102202,
            "01-ai/Yi-9B": 0.01454689205200563,
            "EleutherAI/pythia-1.4b-deduped": 0.013406741767847634,
            "EleutherAI/pythia-12b": 0.013944635930726094,
            "EleutherAI/pythia-160m-deduped": 0.01247630412745394,
            "EleutherAI/pythia-1b-deduped": 0.012902554762313969,
            "EleutherAI/pythia-2.8b-deduped": 0.013724978465537371,
            "EleutherAI/pythia-410m-deduped": 0.012724999945157755,
            "EleutherAI/pythia-6.9b-deduped": 0.013967822714840055,
            "EleutherAI/pythia-70m-deduped": 0.01193591635863284,
            "Qwen/Qwen1.5-0.5B": 0.013340916085246252,
            "Qwen/Qwen1.5-0.5B-Chat": 0.013307250444941115,
            "Qwen/Qwen1.5-1.8B": 0.013905011180063244,
            "Qwen/Qwen1.5-1.8B-Chat": 0.013582571095815291,
            "Qwen/Qwen1.5-14B": 0.014583792546304037,
            "Qwen/Qwen1.5-14B-Chat": 0.01460779491401306,
            "Qwen/Qwen1.5-4B": 0.014291228393536587,
            "Qwen/Qwen1.5-4B-Chat": 0.01423587248790987,
            "Qwen/Qwen1.5-7B": 0.014460496367599015,
            "Qwen/Qwen1.5-7B-Chat": 0.014542104569955262,
            "Qwen/Qwen2-0.5B": 0.013261573677520769,
            "Qwen/Qwen2-0.5B-Instruct": 0.013318528460539426,
            "Qwen/Qwen2-1.5B": 0.014034761386175452,
            "Qwen/Qwen2-1.5B-Instruct": 0.014312094557946704,
            "Qwen/Qwen2-7B": 0.014611369529813262,
            "Qwen/Qwen2-7B-Instruct": 0.0145602203087147,
            "Qwen/Qwen2.5-0.5B": 0.013678810399518813,
            "Qwen/Qwen2.5-0.5B-Instruct": 0.013830568927974332,
            "Qwen/Qwen2.5-1.5B": 0.014542104569955265,
            "Qwen/Qwen2.5-1.5B-Instruct": 0.01457558392201967,
            "Qwen/Qwen2.5-14B": 0.014379441068522073,
            "Qwen/Qwen2.5-14B-Instruct": 0.01417591549000032,
            "Qwen/Qwen2.5-3B": 0.014592230885298962,
            "Qwen/Qwen2.5-3B-Instruct": 0.014601090150633966,
            "Qwen/Qwen2.5-7B": 0.01460779491401305,
            "Qwen/Qwen2.5-7B-Instruct": 0.01453714444428473,
            "google/gemma-2-2b": 0.01461119932984378,
            "google/gemma-2-2b-it": 0.014590931358120172,
            "google/gemma-2-9b": 0.01388881628678211,
            "google/gemma-2-9b-it": 0.013928933461382496,
            "google/gemma-2b": 0.014413988396996077,
            "google/gemma-2b-it": 0.014441889627464398,
            "google/gemma-7b": 0.01456824555029636,
            "google/gemma-7b-it": 0.014607794914013057,
            "meta-llama/Llama-3.1-8B": 0.014539646098471627,
            "meta-llama/Llama-3.1-8B-Instruct": 0.014512682523128347,
            "meta-llama/Llama-3.2-1B": 0.014097810678042187,
            "meta-llama/Llama-3.2-1B-Instruct": 0.014169664520303101,
            "meta-llama/Llama-3.2-3B": 0.014572000527756989,
            "meta-llama/Llama-3.2-3B-Instruct": 0.014568245550296365,
            "meta-llama/Meta-Llama-3-8B": 0.014562291073601227,
            "meta-llama/Meta-Llama-3-8B-Instruct": 0.014512682523128347,
            "openai-community/gpt2": 0.012240491536132873,
            "openai-community/gpt2-large": 0.012668198621315432,
            "openai-community/gpt2-medium": 0.012653835621466646,
            "openai-community/gpt2-xl": 0.013191348179838795
        },
        "arxiv_2025": {
            "meta-llama/Llama-3.2-1B": "N/A",
            "meta-llama/Llama-3.2-3B": "N/A",
            "meta-llama/Llama-3.2-3B-Instruct": "N/A",
            "meta-llama/Llama-3.2-1B-Instruct": "N/A",
            "openai-community/gpt2-xl": "N/A",
            "openai-community/gpt2": "N/A",
            "openai-community/gpt2-medium": "N/A",
            "openai-community/gpt2-large": "N/A",
            "EleutherAI/pythia-2.8b-deduped": "N/A",
            "EleutherAI/pythia-1.4b-deduped": "N/A",
            "EleutherAI/pythia-1b-deduped": "N/A",
            "EleutherAI/pythia-70m-deduped": "N/A",
            "EleutherAI/pythia-160m-deduped": "N/A",
            "EleutherAI/pythia-410m-deduped": "N/A",
            "google/gemma-2-2b": "N/A",
            "google/gemma-2b": "N/A",
            "google/gemma-2b-it": "N/A",
            "google/gemma-2-2b-it": "N/A",
            "Qwen/Qwen1.5-0.5B-Chat": "N/A",
            "Qwen/Qwen1.5-4B-Chat": "N/A",
            "Qwen/Qwen2.5-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-3B": "N/A",
            "Qwen/Qwen1.5-4B": "N/A",
            "Qwen/Qwen2.5-3B-Instruct": "N/A",
            "Qwen/Qwen1.5-0.5B": "N/A",
            "Qwen/Qwen2-1.5B": "N/A",
            "Qwen/Qwen1.5-1.8B": "N/A",
            "Qwen/Qwen2.5-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-0.5B": "N/A",
            "Qwen/Qwen1.5-1.8B-Chat": "N/A",
            "Qwen/Qwen2.5-1.5B": "N/A",
            "Qwen/Qwen2-0.5B": "N/A",
            "meta-llama/Meta-Llama-3-8B-Instruct": "N/A",
            "meta-llama/Meta-Llama-3-8B": "N/A",
            "meta-llama/Llama-3.1-8B-Instruct": "N/A",
            "meta-llama/Llama-3.1-8B": "N/A",
            "EleutherAI/pythia-12b": "N/A",
            "EleutherAI/pythia-6.9b-deduped": "N/A",
            "google/gemma-7b-it": "N/A",
            "google/gemma-2-9b": "N/A",
            "google/gemma-7b": "N/A",
            "google/gemma-2-9b-it": "N/A",
            "01-ai/Yi-1.5-6B-Chat": "N/A",
            "01-ai/Yi-1.5-6B": "N/A",
            "01-ai/Yi-9B": "N/A",
            "01-ai/Yi-6B-Chat": "N/A",
            "01-ai/Yi-6B": "N/A",
            "01-ai/Yi-1.5-9B": "N/A",
            "01-ai/Yi-1.5-9B-Chat": "N/A",
            "Qwen/Qwen2-7B": "N/A",
            "Qwen/Qwen1.5-14B": "N/A",
            "Qwen/Qwen1.5-7B-Chat": "N/A",
            "Qwen/Qwen2.5-7B-Instruct": "N/A",
            "Qwen/Qwen1.5-7B": "N/A",
            "Qwen/Qwen2.5-14B": "N/A",
            "Qwen/Qwen2.5-7B": "N/A",
            "Qwen/Qwen2.5-14B-Instruct": "N/A",
            "Qwen/Qwen1.5-14B-Chat": "N/A",
            "Qwen/Qwen2-7B-Instruct": "N/A"
        },
        "wiki_2025": {
            "meta-llama/Llama-3.2-1B": "N/A",
            "meta-llama/Llama-3.2-3B": "N/A",
            "meta-llama/Llama-3.2-3B-Instruct": "N/A",
            "meta-llama/Llama-3.2-1B-Instruct": "N/A",
            "openai-community/gpt2-xl": "N/A",
            "openai-community/gpt2": "N/A",
            "openai-community/gpt2-medium": "N/A",
            "openai-community/gpt2-large": "N/A",
            "EleutherAI/pythia-2.8b-deduped": "N/A",
            "EleutherAI/pythia-1.4b-deduped": "N/A",
            "EleutherAI/pythia-1b-deduped": "N/A",
            "EleutherAI/pythia-70m-deduped": "N/A",
            "EleutherAI/pythia-160m-deduped": "N/A",
            "EleutherAI/pythia-410m-deduped": "N/A",
            "google/gemma-2-2b": "N/A",
            "google/gemma-2b": "N/A",
            "google/gemma-2b-it": "N/A",
            "google/gemma-2-2b-it": "N/A",
            "Qwen/Qwen1.5-0.5B-Chat": "N/A",
            "Qwen/Qwen1.5-4B-Chat": "N/A",
            "Qwen/Qwen2.5-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-3B": "N/A",
            "Qwen/Qwen1.5-4B": "N/A",
            "Qwen/Qwen2.5-3B-Instruct": "N/A",
            "Qwen/Qwen1.5-0.5B": "N/A",
            "Qwen/Qwen2-1.5B": "N/A",
            "Qwen/Qwen1.5-1.8B": "N/A",
            "Qwen/Qwen2.5-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-0.5B": "N/A",
            "Qwen/Qwen1.5-1.8B-Chat": "N/A",
            "Qwen/Qwen2.5-1.5B": "N/A",
            "Qwen/Qwen2-0.5B": "N/A",
            "meta-llama/Meta-Llama-3-8B-Instruct": "N/A",
            "meta-llama/Meta-Llama-3-8B": "N/A",
            "meta-llama/Llama-3.1-8B-Instruct": "N/A",
            "meta-llama/Llama-3.1-8B": "N/A",
            "EleutherAI/pythia-12b": "N/A",
            "EleutherAI/pythia-6.9b-deduped": "N/A",
            "google/gemma-7b-it": "N/A",
            "google/gemma-2-9b": "N/A",
            "google/gemma-7b": "N/A",
            "google/gemma-2-9b-it": "N/A",
            "01-ai/Yi-1.5-6B-Chat": "N/A",
            "01-ai/Yi-1.5-9B-Chat": "N/A",
            "01-ai/Yi-6B": "N/A",
            "01-ai/Yi-9B": "N/A",
            "01-ai/Yi-1.5-6B": "N/A",
            "01-ai/Yi-6B-Chat": "N/A",
            "01-ai/Yi-1.5-9B": "N/A",
            "Qwen/Qwen2-7B": "N/A",
            "Qwen/Qwen1.5-14B": "N/A",
            "Qwen/Qwen1.5-7B-Chat": "N/A",
            "Qwen/Qwen2.5-7B-Instruct": "N/A",
            "Qwen/Qwen1.5-7B": "N/A",
            "Qwen/Qwen2.5-14B": "N/A",
            "Qwen/Qwen2.5-7B": "N/A",
            "Qwen/Qwen2.5-14B-Instruct": "N/A",
            "Qwen/Qwen1.5-14B-Chat": "N/A",
            "Qwen/Qwen2-7B-Instruct": "N/A"
        },
        "stackexchange_2025": {
            "meta-llama/Llama-3.2-1B": "N/A",
            "meta-llama/Llama-3.2-3B": "N/A",
            "meta-llama/Llama-3.2-3B-Instruct": "N/A",
            "meta-llama/Llama-3.2-1B-Instruct": "N/A",
            "openai-community/gpt2-xl": "N/A",
            "openai-community/gpt2": "N/A",
            "openai-community/gpt2-medium": "N/A",
            "openai-community/gpt2-large": "N/A",
            "EleutherAI/pythia-2.8b-deduped": "N/A",
            "EleutherAI/pythia-1.4b-deduped": "N/A",
            "EleutherAI/pythia-1b-deduped": "N/A",
            "EleutherAI/pythia-70m-deduped": "N/A",
            "EleutherAI/pythia-160m-deduped": "N/A",
            "EleutherAI/pythia-410m-deduped": "N/A",
            "google/gemma-2-2b": "N/A",
            "google/gemma-2b": "N/A",
            "google/gemma-2b-it": "N/A",
            "google/gemma-2-2b-it": "N/A",
            "Qwen/Qwen1.5-0.5B-Chat": "N/A",
            "Qwen/Qwen1.5-4B-Chat": "N/A",
            "Qwen/Qwen2.5-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-0.5B-Instruct": "N/A",
            "Qwen/Qwen2-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-3B": "N/A",
            "Qwen/Qwen1.5-4B": "N/A",
            "Qwen/Qwen2.5-3B-Instruct": "N/A",
            "Qwen/Qwen1.5-0.5B": "N/A",
            "Qwen/Qwen2-1.5B": "N/A",
            "Qwen/Qwen1.5-1.8B": "N/A",
            "Qwen/Qwen2.5-1.5B-Instruct": "N/A",
            "Qwen/Qwen2.5-0.5B": "N/A",
            "Qwen/Qwen1.5-1.8B-Chat": "N/A",
            "Qwen/Qwen2.5-1.5B": "N/A",
            "Qwen/Qwen2-0.5B": "N/A",
            "meta-llama/Meta-Llama-3-8B-Instruct": "N/A",
            "meta-llama/Meta-Llama-3-8B": "N/A",
            "meta-llama/Llama-3.1-8B-Instruct": "N/A",
            "meta-llama/Llama-3.1-8B": "N/A",
            "EleutherAI/pythia-12b": "N/A",
            "EleutherAI/pythia-6.9b-deduped": "N/A",
            "google/gemma-7b-it": "N/A",
            "google/gemma-2-9b": "N/A",
            "google/gemma-7b": "N/A",
            "google/gemma-2-9b-it": "N/A",
            "01-ai/Yi-1.5-6B-Chat": "N/A",
            "01-ai/Yi-1.5-6B": "N/A",
            "01-ai/Yi-9B": "N/A",
            "01-ai/Yi-6B-Chat": "N/A",
            "01-ai/Yi-6B": "N/A",
            "01-ai/Yi-1.5-9B": "N/A",
            "01-ai/Yi-1.5-9B-Chat": "N/A",
            "Qwen/Qwen2-7B": "N/A",
            "Qwen/Qwen1.5-14B": "N/A",
            "Qwen/Qwen1.5-7B-Chat": "N/A",
            "Qwen/Qwen2.5-7B-Instruct": "N/A",
            "Qwen/Qwen1.5-7B": "N/A",
            "Qwen/Qwen2.5-14B": "N/A",
            "Qwen/Qwen2.5-7B": "N/A",
            "Qwen/Qwen2.5-14B-Instruct": "N/A",
            "Qwen/Qwen1.5-14B-Chat": "N/A",
            "Qwen/Qwen2-7B-Instruct": "N/A"
        }
    }
}